<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>marcin-chwedczuk.github.io/</title>
   
   <link>http://localhost:4000</link>
   <description>A place where I share my thoughts about programming.</description>
   <language>en-uk</language>
   <managingEditor> </managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Floating point numbers and Unit Testing</title>
	  <link>//doubles-and-unit-testing</link>
	  <author></author>
	  <pubDate>2019-09-18T02:00:01+02:00</pubDate>
	  <guid>//doubles-and-unit-testing</guid>
	  <description><![CDATA[
	     Floating point numbers are inherently imprecise.
This can be problematic when we try to unit test
numerical algorithms.
Let's see this on an example
(JVM/Scala, ScalaTest used as a testing framework):

{% highlight scala %}
"squaring should work" in {
    val d = 0.6168705534069904

    val result = d*d

    result should be(0.3805292796606466)
}
{% endhighlight %}
This test works just fine... until someone decides to
do a "harmless refactoring" and replaces `d*d` by `Math.pow(d, 2)`:
{% highlight scala %}
"squaring should work" in {
    val d = 0.6168705534069904

    val result = Math.pow(d, 2)

    result should be(0.3805292796606466)
}
{% endhighlight %}
Now the test fails with the following message:
{% highlight no-highlight %}
0.38052927966064654 was not equal to 0.3805292796606466
{% endhighlight %}
The expected and the actual values differ by ~5.6E-17.
Doubles offer precision of about 15 significant digits in a result.
All the other digits after 15th digit are just noise that should be
ignored.

To make our unit-test more robust we have two strategies.
The first strategy is to know the precision that is guaranteed by the algorithm
that we are using, and to round the result to that
precision before returning it to the client:
{% highlight scala %}
def square(d: Double): Double = {
    val d2 = Math.pow(d, 2)
    // Precision from org.apache.commons:commons-math3:3.6.1
    return Precision.round(d2, 8)
}

"squaring should work" in {
    val d = 0.6168705534069904

    val result = square(d)

    result should be(0.38052928) // rounded
}
{% endhighlight %}

The second strategy is to use assertions intended to work
with floating point numbers. Again to use them correctly we need to
be aware of the precision of our algorithm:
{% highlight scala %}
"squaring should work" in {
    val d = 0.6168705534069904

    val result = d*d

    result should be(0.3805292796606466 +- 0.000000005)
}
{% endhighlight %}
In this case it is good to define the precision
as a global constant (or as a constant per algorithm).

Personally I prefer the first strategy, but with
either of them our tests will be more robust and
refactoring-friendly.

#### Troubles with NaN 

Totally different set of problems are connected to `NaN` values.
On JVM operator `==` and `equals` behave 
inconsistently when comparing `NaN`s:
{% highlight scala %}
"Jvm's Double" should {
    "follow JVM spec" in {
        val nan = Double.NaN;

        // Required by IEEE 754 Standard
        (nan == nan) should be(false)

        // Required by JVM Object#equals contract:
        // "for any non-null reference value x,
        //  x.equals(x) should return true"
        nan.equals(nan) should be(true)
    }
}
{% endhighlight %}

Unit testing frameworks often do not help here much.
For example the following test:
{% highlight scala %}
"how to check that a value is NaN?" in {
    val nan = Double.NaN;
    nan should be(nan)
}
{% endhighlight %}
will fail with a rather unhelpful message:
{% highlight no-highlight %}
NaN was not equal to NaN
{% endhighlight %}
According to ScalaTest guidelines we should use `Double#isNaN`
to check if a value is `NaN`:
{% highlight scala %}
"how to check that a value is NaN?" in {
    val nan = Double.NaN;
    nan.isNaN should be(true)
}
{% endhighlight %}

We experience similar troubles when we try to
compare case classes containing double fields with `NaN` values:
{% highlight scala %}
case class CaseClass(d1: Double,
                     d2: Double)

// In test code:
val inf = Double.PositiveInfinity
val nan = Double.NaN

CaseClass(1,2) shouldBe(CaseClass(1,2))
CaseClass(1, +0.0) shouldBe(CaseClass(1, -0.0))
CaseClass(1, inf) shouldBe(CaseClass(1, inf))

// fails: CaseData(1.0,NaN) was not equal to CaseData(1.0,NaN)
CaseClass(1, nan) shouldBe(CaseClass(1, nan))
{% endhighlight %}
I do not have a good solution for this problem.
We can either create a custom assertion for a given case class ourselves,
define a custom equality using 
[Scalactic](http://www.scalactic.org/user_guide/CustomEquality)
or we can use `Option[Double]` and
somehow map `NaN`s to `Option`s `None`.
None of the solutions is great.

The last thing to remember is that we cannot `match` `NaN` values:
{% highlight scala %}
val x = Double.NaN

// will fail
x match {
    case Double.NaN => doStuff()
    case _ => fail("NaN not matched!")
}

// how to do it properly
x match {
    case value@_ if value.isNaN => doStuff()
    case _ => fail("NaN not matched!")
}
{% endhighlight %}


	  ]]></description>
	</item>

	<item>
	  <title>Fluent Validation and complex dependencies between properties</title>
	  <link>//fluent-validation-and-complex-dependencies-between-properties</link>
	  <author></author>
	  <pubDate>2018-09-18T02:00:00+02:00</pubDate>
	  <guid>//fluent-validation-and-complex-dependencies-between-properties</guid>
	  <description><![CDATA[
	     [FluentValidation](https://fluentvalidation.net/) is one of the
best validation libraries for .NET. I use it daily both at work
and in my personal pet projects. Still from time to time I
encounter situations where it is not obvious how 
I should use FluentValidation.
In this blog post I describe one such situation that I have to
deal with recently.

In short I had to validate a simple DTO:
{% highlight csharp %}
public class SampleRequestDto {
    public AddressDto Address { get; set; }
    public ContactInfoDto ContactInfo { get; set; }
}

public class AddressDto {
    public string AddressLine1 { get; set; }
    public string AddressLine2 { get; set; }
    public string City { get; set; }
    public string ZipCode { get; set; }
    public string CountryIsoCode { get; set; }
}

public class ContactInfoDto {
    public string EmailAddress { get; set; }
    // Phone number validation depends on CountryIsoCode.
    public string PhoneNumber { get; set; }
}
{% endhighlight %}
With a small twist that `ContactInfo.PhoneNumber` was 
validated using country dependent format and information
about country itself was stored in `Address.CountryIsoCode` field.

This is generally a good use-case for FluentValidation `Custom` rule:
{% highlight csharp %}
RuleFor(x => x)
    .Custom((dto, context) => {
        var countryIsoCode = dto?.Address?.CountryIsoCode;
        if (string.IsNullOrEmpty(countryIsoCode)) 
            return;

        var country = Countries.FindCountryByIsoCode(countryIsoCode);
        // invalid country code - cannot validate phone number
        if (country == null)
            return;

        var phoneNumber = dto?.ContactInfo?.PhoneNumber;
        if (string.IsNullOrWhiteSpace(phoneNumber))
            return;

        if (!country.PhoneNumberFormat.Matches(phoneNumber)) {
            context.AddFailure(new ValidationFailure(
                $"ContactInfo.PhoneNumber", // property name
                $"'{phoneNumber}' is not a valid phone number in {country.Name}."));
        }
    });

{% endhighlight %}
Unfortunately in my case I also had a bunch of other country dependent 
values like VAT numbers scattered across many DTOs. And I needed
a more reusable and programmer friendly solution than `Custom` rule.

Ideally my validator definition should look like this:
{% highlight csharp %}
public class SampleRequestDtoValidator : AbstractValidator<SampleRequestDto> {
    public  SampleRequestDtoValidator() {
        RuleFor(x => x.Address)
            .SetValidator(new AddressDtoValidator());

        RuleFor(x => x.ContactInfo)
            .SetValidator(new ContactInfoDtoValidator());
    }
}

public class AddressDtoValidator : AbstractValidator<AddressDto> {
    public AddressDtoValidator() {
        RuleFor(x => x.CountryIsoCode)
            .NotEmpty()
            .CountryIsoCode(); // custom extension
        // other rules...
    }
}

public class ContactInfoDtoValidator : AbstractValidator<ContactInfoDto> {
    public ContactInfoDtoValidator() {
        RuleFor(x => x.PhoneNumber)
            .NotEmpty()
            .MaximumLength(50)
            .PhoneNumber(); // custom extension
        // other rules...
    }
}
{% endhighlight %}
Creating property validators like `CountryIsoCode` using FluentValidation
is very simple. You just extend `PropertyValidator` class,
provide an error message template to the base class ctor and override
`IsValid` method. 
Additionally you may define an extension method 
to the `IRuleBuilder<T,TProperty>`
interface to make your validator behave like build-in ones.
{% highlight csharp %}
public class CountryIsoCodeValidator : PropertyValidator {
    public CountryIsoCodeValidator() 
        : base("'{PropertyValue}' is not a valid country iso code.") { }

    protected override bool IsValid(PropertyValidatorContext context) {
        var isoCode = (string) context.PropertyValue;

        if (string.IsNullOrEmpty(isoCode)) {
            return true;
        }

        return Countries.IsKnownIsoCode(isoCode);
    }
}

public static class CountryIsoCodeValidatorExtension {
    public static IRuleBuilderOptions<T, string> CountryIsoCode<T>(
        this IRuleBuilder<T, string> rule
    ) {
        return rule.SetValidator(new CountryIsoCodeValidator());
    }
}
{% endhighlight %}

`CountryCode` validator was easy, what about `PhoneNumber` validator?
Here the only challenge that we must solve 
is finding a way to pass country ISO code from `Address` to 
phone number validator.
To solve this problem I decided to use "advanced" FluentValidation
feature called "Root Context Data". Basically this is a 
`IDictionary<string, object>` that can be prefilled with custom data
before validation starts and then is accessible to every validator
in validators tree.

Let's take a look at an example from 
[official documentation](https://fluentvalidation.net/start#root-context-data):
{% highlight csharp %}
var instanceToValidate = new Person();

var context = new ValidationContext<Person>(person);
context.RootContextData["MyCustomData"] = "Test";

var validator = new PersonValidator();
validator.Validate(context);

// usage inside validator:
RuleFor(x => x.Surname).Custom((x, context) => {
  if(context.ParentContext.RootContextData.ContainsKey("MyCustomData")) {
    context.AddFailure("My error message");
  }
});
{% endhighlight %}
Looks very promising, and what's better we can add values to `RootContextData`
straight inside top-level validators by overriding `PreValidate` method:
{% highlight csharp %}
public class SampleRequestDtoValidator : AbstractValidator<SampleRequestDto> {
    public  SampleRequestDtoValidator() {
        RuleFor(x => x.Address)
            .SetValidator(new AddressDtoValidator());

        RuleFor(x => x.ContactInfo)
            .SetValidator(new ContactInfoDtoValidator());
    }

    protected override bool PreValidate(
        ValidationContext<SampleRequestDto> context, ValidationResult result) 
    {
        var contextData = new ValidationContextData(
            context.RootContextData);

        contextData.CountryIsoCode = 
            context.InstanceToValidate?.Address?.CountryIsoCode;

        return true; // continue validation
    }
}
{% endhighlight %}
To avoid dealing with `object`s I have also created a strongly typed
wrapper (`ValidationContextData` class) around `RootContextData`
dictionary.

IMPORTANT: To make validators reusable you should set `RootContextData` only
in top level validators. Validators used with `SetValidator`
method are not considered top level.

Now implementing `PhoneNumberValidator` is easy:
{% highlight csharp %}
public class PhoneNumberValidator : PropertyValidator {
    public PhoneNumberValidator() 
        : base("'{PropertyValue}' is not a valid phone number in {Country}.") { }

    protected override bool IsValid(PropertyValidatorContext context) {
        var phoneNumber = (string) context.PropertyValue;
        if (string.IsNullOrEmpty(phoneNumber)) {
            return true;
        }

        var contextData = new ValidationContextData(
            context.ParentContext.RootContextData);

        var country = TryFindCountry(contextData.CountryIsoCode);
        if (country == null) {
            // without a country we cannot validate a phone number
            return true;
        }

        context.MessageFormatter.AppendArgument("Country", country.Name);

        return country.PhoneNumberFormat.Matches(phoneNumber);
    }

    private Country TryFindCountry(string countryIsoCode) {
        if (string.IsNullOrEmpty(countryIsoCode)) {
            return null;
        }

        return Countries.FindCountryByIsoCode(countryIsoCode);
    }
}

public static class PhoneNumberValidatorExtension {
    public static IRuleBuilderOptions<T, string> PhoneNumber<T>(
        this IRuleBuilder<T, string> rule
    ) {
        return rule.SetValidator(new PhoneNumberValidator());
    }
}
{% endhighlight %}
And we are done!

#### Unit-testing validators

FluentValidation provides several extension methods that
make unit-testing easy, just take a look:
{% highlight csharp %}
using FluentValidation.TestHelper;

public class SampleRequestDtoValidatorTest {
    private readonly SampleRequestDtoValidator _validator;

    public SampleRequestDtoValidatorTest() {
        _validator = new SampleRequestDtoValidator();
    }

    [Fact]
    public void Should_return_error_when_phone_number_is_invalid_and_countryIsoCode_is_set() {
        // Arrange
        var invalidRequest = 
            SampleRequestDtoFixture.CreateValidRequest();
        invalidRequest.Address.CountryIsoCode = "PL";
        invalidRequest.ContactInfo.PhoneNumber = "+48 123";

        // Assert
        _validator
            .ShouldHaveValidationErrorFor(
                x => x.ContactInfo.PhoneNumber, invalidRequest)
            .WithErrorMessage(
                "'+48 123' is not a valid phone number in Poland.");
    }
}
{% endhighlight %}

#### Design considerations

Everything works right now, but there is still place for improvement.
For example what happens when a programmer forgets to
override `PreValidate` method and set all required properties?
Validation of certain properties will be silently skipped.
This is not good.
To minimize this problem I put additional checks inside `ValidationContextData`
class. They will throw an exception with a descriptive message if
validator tries to access a property that was not previously set.

In my application values like phone numbers are always validated against
country specific formats. But I can imaging situations where
sometimes we use country agnostic phone number validator and
sometimes 
we use country specific one. In such cases it would be good
to call the country agnostic validator just a `PhoneNumberValidator` and
the country specific validator a `CountryDependentPhoneNumberValidator`.

I have a mixed feelings about `ValidationContextData` class because
it is used by every country specific validator in my code. Maybe 
instead of introducing this common dependency every validator should
access `RootContextData` and check if the property is set itself?

Sample source code: [GitHub](https://github.com/marcin-chwedczuk/blog-fluent-validation-adventure).


	  ]]></description>
	</item>

	<item>
	  <title>You can live without mocking frameworks</title>
	  <link>//you-can-live-without-your-mocking-framework</link>
	  <author></author>
	  <pubDate>2018-09-08T02:00:00+02:00</pubDate>
	  <guid>//you-can-live-without-your-mocking-framework</guid>
	  <description><![CDATA[
	     For a long time I have been fan of mocking frameworks like 
[Moq](https://github.com/Moq/moq4/wiki/Quickstart)
and [NSubstitute](http://nsubstitute.github.io).
These libraries seems indispensable while unit-testing.
They allow us to easily generate subs and mocks and assert that
certain interaction between components took place.

NOTE: If you do not remember difference between stub and mock
please read [this Martin Fowler article](https://martinfowler.com/articles/mocksArentStubs.html). 
In short mocks are used to test interactions between components 
(a method was called, a property was set) 
while stubs are used as dumb implementations of component dependencies 
(they usually either do nothing or provide some preset data).

But recently, after reading volume 1 of 
[Elegant Objects](https://www.yegor256.com/elegant-objects.html)
which by the way I strongly recommend, I changed my mind.
In one of the chapters author presents the idea that every interface
should have an associated fake object. A fake object is a simple
but *working* implementation of an interface and resides in the same
source code file as the interface itself.
Fake objects serve two purposes. First, they are example implementations
of interfaces that show users how the interfaces should be implemented.
And second they can be used as stubs and mocks in unit-tests.

Of course this idea seemed a bit extreme to me, so I decided to go with
a bit more evolutionary approach.
I **slowly** replaced all mock object that I had in my unit-tests 
with fakes (I put all fakes in my unit test projects - but I am still thinking that maybe they deserve a project of their own). 
During this process all interaction testing assertions 
that are usually performed using mocking frameworks
were replaced by behaviour testing assertions on fake objects.

It will be the best to illustrate this process using an example.
Say we have a simple component `EventPublishingComponent` that
publishes two events (order is not important):
{% highlight csharp %}
public class EventPublishingComponent {
    private readonly EventPublisher _eventPublisher;
    public EventPublishingComponent(EventPublisher eventPublisher)
        => _eventPublisher = eventPublisher;

    public async Task Publish() {
        await _eventPublisher.Publish(new FirstEvent(id: 3));
        await _eventPublisher.Publish(
          new SecondEvent(id: "ZDKA9JOPCKXI7"));
    }
}

public class FirstEvent : Event {
    public int Id { get; }
    public FirstEvent(int id)
        => Id = id;
}

public class SecondEvent : Event {
    public string Id { get; }
    public SecondEvent(string id)
        => Id = id;
}

public interface EventPublisher {
    Task Publish(Event @event);
}

public interface Event { }
{% endhighlight %}
A "classic" unit test for this component using NSubstitute 
could look like this:
{% highlight csharp %}
public class EventPublishingComponentTest {
    private readonly EventPublisher _eventPublisher;
    private readonly EventPublishingComponent _component;

    public EventPublishingComponentTest() {
        _eventPublisher = Substitute.For<EventPublisher>();
        _component = new EventPublishingComponent(_eventPublisher);
    }

    [Fact]
    public async Task Should_publish_FirstEvent() {
        // Arrange
        FirstEvent firstEvent = null;
        await _eventPublisher
            .Publish(Arg.Do<FirstEvent>(e => firstEvent = e));

        // Act
        await _component.Publish();

        // Assert
        await _eventPublisher.Received(1)
            .Publish(Arg.Any<FirstEvent>());

        Check.That(firstEvent)
            .IsNotNull();

        Check.That(firstEvent.Id)
            .IsNotZero();
    }
}
{% endhighlight %}
I am sure you have seen a lot of tests like this. 
The key points are: Your create mocks and stubs using your
favourite mocking library in the test constructor or setup method.
In the arrange (given) part of the test you define mocks and stubs
behaviour using library specific syntax. Here e.g. we are capturing
argument passed to `Publish` method for later use:
{% highlight csharp %}
FirstEvent firstEvent = null;
await _eventPublisher
    .Publish(Arg.Do<FirstEvent>(e => firstEvent = e));
{% endhighlight %}
In the assert (then) part of the test we use again library specific
syntax to check that a method on a mock 
was called with given set of arguments.

This approach is fine but it has some disadvantages:

1. It makes your tests very brittle. For example if I add a new method
 on `EventPublisher` called 
 `PublishAll(events)` that allows me to publish all events at once and
 refactor `EventPublishingComponent` to use it
 then `EventPublishingComponent` tests would stop working.
 The main problem here is that my tests check internal interaction
 between components 
 (was method `Publish` called?) instead of checking external behaviour 
 of the system (was event published?).

2. Mocking library is another tool that you must learn. 
 And please remember that most of the developers are not too eager to
 read documentation. Time presumably saved by using mocking library 
 will be lost on reading StackOverflow answers and on fighting with
 the library itself 
 (ever have a problem that your stub does not return intended value?). 

3. It makes your tests less readable. I must admit that 
 NSubstitute is a huge improvement over Moq in terms
 of readability but it still introduces a lot of visual noise in the test
 code. For example do see all 
 those `<`, `>`, `(` and `)` in the code below:

{% highlight csharp %}
FirstEvent firstEvent = null;
await _eventPublisher
    .Publish(Arg.Do<FirstEvent>(e => firstEvent = e));
{% endhighlight %}

Now let us see how our test can look like if we use fakes instead:
{% highlight csharp %}
public class EventPublishingComponentTest_UsingFakes {
    private readonly InMemoryEventPublisher _eventPublisher;
    private readonly EventPublishingComponent _component;

    public EventPublishingComponentTest_UsingFakes() {
        _eventPublisher = new InMemoryEventPublisher();
        _component = new EventPublishingComponent(_eventPublisher);
    }

    [Fact]
    public async Task Should_publish_FirstEvent() {
        // Act
        await _component.Publish();

        // Assert
        var firstEvent = _eventPublisher.PublishedEvents
            .OfType<FirstEvent>()
            .SingleOrDefault();

        Check.That(firstEvent)
            .IsNotNull();

        Check.That(firstEvent.Id)
            .IsNotZero();
    }
}
{% endhighlight %}
To make this test compile we also need to write a fake for 
`EventPublisher` interface. Please keep in mind that fake is a simple
but **working** implementation of the interface:
{% highlight csharp %}
public class InMemoryEventPublisher : EventPublisher {
    private readonly List<Event> _publishedEvents 
      = new List<Event>();

    public IReadOnlyList<Event> PublishedEvents
        => _publishedEvents;

    public Task Publish(Event @event) {
        if (@event == null)
            throw new ArgumentNullException(nameof(@event));

        _publishedEvents.Add(@event);
        return Task.CompletedTask;
    }
}
{% endhighlight %}

I am sure that after seeing both versions of the test 
you agree with me that both are quite short and readable,
yet the second version does not have the earlier mentioned disadvantages.
Now you may rightly say that with the second approach 
you are forced to create fakes for
almost all interfaces in your application. You are right, but
you actually want to create fakes. Here is why:

1. Fakes are like TDD for your interface **design**. By creating a fake
 you actually check how difficult it is for a client 
 of your API to provide an implementation. A fake too big or 
 too difficult to
 implement is a sign that maybe your interface is doing too much.
 Also fakes can be treated as "reference implementations" of interfaces
 and as such they are part of your API documentation.

2. Writing a fake is a one-time effort. After fake is written it can
 be reused across many tests. Compare this with subs and mocks that you
 need to setup every time you want to use them.

Now it is time for a more real world example. 
As you probably heard *Performance is a feature* but logging can 
also be a feature. Imagine an application where we must log
every failed login attempt. Since this is a business requirement
we want to code it as an acceptance test.
How difficult it can be to check that one method call was
performed:
{% highlight csharp %}
logger.LogDebug("User '{userName}' log into application.", "root");
{% endhighlight %}
In practice it can be more difficult than it seems especially if you use
notoriously hard to test `ILogger` from `Microsoft.Extensions.Logging.Abstractions` package.

Why is `ILogger` hard to test? 

1. `ILogger` interface contains only three methods 
 ([source code here](https://github.com/aspnet/Logging/blob/master/src/Microsoft.Extensions.Logging.Abstractions/ILogger.cs))
 rest of its functionality is provided via extension methods.

2. Extension methods that operate on `ILogger` often 
 create wrappers around original 
 arguments using classes like `FormattedLogValues`.
 Most of these wrapper classes does not 
 overload `Equals` and `GetHashCode` rendering
 argument matchers from mocking frameworks useless.

3. No easy access to the logged message.
 Only method responsible for actual logging on `ILogger` interface
 is `Log`:

{% highlight csharp %}
void Log<TState>(
  LogLevel logLevel, 
  EventId eventId, 
  TState state, 
  Exception exception, 
  Func<TState, Exception, string> formatter);
{% endhighlight %}

To gain access to the logged message we must either dig 
into `state` argument
or call `formatter(state, exception)`.

All this causes that naive testing aproachs like this fail:
{% highlight csharp %}
[Fact]
public async Task Naive_test() {
  var logger = Substitute.For<ILogger<SomeClass>>();
      
  logger
    .LogDebug("User '{userName}' log into application.", "root");

  logger.Received()
    .LogDebug("User '{userName}' log into application.", "root");
}
{% endhighlight %}
And how they fail? With confusing error messages like this one:
{% highlight no-highlight %}
Error Message:
 NSubstitute.Exceptions.ReceivedCallsException : 
  Expected to receive a call matching:
  Log<Object>(Debug, 0, User 'root' log into application., <null>, Func<Object, Exception, String>)
Actually received no matching calls.
Received 1 non-matching call 
 (non-matching arguments indicated with '*' characters):
  Log<Object>(Debug, 0, *User 'root' log into application.*, <null>, Func<Object, Exception, String>)
{% endhighlight %}
Not very helpful, isn't it?

If you really want to test `ILogger` using NSubstitute you must
use the following code:
{% highlight csharp %}
var logger = Substitute.For<ILogger<SomeClass>>();

dynamic state = null;
Exception exception = null; 
Func<object, Exception, string> formatter = null;

logger.Log(LogLevel.Debug, 
  Arg.Any<EventId>(), 
  Arg.Do<object>(s => state = s), 
  Arg.Do<Exception>(ex => exception = ex), 
  Arg.Do<Func<object, Exception, string>>(f => formatter = f));

logger
  .LogDebug("User '{userName}' log into application.", "root");

logger.Received(1)
  .Log(LogLevel.Debug, 
      Arg.Any<EventId>(), 
      Arg.Any<object>(), 
      Arg.Any<Exception>(), 
      Arg.Any<Func<object, Exception, string>>());

Check.That(formatter(state, exception))
    .IsEqualIgnoringCase("User 'root' log into application.");
{% endhighlight %}
Did I say something earlier about unreadable tests and a lot of 
visual noise caused by mocking frameworks? Now you can see it with your
own eyes!

Now it is time for our second approach using fakes. First we create
a fake logger:
{% highlight csharp %}
public class InMemoryListOfEntriesLogger : ILogger {
    private readonly List<LogEntry> _loggedEntries 
      = new List<LogEntry>();

    private readonly Dictionary<string, int> _bookmarks 
      = new Dictionary<string, int>();

    public IReadOnlyList<LogEntry> LoggedEntries 
        => _loggedEntries;

    public IDisposable BeginScope<TState>(TState state) {
        // Notice that we do not have to implement
        // all methods for interfaces that are *not
        // part* of our application.
        throw new NotImplementedException();
    }

    public bool IsEnabled(LogLevel logLevel) {
        return true;
    }

    public void Log<TState>(
        LogLevel logLevel, 
        EventId eventId, 
        TState state, 
        Exception exception, 
        Func<TState, Exception, string> formatter) 
    {
        _loggedEntries.Add(
          new LogEntry(
            logLevel, 
            formatter(state, exception), 
            exception));
    }
}

public class LogEntry {
  public LogLevel LogLevel { get; }
  public string Message { get; }
  public Exception Exception { get; }

  public LogEntry(LogLevel logLevel, string message, 
    Exception ex = null) {
      LogLevel = logLevel;
      Message = message;
      Exception = ex;
  }

  public override string ToString()
      => $"{LogLevel}: {Message}" + 
         (Exception != null 
            ? $" Exception: {Exception.GetType().Name}" 
            : "") +
         ".";
}
{% endhighlight %}
Notice that we did not implement all methods of `ILogger` interface.
For external interfaces that are not under our control we should
implement just enough functionality in our fakes to make them usable.

Now it is time for writing actual test:
{% highlight csharp %}
var logger = new InMemoryListOfEntriesLogger();

logger.LogDebug("User '{userName}' log into application.", "root");

Check.That(logger.LoggedEntries)
    .HasElementThatMatches(x => 
        x.Level == LogLevel.Debug &&
        x.Message == "User 'root' log into application.");
{% endhighlight %}
Wow! Test is short, readable and simple. Exactly what I was looking for.

I hope that this blog post persuaded you to start using fakes in your
unit tests. At least you now know that you have a good alternative to
mocking frameworks.

Sample source code (with a bit more complicated example): 
[GitHub](https://github.com/marcin-chwedczuk/blog-fakes-vs-mocks).


	  ]]></description>
	</item>


</channel>
</rss>
