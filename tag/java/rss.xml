<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>marcin-chwedczuk.github.io/</title>
   
   <link>http://localhost:4000</link>
   <description>A place where I share my thoughts about programming.</description>
   <language>en-uk</language>
   <managingEditor> </managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Useful JDK tools (part 1)</title>
	  <link>//useful-jdk-tools-part-1</link>
	  <author></author>
	  <pubDate>2020-07-10T02:00:01+02:00</pubDate>
	  <guid>//useful-jdk-tools-part-1</guid>
	  <description><![CDATA[
	     JDK comes with a bunch of handy tools. It's good to
know about them. In this post we will take a look at
`jps`, `jstack`, `jmap` and `jhat`.

### jps

`jps` is a JVM counterpart to unix `ps` command.
By default `jps` prints process PID and 
the name of the main class
or the name of a jar file if the 
application was started using `java -jar` option.
{% highlight nohighlight %}
$ jps
54177 Jps
54173 App
54452 app.jar
{% endhighlight %}

But it can be more talkative. 
`-l` option adds a package name to the
main class name and a full/relative path to the jar filename.
`-m` option will print command line arguments passed to the program.
{% highlight nohighlight %}
$ jps -lm
54355 pl.marcinchwedczuk.app.App arg1 arg2 arg3
54452 build/libs/app.jar arg1 arg2 arg3
54458 jdk.jcmd/sun.tools.jps.Jps -lm
{% endhighlight %}

To print JVM switches we use `-v` option:
{% highlight nohighlight %}
$ jps -v
54654 app.jar -Xmx32m -Xms32m
54657 Jps -Dapplication.home=... -Xms8m ...
{% endhighlight %}

### jstack

`jstack PID` can be used to print current stack traces of
all threads running in java process.
You can also print stack traces from a core dump file.
The output of `jstack` command is often referred to
as a _thread dump_.

Thread dumps are invaluable resources when it comes to debugging
nasty deadlocks that show up only on the production servers.
On the other hand the number of threads in a serious java application
can be overwhelming. To make the most of thread dumps, you
need to give threads meaningful names. You should give names 
(via `Thread::setName`) at least to the threads that you create 
yourself and 
you should also supply a "thread naming" `ThreadFactory` when creating
new thread pools (e.g. `newFixedThreadPool(int nThreads, ThreadFactory threadFactory)`).

Let's create a simple app that deadlocks and see what `jstack`
will print:
{% highlight java %}
public static void main(String[] args) throws InterruptedException {
	Lock l1 = new ReentrantLock();
	Lock l2 = new ReentrantLock();

	var t1 = new Thread(() -> {
		Thread.currentThread().setName("AppThread#1");
		l1.lock();
		try {
			Thread.sleep(1000);
		} catch (InterruptedException e) {
			Thread.currentThread().interrupt();
		}
		l2.lock();
	});

	var t2 = new Thread(() -> {
		Thread.currentThread().setName("AppThread#2");
		l2.lock();
		try {
			Thread.sleep(1000);
		} catch (InterruptedException e) {
			Thread.currentThread().interrupt();
		}
		l1.lock();
	});

	t1.start(); t2.start();
	t1.join(); t2.join();
}
{% endhighlight %}
EDIT: I was tired when I wrote this code. It will deadlock
both threads
say 99% of time but not always. Instead of `sleep` I should use
`CountDownLatch`. I leave the code as it is as I don't want to regenerate
thread dumps but I wanted to point out this problem.

For readability I had to shorten `jstack` output.
{% highlight nohighlight %}
$ jstack `jps | grep App | cut -d ' ' -f 1`

"main" #1 prio=5 os_prio=31 cpu=46.25ms elapsed=85.17s tid=0x00007fb623810800 nid=0x1803 in Object.wait()  [0x000070000027a000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(java.base@14.0.1/Native Method)
	...
	at java.lang.Thread.join(java.base@14.0.1/Thread.java:1371)
	at pl.marcinchwedczuk.bzzz.App.main(App.java:37)

"AppThread#1" #13 prio=5 os_prio=31 cpu=1.30ms elapsed=85.12s tid=0x00007fb622031000 nid=0x9b03 waiting on condition  [0x00007000014b3000]
   java.lang.Thread.State: WAITING (parking)
	at jdk.internal.misc.Unsafe.park(java.base@14.0.1/Native Method)
	...
	at java.util.concurrent.locks.ReentrantLock.lock(java.base@14.0.1/ReentrantLock.java:322)
	at pl.marcinchwedczuk.bzzz.App.lambda$main$0(App.java:22)
	at pl.marcinchwedczuk.bzzz.App$$Lambda$1/0x0000000800b65840.run(Unknown Source)
	at java.lang.Thread.run(java.base@14.0.1/Thread.java:832)
...
Found one Java-level deadlock:
=============================
"AppThread#1":
  waiting for ownable synchronizer 0x00000007ffd92998, (a java.util.concurrent.locks.ReentrantLock$NonfairSync),
  which is held by "AppThread#2"

"AppThread#2":
  waiting for ownable synchronizer 0x00000007ffd92968, (a java.util.concurrent.locks.ReentrantLock$NonfairSync),
  which is held by "AppThread#1"
...
{% endhighlight %}
Notice that JVM was able to detect the deadlock, saving us a hours
of debugging. If you have a heisenbug you may consider running
`jstack` periodically and searching its output for `Found * deadlock` lines.

Now let's see how we can extract thread dumps for a core dump.
And for that we need a core dump.

Here I will describe how to make a core dump on macOS 10.15
(this is based on [this article](https://developer.apple.com/library/archive/technotes/tn2124/_index.html#//apple_ref/doc/uid/DTS10003391-CH1-SECCOREDUMPS))
First we need to execute `ulimit -c unlimited` in the shell
to remove the file size limit on created core-dump files.
A simple crashing hello world C program can create about 2GB core dump,
Java cores can have sizes of 10GB or more.
Then we need to set appropriate
permissions for `/cores` directory:
{% highlight nohighlight %}
$ sudo chmod 1777 /cores
# Test if we have enough permissions
$ echo 1 > /cores/test
{% endhighlight %}
TIP: `1` in `1777` is for [sticky bit](https://en.wikipedia.org/wiki/Sticky_bit).
If a directory has this bit set then 
only the owner of a file contained in that directory
can remove or rename that file.
If we additionally create a file with `700` permissions 
then nobody beyond us will be able to change or
remove the file.

Then _in the same_ shell in which we executed `ulimit -c unlimited`
we have to run a java application and in a new
terminal window we need to send `SIGSEGV` to that app:
{% highlight nohighlight %}
$ kill -SIGSEGV PID
{% endhighlight %}
After being hit by `SIGSEGV` Java should crash with a message:
{% highlight nohighlight %}
$ java -jar build/libs/bzzz.jar
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00007fff6f4cfdfa, pid=55303, tid=775
...
# Core dump will be written. Default location: /cores/core.56128
...
{% endhighlight %}
It may take a while to write 10GB+ file on disk so be patient.

Now for some reason I was not able to take a core dump from
official Oracle distribution of JDK. When I used OpenJDK
build everything worked perfectly. Now when I switched to OpenJDK
I have to use OpenJDKs `jstack` to analyze the core dump.
{% highlight nohighlight %}
$ export PATH=/usr/local/Cellar/openjdk/14.0.1/bin:$PATH
$ jhsdb jstack --core /cores/core.56128 \
	 --exe /usr/local/Cellar/openjdk/14.0.1/bin/java

"main" #1 prio=5 tid=0x00007fb4c300c000 nid=0x1d03 in Object.wait() [0x00007000027db000]
   java.lang.Thread.State: WAITING (on object monitor)
   JavaThread state: _thread_blocked
 - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
	- waiting on <0x000000061fe55d88> (a java.lang.Thread)
 - java.lang.Thread.join(long) @bci=72, line=1303 (Interpreted frame)
	- locked <0x000000061fe55d88> (a java.lang.Thread)
 - java.lang.Thread.join() @bci=2, line=1371 (Interpreted frame)
 - pl.marcinchwedczuk.bzzz.App.main(java.lang.String[]) @bci=57, line=37 (Interpreted frame)
...
{% endhighlight %}
For some reason in OpenJDK 14 the command `jstack /path/to/java coredump`
did not work. Instead I have to use a new tool introduced in JDK9
called `jhsdb`. Anyway the result is the same, we managed to
get thread dumps from the core dump. Again the tool was smart enough
to point out the deadlock (not visible on attached listing).

OK lets cleanup our system and revert the settings:
`ulimit -c 0`, `rm /cores/*` and `sudo chmod 1775 /cores`.

### jmap

`jmap` can be used to display various info about
Java process heap. For example we may take a heap 
histogram, which tells us number of instances and
total memory size taken per class.
{% highlight nohighlight %}
$ jmap -histo $PID | head
No dump file specified
 num     #instances         #bytes  class name (module)
-------------------------------------------------------
   1:           965        2775128  [I (java.base@14.0.1)
   2:          7555         399568  [B (java.base@14.0.1)
   3:          7324         175776  java.lang.String (java.base@14.0.1)
   4:          1295         160512  java.lang.Class (java.base@14.0.1)
   5:           964          88712  [Ljava.lang.Object; (java.base@14.0.1)
   6:          1872          59904  java.util.HashMap$Node (java.base@14.0.1)
{% endhighlight %}

But the real power of `jmap` lies in its ability
to take heap dumps:
{% highlight nohighlight %}
$ jmap -dump:live,format=b,file=heapdump $PID
Dumping heap to /path/to/heapdump ...
Heap dump file created [4264220 bytes in 0.018 secs]
{% endhighlight %}
Heapdumps can then be comfortably opened and analyzed in tools like
[Eclipse Memory Analyzer](https://www.eclipse.org/mat/).

![Eclipse Memory Analyzer](assets/images/2020-07-10/ema.png)

Heapdumps can be quite huge, if you want to move them between
servers remember to first compress them to speed things up.
They also contain sensitive data like AWS access
keys and user passwords, so please keep them secure.

TIP: You can also generate heapdumps on
out of memory errors using `-XX:+HeapDumpOnOutOfMemoryError` JVM switch.

EDIT: Since JDK9 the recommended way of generating heapdumps
changed. You may want to see [this article on InfoQ](https://www.infoq.com/news/2015/12/OpenJDK-9-removal-of-HPROF-jhat/).

### jhat

Now what if you don't want/have permissions to install fancy heapdump analyzers?
Not all is lost, we may still use primitive but working `jhat`.
Run `jhat heapdump` to start `jhat` HTTP server with basic
heapdump browser.

EDIT: Unfortunately `jhat` was removed in JDK9.
	  ]]></description>
	</item>

	<item>
	  <title>Matching regexes using backtracking</title>
	  <link>//matching-regexes-using-backtracking</link>
	  <author></author>
	  <pubDate>2020-06-28T02:00:01+02:00</pubDate>
	  <guid>//matching-regexes-using-backtracking</guid>
	  <description><![CDATA[
	     In this post we will write a simple regex library.
The table below presents regex operators that we are going to support:

<table>
    <colgroup>
        <col width="25%" />
        <col width="75%" />
    </colgroup>
    <thead>
        <tr class="header">
            <th>Operator</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td markdown="span">A single character e.g. `a`, `\n`, `\(`</td>
            <td markdown="span">
                A single character matches itself.<br/>
                Special characters need to be escaped e.g. `\n`.
            </td>
        </tr>
        <tr>
            <td markdown="span">Character groups e.g. `[a-z]`, `[^xyz]`</td>
            <td markdown="span">Character group matches any character
                that is part of the group.<br/><br/>
                Negated character group (`[^xyz]`)
                matches any character that is _not_ part of the group.<br/><br/>
                Character ranges like `a-z` can be used inside groups.
                A character c belongs to `a-z` range when its
                numerical value falls between `(int)'a' <= (int)c <= (int)'z'`.
            </td>
        </tr>
        <tr>
            <td markdown="span">`.` wildcard</td>
            <td markdown="span">
                `.` wildcard will match any single character. 
                <br /><br />
                For example
                `...` will match any string consisting of three characters.
            </td>
        </tr>
        <tr>
            <td markdown="span">Concatenation e.g. `abc`,<br/>`[0-9]-[0-9]`</td>
            <td markdown="span">Just as we can concatenate strings, 
                we may also concatenate regexes. 
                The resulting expression will match an input, only when the input can be split into two parts, so that
                the first part of the input matches the first concatenated regex and
                the second part of the input matches the second concatenated regex.
                <br /><br />
                For example input `9X` matches the regex `[0-9][XYZ]` because `9` matches `[0-9]` and `X` matches `[XYZ]`.
            </td>
        </tr>
        <tr>
            <td markdown="span">Alternative e.g. `Z|X|[0-9]`</td>
            <td markdown="span">Input matches the alternative when it matches
                any branch of the alternative. <br /><br/>
                For example inputs `Z`, `X`
                and `3` will all match `Z|X|[0-9]` alternative because they match
                respectively `Z`, `X` and `[0-9]` branches. 
                <br /><br/>
                Alternative has lower priority than concatenation so
                `foo|bar` means `(foo)|(bar)`, not `fo(o|b)ar`.
            </td>
        </tr>
        <tr>
            <td markdown="span">Repetition (quantification) 
                e.g. `a*`, `[0-9]?`, `X{1,5}`</td>
            <td>
                Preceding regex must match input specified number of times.<br/>
                Supported operators are: <br/><br/>
                <ul>
                    <li><code>*</code> - matches zero or more times</li>
                    <li><code>+</code> - matches one or more times</li>
                    <li><code>?</code> - matches zero or one time</li>
                    <li><code>{n}</code> - matches exactly n times</li>
                    <li><code>{n,m}</code> - matches between n and m
                     times (inclusive) 
                    </li>
                </ul>
                <div markdown="span">
                    For example `[0-9]*` will match any string consisting of digits, including empty string.<br />
                    On the other hand `[0-9]{2,3}` will match strings consisting of two or three decimal digits.<br/><br/>
                    In our limited implementation we do not support spaces
                    (or any other whitespace characters) inside `{n,m}` expressions.<br/><br/>
                    Repetition has higher priority than concatenation and 
                    alternative so `foo{5}` means `fo(o{5})`, not `(foo){5}`.<br/><br/>
                    Repetition operators are greedy, this means they will try
                    to match as much input as possible.<br />
                    For example `(a*)(a*)` will match the `aaaaa` input in
                    the following way `(aaaaa)()` - the first `a*` will match
                    all the characters, leaving empty string for the second `a*` to match.
                </div>
            </td>
        </tr>
        <tr>
            <td markdown="span">`^` and `$` anchors</td>
            <td markdown="span">
                `^` matches the beginning of the input.<br/>
                `$` matches the end of the input.<br/><br/>
                For example `^foo` will match strings that start with
                `foo` and `bar$` will match strings that end with `bar`.
            </td>
        </tr>
        <tr>
            <td markdown="span">Grouping (parentheses)</td>
            <td markdown="span">
                Parentheses are used to alter the precedence of the operators.<br/><br/>
                For example compare `foo|bar` with `fo(o|b)ar`,
                the first one will match `foo`, the second one `fooar`.
            </td>
        </tr>
    </tbody>
</table>

The library itself is quite small, it consists of two parts:
a parser and a matcher. 
The parser is a very simple [recursive descent parser](https://en.wikipedia.org/wiki/Recursive_descent_parser)
and as most of manually written parsers
it probably contains some undiscovered bugs.
The parser itself is not the main focus of this article,
so we will tread it as a black box that consumes regular 
expressions in text form and produces equivalent ASTs or Abstract Syntax Trees.

ASTs are tree like data structures, 
that make order of operator evaluation and the internal structure of a regular
expression explicit.
Let's see this on an example. The AST representation of 
 `^a(foo|bar|egg)*b$` regex is:
![AST tree](assets/images/2020-06-28/ast1.svg)

The anchors `^` and `$` are represented by their own
AST nodes `AT_BEGINNING` and `AT_END`.
To represent both character groups and single characters, we use
`GROUP` nodes. `GROUP` nodes are very simple, they contain a list
of characters that they match. A `GROUP` node for `[0-9]` regex
contains characters `0123456789` in the list.
For negated groups like `[^0-9]` we use `NEGATED_GROUP` node,
the representation is the same as for `GROUP` (we keep `0123456789` characters
in the list).
Next is the tricky one, we use `NEGATED_GROUP` without any characters
to represent wildcard (`.`). This makes sense because an empty group `[]` 
does not match anything, so its negation will match all characters.

To represent quantification operators like `?`, `+`, `*` and `{n,m}`
we use `REPEAT` nodes. `REPEAT` nodes contain two additional attributes:
minimum and maximum number of allowed repetitions.
We use `Long.MAX_VALUE` to signify that maximum number of repetitions is unbound.
Finally we use `CONCAT` node to represent concatenation of two or more
regular expressions.

In the code all AST nodes are represented by a single class
called `RAst`:
{% highlight java %}
public class RAst {
    public final RAstType type;
    public final Set<Character> chars;
    public final List<RAst> exprs;

    // Repeat from to, both inclusive
    public final long repeatMin;
    public final long repeatMax;

    // ...
{% endhighlight %}
`type` field describes what kind of AST node this instance
represents e.g. `CONCAT`.
`GROUP` and `NEGATED_GROUP` nodes keep the set of matched/not-matched
characters in `chars` field.
`CONCAT` and `ALTERNATIVE` nodes keep their children in `exprs` field 
(the order of children is important, hence a `List`).
`REPEAT` node keeps its only child as a single element list in `exprs` field.

The matcher is represented in the code by `BacktrackingMatcher` class.
The interface of the matcher is very simple:
{% highlight java %}
public class BacktrackingMatcher {
    public static Match match(String s, RAst regex);
}

public class Match {
    public final boolean hasMatch;
    public final String input;
    public final int start;
    public final int end;

    public String matched()  {
        if (!hasMatch) return null;
        return input.substring(start, end);
    }
}
{% endhighlight %}
Our matcher will only find the first substring of the input that
matches the regex. Yet it would not be too difficult to extend 
the algorithm to find all matches (start matching again 
after the end of the previous match).

To implement our matcher we will use an algorithm design technique 
called backtracking. The general idea of backtracking is
very simple: we enumerate all the possible solution candidates
in a smart way and then we return the first candidate that is a valid solution.
The part "in a smart way" is very important, usually
enumerating all solution candidates will result in a very
slow algorithm (think `O(2^n)` or even `O(n!)`).
The key here is to quickly and early reject some subsets of
the solutions candidates. 

Let's see this on a very simple example,
say we want to solve a puzzle that is about placing various shapes in 3x3 grid. Some places in the grid are already taken. There is also a rule that describes a valid solution: in every row and column we cannot have two shapes of the same kind.
![Puzzle board](assets/images/2020-06-28/puzzle.svg)
Simple enumeration of all possible assignments of the shapes to the free places
will generate `3^5` solution candidates, most of them wrong.
A smarter candidate generation strategy
would be to check immediately after we fill a free place,
if the solution conditions still holds for this place row and column.
This would save us a lot of work, because we could discard a lot of
solution candidates much more early in the process.
For example we could discard all the solution candidates that have
Cloud shape at 1B position in the first step of the algorithm.

The name of the technique itself comes from the specific way
in which the algorithm generates all the solution candidates.
The naive backtracking algorithm that solves our simple puzzle looks like this:
{% highlight java %}
// Board positions:
// [0 | 1 | 2]
// [3 | 4 | 5]
// [6 | 7 | 8]
// Notice that rowIndex = currentPosition / 3
// and         colIndex = currentPosition % 3
private boolean solve(char[][] board, int currentPosition) {
    if (currentPosition == 9) {
        // All places are filled, check if this
        // candidate is a valid solution.
        return isValidSolution(board);
    }

    if (isPlaceTaken(board, currentPosition)) {
        // Move to checking the next place.
        return solve(board, currentPosition+1);
    }

    // Try putting all shapes in the free place
    for (char shape: new char[] { 'C', 'H', 'R' }) {
        putShape(board, currentPosition, shape);

        if (solve(board, currentPosition + 1)) {
            return true;
        }

        // Clear position or BACKTRACK.
        putShape(board, currentPosition, '?');
    }

    return false;
}
{% endhighlight %}
The key part of the algorithm is the `for` loop,
where we put a shape on the free place and then remove it 
when don't find a solution. This removal
or taking a move back is what gave the algorithm its name.
Alternatively we may say that when `solve` returns `false`,
then the `board` is exactly in the same state as it was
before we called `solve`.

Matching regular expression is somehow similar to solving our previous puzzle.
At each step we have several possibilities, like should we match `foo`
or `fo` from the alternative `(foo|fo)`. How much characters should
`f+` expression match? Should `(bar)?` match `bar` or nothing?
On the other hand the most complexity in matching regular expressions
comes from the fact that we are matching a recurrent structure (tree).
It's like matching our puzzle, but where each empty place can contain
another smaller version of the same puzzle that also must be solved.

The main entry point to our regex matching algorithm is
{% highlight java %}
@FunctionalInterface
public interface Cont {
    boolean run();
}

boolean match(Input input, RAst ast, Cont cont)
{% endhighlight %}
method. It takes three parameters, `input` which is just
the input `String` plus a pointer called `pos` that tracks next, not yet
matched character. `Input` also provides helpful methods that can
be used to save and restore `pos` value (we will need that
for backtracking). Next parameter, `ast`, is an AST subtree that the algorithm
should match. The last parameter `cont` is the most interesting one.
In my previous blog post I wrote about 
[continuations](/continuations-in-java), please read that post before
going further. `cont` is lambda expression (but we may thread it also as
a kind of continuation), that when called will
try to match remaining part of the regex AST (e.g. it will match parents
and the remaining siblings nodes of `ast` node).

The contract of `match` method is as follows.
If the method is not able to match `ast` subtree it will
return `false`, `cont` will not be called and the `input`
will not be modified (or it may be restored to the original state).
On the other hand if `ast` subtree could be matched then
`cont` will be called with the modified `input` and
`match` will return whatever `cont` returns.
Before returning value to the client `input` will be restored
to the original state (this is not strictly necessary if we
are looking for the first match but somehow makes algorithm more elegant).

At the top level we will call `match` somehow like this:
{% highlight java %}
int startIndex = input.currentPos();
AtomicInteger endIndex = new AtomicInteger(0);

boolean hasMatch = match(input, regex, () -> {
    endIndex.set(input.currentPos());
    return true;
});
{% endhighlight %}
This call means that we are looking for the matches
starting at index `startIndex` and if we find one
we save the
end of the match in the `endIndex` variable and return `true`
to signify that matching process should stop.
This is the only place in the algorithm where we use
`return true`. Matched substring could be easily
retrieved as `input.substring(startIndex, endIndex)`.

The body of `match` method is a giant switch statement that
delegates matching of different AST types to different methods (not counting simple
operators):
{% highlight java %}
public static boolean match(Input input, RAst ast, Cont cont) {
    RAstType type = ast.type;
    InputPositionMarker m = null;

    switch (type) {
        /* some cases skipped */

        case GROUP:
            if (input.atEnd()) return false;
            if (ast.chars.contains(input.current())) {
                m = input.markPosition();
                input.advance(1);
                try {
                    return cont.run();
                } finally {
                    input.restorePosition(m);
                }
            }
            return false;

        case CONCAT:
            return concatRec(input, ast.exprs, 0, cont);

        case ALTERNATIVE:
            return alternativeRec(input, ast.exprs, 0, cont);

        case REPEAT:
            return repeatRec(input, ast, 0, cont);

        default: throw new AssertionError("Unknown AST type: " + type);
    }
}
{% endhighlight %}
Let's take a look how matching a `GROUP` is performed.
If the group matches next input character, we save the current
input pointer in `m` variable, then we advance the input pointer 
and finally we call `cont` to match the
rest of the regex. After `cont` returns we restore the input position
using `finally` block. This is a bit hacky but it works.

Matching `CONCAT` node is also simple. We use recursion to match
subsequent children expressions:
{% highlight java %}
private static boolean concatRec(Input input,
                                 List<RAst> exprs,
                                 int currExpr,
                                 Cont cont) {
    if (currExpr == exprs.size()) {
        // We matched all the children
        return cont.run();
    }

    // Match exprs.get(currExpr) child
    return match(input, exprs.get(currExpr), () ->
        // If it succeeded then match next child expression 
        concatRec(input, exprs, currExpr + 1, cont)
    );
}
{% endhighlight %}
Notice that because we are not consuming any input here we have
nothing to restore.

Similarly `ALTERNATIVE` is easy to match:
{% highlight java %}
private static boolean alternativeRec(Input input,
                                      List<RAst> expr,
                                      int currExpr,
                                      Cont cont) {
    if (currExpr == expr.size()) {
        // We tried all branches but found no match.
        return false;
    }

    // Try matching expr.get(currExpr) branch of the alternative
    boolean matched = match(input, expr.get(currExpr), cont);
    // We found a match
    if (matched) return true;

    // No match found - Let's try next alternative "branch"
    return alternativeRec(input, expr, currExpr+1, cont);
}
{% endhighlight %}
Here `currExpr` points to the current alternative branch that we are matching.
Instead of using recursion we may implement `alternativeRec` 
using a simple `for` loop, which I left as an exercise for the reader.

Matching `REPEAT` node causes the most troubles, because all
quantification operators are greedy by default. This means that
e.g. `a+` will try to match as much characters as possible.
To implement this behavior we first attempt to match `REPEAT`s child subtree 
as many times as possible, then we move "backwards" calling `cont`
each time to check if we have a match.
The diagram below illustrates this process:
{% highlight nohighlight %}
We match a+ expression:
a
a a
a a a         // We matched a three times.
a a a noMatch // Forth time we have noMatch.
a a a cont()  // We move backwards, calling cont()
a a cont()    // each time until it returns true.
a cont() match // cont() returned true.
               // We stop moving backwards and return true from a+.
{% endhighlight %}
The code of `repeatRec` is:
{% highlight java %}
private static boolean repeatRec(Input input,
                                 RAst repeatAst,
                                 long matchCount,
                                 Cont cont) {
    // For expressions like R{n,m} do we have
    // more matches than necessary?
    if (matchCount > repeatAst.repeatMax)
        return false;

    // Greedy matching as much as possible.
    boolean matched = match(input, repeatAst.headExpr(), () ->
        repeatRec(input, repeatAst, matchCount+1, cont)
    );

    // We are moving backwards, calling `cont` each time.
    // We also make sure that we have min number of matches
    // for expressions like R{n,m}.
    if (!matched && (matchCount >= repeatAst.repeatMin)) {
        return cont.run();
    }

    return matched;
}
{% endhighlight %}

And generally that's it. Our simple regex engine.
There are some details left (like handling `^` or `$` or
moving `startIndex`) but the idea behind the backtracking
matcher should now be familiar to us.

You can find source code for the engine (including tests)
on GitHub: [https://github.com/marcin-chwedczuk/reng](https://github.com/marcin-chwedczuk/reng). But before you jump to see the
code I really recommend you to write a similar engine (in your
favorite language) yourself. This will give you a much more
deeper understanding of the algorithm.

Last but not least, our algorithm has a decent performance,
given that we use reasonable regexes and inputs.
A regex like `(a+)*c` matched on the input `aaaaaaaaaaaaaaaaaaaaaaaaaaaab`
will have a very bad performance. This is a common problem
not only in our matcher but in most regex libraries
that use backtracking algorithms. You can 
read more about this problem on [Wikipedia](https://en.wikipedia.org/wiki/ReDoS).

	  ]]></description>
	</item>

	<item>
	  <title>Continuations in Java</title>
	  <link>//continuations-in-java</link>
	  <author></author>
	  <pubDate>2020-06-27T02:00:01+02:00</pubDate>
	  <guid>//continuations-in-java</guid>
	  <description><![CDATA[
	     CSP or Continuation-Passing Style is a style of programming in which
functions return results via callbacks.
For example `+` operator is a function that takes two numbers and
returns their sum. In CSP `+` operator becomes a function that takes
three arguments, two terms and a callback, usually called a continuation in
the context of CSP.
In Java we can express this as:

{% highlight java %}
void add(int a, int b, Cont<Integer> cont) {
    cont.apply(a + b);
}

@FunctionalInterface
private interface Cont<R> {
  void apply(R result);
}
{% endhighlight %}

Because functions' results are always returned via callback calls,
CSP is forcing us to name the returned values by naming callback parameters.
In addition CSP makes the order of evaluation of an expression explicit.
For example, a simple Java program in imperative style:
{% highlight java %}
System.out.println(1 + 2 + 3);
System.exit(0);
{% endhighlight %}
Can be expressed in CSP as follows:
{% highlight java %}
add(1, 2, partialSum ->
  add(partialSum, 3, sum ->
    print(sum, unit ->
      System.exit(0))));

static void print(int n, Cont<Void> cont) {
  System.out.println(n);
  cont.apply(null);
}
{% endhighlight %}
While transforming imperative programs into CSP form we may encounter
problems with handling procedures (methods returning `void` in Java).
A lot of functional programming languages do not support procedures,
instead they define a special type called `Unit`, that has only
a single value and use that type to signify that function does
not return any meaningful data.
So defined `Unit` type is often identified with the empty tuple `()`.
In Java we do not have `Unit`, but we may use `Void` type with its only
allowed value `null` to simulate it.

While looking at our last example we may notice that in CSP form,
function arguments can be in one of three forms:
a constant, a variable or a lambda expression.
There is no rule preventing us from passing two or more
callbacks to a single function. 
Indeed this is necessary to translate `if` statement to CSP counterpart:
{% highlight java %}
void iff(boolean expr,
         Cont<Boolean> trueBranch,
         Cont<Boolean> falseBranch) {
    if (expr) trueBranch.apply(true);
    else falseBranch.apply(false);
}
{% endhighlight %}
Instead of `Cont<Boolean>` we could use here `Cont<Void>` as well.

To get a better feel for CSP we will look at three more examples.
We will start with a simple (naive) program for computing sum
of all numbers between given two numbers:
{% highlight java %}
static long sum(int from, int to) {
  long sum = 0;
  for (int i = from; i <= to; i++) {
    sum += i;
  }
  return sum;
}
{% endhighlight %}
The transformation to CSP will become easier
if we first replace `for` loop with recursion:
{% highlight java %}
static long sum_rec(int from, int to) {
  return (from > to)
    ? 0
    : from + sum_rec(from+1, to);
}
{% endhighlight %}
This version can be easily translated into CSP:
{% highlight java %}
static void sumCC(int from, int to, Cont<Long> cont) {
  gt(from, to, fromGreaterThanTo ->
    iff(fromGreaterThanTo,
      x -> cont.apply(0L),
      x -> add(from, 1, from1 ->
        sumCC(from1, to, sumCC1 ->
          addLong(from, sumCC1, cont)))));
}
{% endhighlight %}
Where `gt` is the CSP counterpart of `>` operator.

Next we will transform factorial computing function.
This time we will start with a recursive definition that is 
easier to translate:
{% highlight java %}
static int factorial(int n) {
  if (n == 0) return 1;
  return factorial(n-1)*n;
}
{% endhighlight %}
CSP version of factorial looks like this:
{% highlight java %}
private static void factorial(int n, Cont<Integer> cont) {
  eq(n, 0, isNZero ->
    iff(isNZero,
      x -> cont.apply(1),
      x -> add(n, -1, nm1 ->
        factorial(nm1, fnm1 ->
          multiply(n, fnm1, cont)))));
}
{% endhighlight %}

As the last example we will transform a function
that computes Fibonacci sequence:
{% highlight java %}
static int fib1(int n) {
    if (n < 2) return 1;
    return fib1(n-1) + fib1(n-2);
}
{% endhighlight %}
In CSP it looks like this:
{% highlight java %}
static void fib(int n, Cont<Integer> cont) {
  lt(n, 2, nlt2 ->
    iff(nlt2,
      x -> cont.apply(1),
      x -> add(n, -1, nm1 ->
        fib(nm1, fnm1 ->
          add(n, -2, nm2 ->
            fib(nm2, fnm2 ->
              add(fnm1, fnm2, cont)))))));
}
{% endhighlight %}

Now we should have, at least intuitive feel, how the
transformation to CSP works. In fact any program can be
transformed to CSP. The last point is quite interesting,
especially if we pass `() -> exit(0)` or some other not-returning function
as the last continuation. Why? Because in that case we will
never return from any of the called functions.
Let's see how this works on a simple example:
{% highlight java %}
static void main(String[] args) {
    factorial(6, fac6 ->
      print(fac6, x ->
        System.exit(0)));

    System.out.println("Will never be printed");
}
{% endhighlight %}

The entire idea of having a call stack is about providing a way for
the called functions to return the control to the callers.
But if we are never returning, then we don't need a call stack, right?
Not so fast, some of you may say - what about passing arguments to 
the called functions,
call stack is used for that too. Yes, the arguments are also stored on
the call stack but with CSP we capture 
the values of arguments using closures.
Of course JVM does not know that our programs are in CSP form or that they 
would do fine without having a call stack at all.
Instead we get a new call stack frame every time we call something,
this results in `StackOverflowError` quickly when we call
e.g. `factorial(3000, r -> ...)`.

Too avoid `StackOverflowError`s we may use a technique called trampolining. 
Trampolining in connection with CSP
could reduce the required call stack space to a constant number
of slots.
The idea of trampolining is very simple, we split computation into
parts and then we compute only the first part and _return_ a 
continuation (called thunk) that is responsible for computing the rest. 
The returned continuation captures the result of the first computation in
its closure so we don't have to recompute it.
Let's see how a trampolined `+` operator would looks like:
{% highlight java %}
static Thunk add(int a, int b, Cont<Integer> cont) {
    int sum = a + b;
    return () -> cont.apply(sum);
}

static Thunk add3(int a, int b, int c, Cont<Integer> cont) {
    return add(a, b, sum ->
            add(sum, c, cont));
}

@FunctionalInterface
private interface Cont<R> {
    Thunk apply(R result);
}

@FunctionalInterface
private interface Thunk {
    Thunk run();
}
{% endhighlight %}
Notice that trampolined `+` operator splits its computation
into two parts: computing the sum and calling the continuation.
The called continuation will again split it's work and so on and on.

`add3` function illustrates two key points. 
One is that the logical flow of the program stays the same, we just
call the passed continuations like in a pure CSP program.
The other is, that to introduce trampolining we only need to modify
primitives provided by our programming language (operators and statements).
The program code stays the same.
Of course because Java is a statically-typed language we need to change 
functions return type from `void` into `Thunk`, but this is
a simple mechanical change that would not be necessary in 
a dynamically-typed language.

Next example illustrates how trampolined `if` statement and
`factorial` looks like. Notice that factorial code did not change,
not counting the return type:
{% highlight java %}
static Thunk iff(boolean expr,
                 Cont<Boolean> trueBranch,
                 Cont<Boolean> falseBranch) {
  return (expr)
    ? () -> trueBranch.apply(true)
    : () -> falseBranch.apply(false);
}

static Thunk factorial(int n, Cont<Integer> cont) {
  return eq(n, 0, isNZero ->
    iff(isNZero,
      x -> cont.apply(1),
      x -> add(n, -1, nm1 ->
        factorial(nm1, fnm1 ->
          multiply(n, fnm1, cont)))));
}
{% endhighlight %}

Because we are now performing computation "in parts", we need 
a procedure that will be continually invoking returned thunks,
thus ensuring that out computation is making progress.
A procedure like this is called a trampoline:
{% highlight java %}
static void trampoline(Thunk thunk) {
  while (thunk != null) {
      thunk = thunk.run();
  }
}

static <T> Cont<T> endCall(Consumer<T> call) {
  return r -> {
      call.accept(r);
      return null;
  };
}
{% endhighlight %}
We are also providing a new primitive operator `endCall` that
can be used to mark the last part of the computation.
Using `trampoline` we may now compute `factorial(3000)`
without any troubles:
{% highlight java %}
AtomicInteger res = new AtomicInteger(-1);
trampoline(factorial(400000, endCall(res::set)));
System.out.println(res.get())
{% endhighlight %}
As a side effect, we may now use trampoline to mix
CSP and imperative code in the same program.

CSP and trampolining are not mere theoretical concepts,
there where and are still used to implement e.g. LISP interpreters.
Continuations can also be used to simplify backtracking algorithms.
Source code for this blog post can be found
[here](https://github.com/marcin-chwedczuk/reng/tree/master/test/pl/marcinchwedczuk/continuations).



	  ]]></description>
	</item>

	<item>
	  <title>Spy JVM network traffic with Owasp ZAP proxy</title>
	  <link>//spy-jvm-network-traffic-with-owasp-zap</link>
	  <author></author>
	  <pubDate>2019-01-24T01:00:00+01:00</pubDate>
	  <guid>//spy-jvm-network-traffic-with-owasp-zap</guid>
	  <description><![CDATA[
	     We start by downloading [Owasp ZAP proxy](https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project):

{% highlight shell %}
$ # Download and unpack...
$ curl -O -J -L https://github.com/zaproxy/zaproxy/releases/download/2.7.0/ZAP_2.7.0_Linux.tar.gz
$ tar xvzf ZAP_2.7.0_Linux.tar.gz

$ # Run ZAP proxy...
$ ./ZAP_2.7.0/zap.sh  
{% endhighlight %}
By default ZAP listens on `localhost:8080`. You can change default address
and port by going into Tools -> Options -> Local Proxies tab:
![ZAP Local Proxies tab](assets/images/2019-01-25/zap_options.png)

To test that network traffic interception works, 
we will use a simple Java app:
{% highlight java %}
public static void main(String[] args) throws IOException {
    CloseableHttpClient client = HttpClientBuilder.create()
            .useSystemProperties()
            .build();
    try {
        String status = client
            .execute(new HttpGet("http://httpstat.us/200"))
            .getStatusLine()
            .toString();

        System.out.println(status);
    }
    finally {
        client.close();
    }
}
{% endhighlight %}
There are few things to notice:

* We use Apache HttpClient to perform http requests.
* By default Apache HttpClient do not use proxy servers,
 even if you set ZAP as a system wide proxy. We will deal
 with this problem later. For now we will use `useSystemProperties()` method
 on `HttpClientBuilder` class that will enable proxy support.
* Right now we will concentrate on intercepting HTTP traffic.
 I will show you how to deal with HTTPS connections later.

If we, now, run our application, we will notice that ZAP did not
intercept any traffic:
{% highlight shell %}
$ java -jar ./build/libs/zapproxydemo-1.0-SNAPSHOT.jar 
HTTP/1.1 200 OK
{% endhighlight %}
Indeed right now our application does not know that it should use
a proxy server. We may force it to use a proxy via JVM command line
parameters:
{% highlight shell %}
$ java -Dhttp.proxyHost=127.0.0.1 \
 -Dhttp.proxyPort=8080 \
 -Dhttps.proxyHost=127.0.0.1 \
 -Dhttps.proxyPort=8080 \
 -jar ./build/libs/zapproxydemo-1.0-SNAPSHOT.jar 
{% endhighlight %}
or by dynamicaly setting system properties in code:
{% highlight java %}
System.setProperty("http.proxyHost", "127.0.0.1");
System.setProperty("http.proxyPort", "8080");
System.setProperty("https.proxyHost", "127.0.0.1");
System.setProperty("https.proxyPort", "8080");
{% endhighlight %}
Whatever method you use, if you run the application again,
you should be able to see now a single intercepted request in ZAP:
![Intercepted request in ZAP](assets/images/2019-01-25/intercepted_request.png)
You can remove previously recorded requests in ZAP by pressing `Ctrl+N`.

#### Intercepting traffic from proxy unfriendly apps

As I mentioned previously, Apache HttpClient ignores
proxy settings by default.
If we create our `HttpClient` using `create()` method:
{% highlight java %}
public static void main(String[] args) throws IOException {
    CloseableHttpClient client = HttpClientBuilder.create()
            .build();

    try {
        String status = client
            .execute(new HttpGet("http://httpstat.us/200"))
            .getStatusLine()
            .toString();

        System.out.println(status);
    }
    finally {
        client.close();
    }
}
{% endhighlight %}
`HttpClient` will ignore proxy settings no matter how we set them.

For dealing with cases like this, we may use
[proxychains-ng](https://github.com/rofl0r/proxychains-ng/tree/v4.13).
This project is a new reincarnation of old
[proxychains](https://github.com/haad/proxychains) util which is no
longer maintained.
Please be aware of this difference. On my system `apt-get install proxychains`
installs `proxychains` and not `proxychains-ng` that we need here.
To install `proxychains-ng` I needed to download sources from GitHub
and compile them myself:
{% highlight shell %}
$ # Checkout tag v4.13
$ git clone --branch v4.13 git@github.com:rofl0r/proxychains-ng.git

$ cd proxychains-ng
$ ./configure
$ # If there are no errors from configure script
$ make
$ ./proxychains4 --help

Usage:  ./proxychains4 -q -f config_file program_name [arguments]
    -q makes proxychains quiet - this overrides the config setting
    -f allows one to manually specify a configfile to use
    for example : proxychains telnet somehost.com
More help in README file

$ # Install system wide...
$ sudo make install
{% endhighlight %}
We also need to change default `proxychains-ng` configuration:
{% highlight shell %}
sudo vim /etc/proxychains.conf

# Comment out line:
# proxy_dns

# Change ProxyList to:
[ProxyList]
http 127.0.0.1 8080
{% endhighlight %}

Now if we run our application using `proxychains`:
{% highlight shell %}
$ proxychains4 java -jar ./build/libs/zapproxydemo-1.0-SNAPSHOT.jar 
[proxychains] config file found: /etc/proxychains.conf
[proxychains] preloading /usr/local/lib/libproxychains4.so
[proxychains] DLL init: proxychains-ng 4.13-git-10-g1198857
[proxychains] Strict chain  ...  127.0.0.1:8080  ...  23.99.0.12:80  ...  OK
HTTP/1.1 200 OK
{% endhighlight %}
We will be able to intercept traffic using ZAP.

One of the limitations of proxychains is that it may not work for
subprocesses. If you app launches other applications they may
not be proxied at all.

#### Intercepting HTTPS traffic

So far, so good, but what will happen if we try to intercept
HTTPS traffic from a new, more secure, example:
{% highlight java %}
public static void main(String[] args) throws IOException {
    System.setProperty("http.proxyHost", "127.0.0.1");
    System.setProperty("http.proxyPort", "8080");
    System.setProperty("https.proxyHost", "127.0.0.1");
    System.setProperty("https.proxyPort", "8080");

    CloseableHttpClient client = HttpClientBuilder.create()
            .useSystemProperties()
            .build();

    String url = "https://www.random.org/integers/?num=12&min=1&max=100&col=3&base=10&format=plain&rnd=new";

    try {
        HttpEntity entity = client
            .execute(new HttpGet(url))
            .getEntity();

        String responseBody = EntityUtils.toString(entity);
        System.out.println(responseBody);
    }
    finally {
        client.close();
    }
}
{% endhighlight %}
We will get an exception similar to:
{% highlight no-highlight %}
Exception in thread "main" javax.net.ssl.SSLHandshakeException:
sun.security.validator.ValidatorException: PKIX path building failed:
sun.security.provider.certpath.SunCertPathBuilderException: unable
to find valid certification path to requested target
{% endhighlight %}
We get this exception because certificate returned by ZAP
proxy is not trusted.
To fix this problem we must generate a new ZAP root cert and add it
(temporarily) to Java keystore.

Generate a new cert and save it somewhere
(Tools -> Options -> Dynamic SSL Certificates):
![ZAP generate a new root certificate](assets/images/2019-01-25/gen_cert.png)
Don't forget to click OK.

Then add ZAP root certificate to Java keystore:
{% highlight shell %}
$ cd $JAVA_HOME/jre/lib/security
$ pwd
/usr/lib/jvm/java-8-oracle/jre/lib/security
$ # You should see cacerts file in this directory.

$ # Create a backup
$ sudo cp cacerts cacerts.bakup2019-01-26

$ # Add certificate to the store
$ sudo keytool -importcert \
 -alias zap-proxy.org \
 -file ~/owasp_zap_root_ca.cer \
 -keystore cacerts
$ # When asked about keystore password 
$ # write: changeit (the default password)
{% endhighlight %}
If we run our app again, we will be able to intercept an HTTPS request:
![Intercepted HTTPS call](assets/images/2019-01-25/intercept_https.png)

This again should work with `proxychains-ng`.
Sometimes to make it work you will have to **uncommend** `proxy_dns`
option in `/etc/proxychains.conf` file, that I earlier said to
comment out. Why is this sometimes needed, to be honest, I don't know but
it works this way...

**For security reasons** after you finished your debugging session,
you should remove ZAP certificate from Java keystore:
{% highlight shell %}
$ cd $JAVA_HOME/jre/lib/security

$ # Make sure you see your cert
$ sudo keytool -list -v -keystore cacerts | grep zap-proxy.org
Enter keystore password:  changeit

$ # Remove it
$ sudo keytool -delete -alias zap-proxy.org -keystore cacerts

$ # Make sure it's gone
$ sudo keytool -list -v -keystore cacerts | grep zap-proxy.org
Enter keystore password:  changeit
{% endhighlight %}
Always generate a new ZAP proxy certificate
before adding it to Java keystore. If you must do this
often, I can advice you to create a script and/or bash alias to
make entire process more convenient.


	  ]]></description>
	</item>

	<item>
	  <title>Java streams best practices</title>
	  <link>//java-streams-best-practices</link>
	  <author></author>
	  <pubDate>2017-11-08T01:00:00+01:00</pubDate>
	  <guid>//java-streams-best-practices</guid>
	  <description><![CDATA[
	     In this short post I am going to present Java 8 streams 
best practices. Most of them either I figured out myself or
learned from my colleagues.

Let's start with some "obvious" things about code formatting:

* You should have at most one stream method call per line.
 This will make stream operations like `map`, `filter` and 
 `collect` easily recognizable.
{% highlight java %}
// BAD CODE:
strings.stream().filter(s -> s.length() > 2).sorted()
	.map(s -> s.substring(0, 2)).collect(Collectors.toList());

// GOOD CODE:
strings.stream()
	.filter(s -> s.length() > 2)
	.sorted()
	.map(s -> s.substring(0, 2))
	.collect(Collectors.toList());
{% endhighlight %}

* You should `import static` all of the standard 
 stream related methods. This will make code shorter, 
 easier to read and easier to understand by removing all 
 unnecessary visual noise.
{% highlight java %}
// BAD CODE:
strings.stream()
	.sorted(Comparator.reverseOrder())
	.limit(10)
	.collect(Collectors.toMap(Function.identity(), String::length));

// GOOD CODE:
strings.stream()
	.sorted(reverseOrder())
	.limit(10)
	.collect(toMap(identity(), String::length));
{% endhighlight %}

* You should prefer method references to lambdas.
{% highlight java %}
// AVOID:
strings.stream()
	.map(s -> s.length())
	.collect(toList());

// PREFER:
strings.stream()
	.map(String::length)
	.collect(toList());
{% endhighlight %}
Method references are easier to read since we
avoid all the visual noise generated by `->` and `()` operators.
They are also handled more efficiently by current version of Java.
Lambda expressions like `s -> s.length()` are compiled
to a private static method and an `invokedynamic` instruction.
{% highlight java %}
// s -> s.lenght() is translated into:
private static Integer lambda$main$0(String s) {
	return s.length();
}
{% endhighlight %}
Method references are compiled to only `invokedynamic` instruction.

* You should use methods from `Class<T>` to filter stream elements by a type
 and to cast stream elements to a type.
{% highlight java %}
Stream<Object> objects = Stream.of(
	"a string",
	42,
	new String[] { "an array" },
	"another string");

List<String> strings = objects
	.filter(String.class::isInstance)
	.map(String.class::cast)
	.collect(toList());
{% endhighlight %}
Also rember that `Class<T>::isInstance` only checks if 
the value can be assigned to a variable of type `T`. For example
`Object.class.isInstance("foo")` returns `true` because string
`"foo"` can be assigned to a variable of type `Object`.
If you want to check that stream elements have exactly type `T`
you must use expression:
{% highlight java %}
.filter(x -> (x != null) && x.getClass().equals(T.class))
{% endhighlight %}

* Give meaningful names to frequently used collector expressions.
 In most cases this means extracting collector expression into
 its own method.
{% highlight java %}
// USED FROM TIME TO TIME:
Map<Integer, Entity> entityById = entities.stream()
	.collect(toMap(Entity::getId, identity()));

// USED FREQUENTLY:
Map<Integer, Entity> entityById = entities.stream()
	.collect(ExtraCollectors.toByIdMap());

private static class ExtraCollectors {
  public static Collector<Entity,?,Map<Integer,Entity>> toByIdMap() {
	return Collectors.toMap(Entity::getId, identity());
  }
}
{% endhighlight %}
You may also consider using static import for your own frequently
used collectors.

* Use the following pattern when you sort stream values at hoc:
{% highlight java %}
List<Student> result = students.stream()
	.sorted(
	  comparing(Student::getSurname)
		.thenComparing(Student::getName, reverseOrder())
		.thenComparing(Student::getAge)
		.thenComparing(Student::getId, reverseOrder())
	)
	.collect(toList());
{% endhighlight %}
Notice how we used `reverseOrder()` to reverse order of sorting
by name and id. Also bear in mind that it is always a good idea
to extract complicated comparers to its own method or a final field.

* Use `IntStream`, `LongStream` and `DoubleStream` when working with
 primitive types. They are faster (they avoid boxing) and easier to
 use (they add useful methods like `sum`).
{% highlight java %}
Stream<String> strings = Stream.of("a", "foo", "bar", "baz");

double averageLength = strings
		.mapToInt(String::length)
		.summaryStatistics()
		.getAverage();
{% endhighlight %}
Use `mapTo[Int|Long|Double]` and `mapToObj` to convert 
between a stream and a specialized primitive stream.

Also learn about static helper methods exposed by specialized stream
classes:
{% highlight java %}
// prints: 0 1 2 3 4 5 6 7 8 9
IntStream.range(0, 10)
	.forEach(System.out::println);

// prints: 1 2 4 8 16 32 64 128 256 512
IntStream.iterate(1, i -> 2*i)
	.limit(10)
	.forEach(System.out::println);

ThreadLocalRandom random = ThreadLocalRandom.current();

// prints: -376368599 2112239618
// just to demo generate method:
IntStream.generate(random::nextInt)
	.limit(2)
	.forEach(System.out::println);

// prints: -1134353240 2007034835
// stream of random int's - more idiomatic way:
random.ints()
	.limit(2)
	.forEach(System.out::println);
{% endhighlight %}

* Avoid using `peek()`.
 Try to make your streams free of side-effects.

This list is by no means complete. I will try to add some more
practices in the future. Bye!



	  ]]></description>
	</item>

	<item>
	  <title>Hibernate HHH000179 warning&#58 Narrowing proxy to class this operation breaks ==</title>
	  <link>//HHH000179-narrowing-proxy-to-class-this-operation-breaks-equality</link>
	  <author></author>
	  <pubDate>2017-07-30T02:00:00+02:00</pubDate>
	  <guid>//HHH000179-narrowing-proxy-to-class-this-operation-breaks-equality</guid>
	  <description><![CDATA[
	     In this post I will explain why Hibernate is generating the HHH000179
warning and when ignoring it may introduce bugs in your code.

To understand what this "Narrowing proxy" is all about,
first we must learn about Hibernate proxies.
When we read a value of lazy loaded property or when we call
`EntityManager::getReference` Hibernate returns a proxy object.
This proxy is an instance of a class that was generated at runtime using
library like [Javassit](http://jboss-javassist.github.io/javassist/).

For example for a simple entity:
{% highlight java %}
@Entity
@Table(name = "person")
public class Person extends BaseEntity {
    @Column(name = "person_name", nullable = false)
    private String name;

    @ManyToOne(optional = false, fetch = FetchType.LAZY, cascade = CascadeType.ALL)
    @JoinColumn(name = "house_id")
    private House house;

    @OneToMany(mappedBy = "owner", fetch = FetchType.LAZY, cascade = CascadeType.ALL, orphanRemoval = true)
    private Set<Pet> pets = new HashSet<>(0);

    // ...
}
{% endhighlight %}
Generated proxy class looks similar to:
{% highlight java %}
public class Person_$$_jvst5ed_2 
        extends Person 
        implements HibernateProxy, ProxyObject {
 
    private MethodHandler handler;
    private static Method[] _methods_;
 
    // plenty of other stuff here
 
    public final UUID _d7getId() {
        return super.getId();
    }
 
    public final UUID getId() {
        Method[] var1 = _methods_;
        return (UUID)this.handler.invoke(this, var1[14], var1[15], new Object[0]);
    }
}
{% endhighlight %}

TIP: In Hibernate 5.1 you may write generated 
proxy classes to disk by putting a breakpoint
in [`JavassistProxyFactory::buildJavassistProxyFactory`](https://github.com/hibernate/hibernate-orm/blob/ba3359fe62be258638554fe23a2a0a6a50f7e732/hibernate-core/src/main/java/org/hibernate/proxy/pojo/javassist/JavassistProxyFactory.java#L102)
method and setting 
`factory.writeDirectory` field to a valid path. 
You may want to use a conditional
breakpoint to avoid doing this manually every time a proxy is generated.

The most important point here is that proxy class *extends* entity class.

Now let's see what happens when we mix proxies with inheritance.
Given a simple class hierarchy:
{% highlight java %}
@Entity
@Inheritance(strategy = InheritanceType.SINGLE_TABLE)
@DiscriminatorColumn(name = "animal_type")
public abstract class Pet extends BaseEntity {
    @Column
    private String name;

    @JoinColumn(name = "owner_id", nullable = false)
    @OneToOne(optional = false, fetch = FetchType.LAZY)
    private Person owner;

    public abstract String makeNoise();
    // ...
}

@Entity
@DiscriminatorValue("cat")
public class Cat extends Pet { /* ... */ }

@Entity
@DiscriminatorValue("dog")
public class Dog extends Pet { /* ... */ }
{% endhighlight %}
When we use `EntityManager::getReference` to load a `Pet` we will
get a proxy that extends `Pet` class because Hibernate does not know yet
whatever our pet is a `Cat` or a `Dog`:
{% highlight java %}
// In some earlier transaction:
Cat gerard = new Cat("gerard");
entityManager.persist(gerard);

gerardId = gerard.getId();

// In current transaction:
Pet pet = entityManager.getReference(Pet.class, gerardId);

assertThat(pet)
        .is(hibernateProxy())
        .is(uninitialized())
        .isInstanceOf(Pet.class)
        .isNotInstanceOf(Cat.class);
{% endhighlight %}
We may force Hiberante to query database to load proxied entity
state but that doesn't change proxy identity:
{% highlight java %}
// makeNoise() will access field *via getter* to initialize proxy
logger.info("Pet is a cat: " + pet.makeNoise()); // meow meeeow

assertThat(pet)
        .isNot(uninitialized())
        .isNotInstanceOf(Cat.class);
{% endhighlight java %}
Even though now Hibernate knows that our pet is a `Cat` it cannot
change already loaded proxy class definition,
`Pet` proxy continues to be so.
This may cause you problems because tests like `pet instanceof Cat` will
fail although pet indeed represents a cat.

There is also a second issue that may come up when working with proxies.
If `makeNoise()` method would access pet data via field, proxy would not
be notified about that data access and it wouldn't load data from DB,
causing our method to read an uninitialized field value.
_The moral is that we should always use getters and setters 
when dealing with entity state_.

Now you may think that if we try to load `Pet` again (after proxy was
initialized), Hibernate will return instance of the `Cat` entity.
The behavior displayed by Hibernate is slightly different
because of Hibernate first level cache
that prefers returning already
loaded entity instance than creating a new one:
{% highlight java %}
Pet pet2 = entityManager.getReference(Pet.class, gerardId);

assertThat(pet2)
        .isNotInstanceOf(Cat.class)
        .isSameAs(pet);
{% endhighlight %}

What will happen when we try to explicitly load a `Cat` entity:
{% highlight java %}
// HHH000179: Narrowing proxy to class Cat - this operation breaks ==
Pet pet3 = entityManager.getReference(Cat.class, gerardId);
assertThat(pet3)
        .isInstanceOf(Cat.class)
        .isNot(hibernateProxy());
{% endhighlight %}
Now we got the famous HHH000179 warning, and Hiberante handled
us unproxied `Cat` instance.
But why was this warning generated? Because right now we 
we have two different object (the proxy and the `Cat` instance)
in our session that point to exactly the same entity.

Of course the pet proxy is pointing to the cat instance,
and changes applied to e.g. entity instance are reflected in the proxy state:
{% highlight java %}
assertThat(pet.getName())
    .isEqualTo("gerard");

assertThat(pet)
    .isNotSameAs(pet3);

// set via Cat entity
pet3.setName("proton");

// reflected via proxy
assertThat(pet.getName())
    .isEqualTo("proton");
{% endhighlight %}

So you may think that having two representation of the same DB row 
in memory is OK,
but the real troubles begin if we do not override `equals()` and `hashCode()`
methods properly. This is demonstrated by example:
{% highlight java %}
// Alice is owner of the cat
Person alice = entityManager.find(Person.class, aliceId);

// Alice can own and not own the same cat...
assertThat(alice.getPets().contains(pet))
        .isFalse();

assertThat(alice.getPets().contains(pet3))
        .isTrue();

// But only if we rely on default equals() and 
// hashCode() implementation
{% endhighlight %}
Fortunately this can be easily fixed by providing `equals()` implementation
that is based either on primary key or business key equality, for example:
{% highlight java %}
@MappedSuperclass
public abstract class BaseEntity {
    @Id
    @Type(type="binary(16)")
    private UUID id;

    protected BaseEntity() {
        this.id = UUID.randomUUID();
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || !(o instanceof BaseEntity)) return false;

        BaseEntity that = (BaseEntity) o;

        // remember to use *getters*
        return getId().equals(that.getId());
    }

    @Override
    public int hashCode() {
        return getId().hashCode();
    }
}
{% endhighlight %}

We may also reproduce above behaviour with lazy loading,
you can find an example of how to do this in the attached source code.

#### Significance in the real world application

Recently I developed a module in an application that was based on huge
in-house framework (Ughhh). This framework let's call it X
contained some of the entities that we used, but we have no way of
modifying them. The only way to add some fields to an already existing entity
was to extend it (fortunately for us, most entities in X were declared
as base classes with inheritance strategy SINGLE_TABLE).
At the end of this project we had plenty of small class hierarchies
consisting only of super class and a single subclass.
We also had plenty of references from other entities to either
this sup or super classes. As you may expect this was a fertile 
ground for Hibernate HHH000179 warnings, and so I devoted a few hours of
my time to figure out what this warning is all about. In our case
providing proper `equals()` and `hashCode()` was all that was needed.
But just to sum up I want to present the last, more real world example.

Shipped with framework X:
{% highlight java %}
@Entity
@Table(name = "extensible_user")
@Inheritance(strategy = InheritanceType.SINGLE_TABLE)
@DiscriminatorColumn(name = "discriminator")
@DiscriminatorValue("NOT_USED")
public class LegacyUser {
    @Id
    @GeneratedValue
    private Long id;

    @Column
    private String userPreference1;

    @Column
    private String userPreference2;
    // ...
}

@Entity
@Table(name = "document")
public class LegacyDocument {
    @Id
    @GeneratedValue
    private Long id;

    @Column
    private String contents;

    @ManyToOne(optional = false, fetch = FetchType.LAZY)
    @JoinColumn(name = "owner_id")
    // !!! Entity referes to super class !!!
    private LegacyUser owner;

    // ...
}
{% endhighlight %}
Shipped with my module:
{% highlight java %}
@Entity
@DiscriminatorValue("EXTENDED")
public class ExtendedUser extends LegacyUser {
    @Column
    private String userPreference3;
    // ...
}

@Entity
@Table(name = "comment")
public class Comment {
    @Id
    @GeneratedValue
    private Long id;

    @ManyToOne(/*...*/)
    @JoinColumn(name = "document_id")
    private LegacyDocument document;

    @ManyToOne(/*...*/
    @JoinColumn(name = "author_id")
    // !!! Entity refers to subclass !!!
    private ExtendedUser author;

    @Column
    private String contents;
    // ...
}
{% endhighlight %}
As you can see legacy class `Document` is using `LegacyUser` to refer to
a system user. New class `Comment` is using `ExtendedUser` to refer to
a system user.

Without proper `equals()` implementation we may get into troubles:
{% highlight java %}
LegacyDocument document = 
    entityManager.find(LegacyDocument.class, documentId);

// we load some data from document owner
LegacyUser documentOwner = document.getOwner();
doSomethingWithOwner(documentOwner);

// HHH000179: Narrowing proxy to class ExtendedUser 
//  - this operation breaks ==
// When Hibernate loads comment that has 
// field of type ExtendedUser with the same Id as LegacyUser 
// it realizes that documentOwner is indeed ExtendedUser.
// So this time Hibernate could figure out that 
// it generated wrong proxy without querying DB.
List<Comment> comments = entityManager.createQuery(
            "select c from Comment c where c.document.id = :docId",
            Comment.class)
        .setParameter("docId", document.getId())
        .getResultList();

// Now the most interesting part
ExtendedUser commentAuthor = comments.get(0).getAuthor();

// comment author and doc author is the same user
assertThat(commentAuthor.getId())
        .isEqualTo(documentOwner.getId());

// but...
assertThat(commentAuthor)
        .isNotSameAs(documentOwner);

// Now without overloading hashCode()/equals() we may
// expect troubles...
Set<LegacyUser> users = new HashSet<>();
users.add(commentAuthor);
users.add(documentOwner);

assertThat(users).hasSize(2);
{% endhighlight %}

And that is all that I wanted to say about HHH000179. 
The most important thing that
you should remember from this article is that with 
good `equals()` and `hashCode()` implementation
HHH000179 warning can be safely ignored.

Source code: [https://github.com/marcin-chwedczuk/hibernate_narrowing_proxy_warning_demo](https://github.com/marcin-chwedczuk/hibernate_narrowing_proxy_warning_demo)


	  ]]></description>
	</item>

	<item>
	  <title>Debugging OpenJDK 8 with NetBeans on Ubuntu</title>
	  <link>//debugging-openjdk8-with-netbeans-on-ubuntu</link>
	  <author></author>
	  <pubDate>2017-06-24T02:00:00+02:00</pubDate>
	  <guid>//debugging-openjdk8-with-netbeans-on-ubuntu</guid>
	  <description><![CDATA[
	     In this post we will learn how to download, compile and debug OpenJDK 8
using Ubuntu and NetBeans IDE.

#### Downloading and compiling OpenJDK 8

[OpenJDK](http://openjdk.java.net/) project uses Mercurial for source
code versioning. To get sources using Mercurial follow instructions described 
[in this SO answer](https://stackoverflow.com/a/29845834/1779504).

To get OpenJDK sources using Git, we need to clone OpenJDK repository mirror
provided by [AdoptOpenJDK project](https://adoptopenjdk.net/about.html).
To speed things up we will only clone `master` branch without commit history:
{% highlight no-highlight %}
$ git clone \
	--depth 1 \
	-b master \
	git@github.com:AdoptOpenJDK/openjdk-jdk8u.git
{% endhighlight %}

Now when we have sources, its time to compile OpenJDK.
First we need to install all required dependencies:
{% highlight no-highlight %}
$ sudo apt install \
        libx11-dev \
        libxext-dev \
        libxrender-dev \
        libxtst-dev \
        libxt-dev \
        libcups2-dev \
        libfreetype6-dev \
        libasound2-dev
{% endhighlight %}
Then we must run `configure` script:
{% highlight no-highlight %}
$ cd openjdk-jdk8u/
$ chmod +x ./configure
$ ./configure \
	--with-debug-level=slowdebug \
	--with-target-bits=64
{% endhighlight %}
We call `configure` with two options:

* `--with-debug-level=slowdebug` - enables generating debug information
 when compiling OpenJDK
* `--with-target-bits=64` - we will generate 64-bit binaries

It may happen than `configure` will return error telling you that you need
to install some additional tool/library. This is something to be expected,
just follow instructions printed by `configure`.
You may need to do this several times until you will 
have all required dependencies installed on your system.

Now it's time to actually build OpenJDK:
{% highlight no-highlight %}
$ make
{% endhighlight %}
This may take some time...
{% highlight no-highlight %}
----- Build times -------
Start 2017-06-24 17:45:26
End   2017-06-24 17:48:53
00:00:12 corba
00:01:25 hotspot
00:00:08 jaxp
00:00:12 jaxws
00:01:13 jdk
00:00:17 langtools
00:03:27 TOTAL
-------------------------
Finished building OpenJDK for target 'default'
{% endhighlight %}

Now we may use our newly built `java` to run "Hello, world!" program:
{% highlight no-highlight %}
$ ./build/linux-x86_64-normal-server-slowdebug/jdk/bin/java \
	-cp "/home/me/dev/java/helloWorld/" \
	App
Hello, world!
{% endhighlight %}

#### Creating project for OpenJDK 8 in NetBeans

You need to [download](https://netbeans.org/downloads/)
and install NetBeans IDE. Since HotSpot is written in C++ we will need
NetBeans with C/C++ support.

Now it is time to create project for OpenJDK in NetBeans.
Select File->New Project...->C/C++ Project with Existing Sources...
![New project dialog window.](assets/images/2017-06-24/new_proj.png)

Then select "Custom" configuration mode:
![New project dialog window 2 step.](assets/images/2017-06-24/new_proj2.png)

We must use the same `configure` arguments that we used on command line:
![Configure options.](assets/images/2017-06-24/new_proj3.png)

Now click "Next" a few more times and then click "Finish".
NetBeans should now run `configure` and build OpenJDK, you should
see compiler output in Build tab:
![Build window.](assets/images/2017-06-24/new_proj4.png)

After build ends you should see output similar to:
{% highlight no-highlight %}
----- Build times -------
Start 2017-06-24 18:07:15
End   2017-06-24 18:11:17
00:00:14 corba
00:01:45 hotspot
00:00:08 jaxp
00:00:13 jaxws
00:01:22 jdk
00:00:20 langtools
00:04:02 TOTAL
-------------------------
Finished building OpenJDK for target 'default'

BUILD SUCCESSFUL (total time: 4m 2s)
{% endhighlight %}

Now we should try to run our "Hello, World!" program from NetBeans.
Click on project and then select "Properties":
![Run command.](assets/images/2017-06-24/run_1.png)
Then go to "Run" category and click on "..." next to "Run command", then
write any command that you want to run. Assume that `"${OUTPUT_PATH}"`
refers to `java` binary:
![Run command step 2.](assets/images/2017-06-24/run_2.png)

Now select Run->Run Project, NetBeans will ask you what binary you want to
run, select `java`:
![Run command step 3.](assets/images/2017-06-24/run_3.png)

Now you should see "Hello, world!" written in Output window:
![Run command step 4.](assets/images/2017-06-24/run_4.png)

#### Debugging with NetBeans

Call to `System.out.println(...)` in Java will ultimately be handled
by `writeBytes` function in `jdk/src/share/native/java/io/io_util.c` file
(this is only valid for Linux builds of OpenJDK).

Lets put a breakpoint inside that function and see what will happen when we
try to debug Hello world program:
![Debug step 1.](assets/images/2017-06-24/debug_1.png)

Select Debug->Debug Main Project. After executing this command you
may see window:
![Debug step 2.](assets/images/2017-06-24/debug_2.png)
JVM uses `SIGSEGV` for its internal purposes, from our point of view
we may just ignore it (select "Don't Catch this Singla Again" and 
"Forward and Continue"). After a few seconds we should be able to
catch a breakpoint and see what JVM is doing:
![Debug step 3.](assets/images/2017-06-24/debug_3.png)

And that's it! 
Now you will be able to check and understand how JVM is working under cover.

#### References

* [http://marcelinorc.com/2016/02/17/using-netbeans-to-hack-openjdk9-in-ubuntu/](http://marcelinorc.com/2016/02/17/using-netbeans-to-hack-openjdk9-in-ubuntu/)
* [https://neugens.wordpress.com/2015/02/26/debugging-the-jdk-with-gdb/](https://neugens.wordpress.com/2015/02/26/debugging-the-jdk-with-gdb/)
* [https://github.com/AdoptOpenJDK/openjdk-build](https://github.com/AdoptOpenJDK/openjdk-build)


	  ]]></description>
	</item>

	<item>
	  <title>Zen and the Art of Unit Testing</title>
	  <link>//zen-and-the-art-of-unit-testing</link>
	  <author></author>
	  <pubDate>2017-02-19T01:00:00+01:00</pubDate>
	  <guid>//zen-and-the-art-of-unit-testing</guid>
	  <description><![CDATA[
	     In this blog post we will concern ourselves with unit testing of
classic 3-layer business applications. We will assume that
all business logic lives in services and components,
that these services operate on entities that are stored and retrieved
from relational database, 
and that these entities doesn't contain any logic.
Moreover we assume usage of 
DTO ([Data Transfer Object](https://en.wikipedia.org/wiki/Data_transfer_object))
to pass data between GUI and application services.

![High level overview of 3-layer architecture](assets/images/2017-02-19/L3arch.svg)

[Dependency Injection](https://en.wikipedia.org/wiki/Dependency_injection)
is indispensable when it comes to unit testing of
modern business applications. Without DI you are forced to write slow
and difficult to maintain integration tests instead of unit tests.
If you don't know what DI
is or if you don't used it before please read articles on [Wikipedia](https://en.wikipedia.org/wiki/Dependency_injection) and [Martin Fowler site](https://martinfowler.com/articles/injection.html),
and return here after you are comfortable with both idea and usage of DI.

Now when we are ready to start, we will follow Confucius advice:

> By three methods we may learn wisdom: First, by reflection, which is noblest;
> Second, by imitation, which is easiest; 
> and third by experience, which is the bitterest.
>
> Confucius

and learn by imitation,
by observing how we may unit test `UserService` component.
We will use popular [JUnit](http://junit.org/junit4/) unit testing framework
with [Mockito](http://site.mockito.org/) mocking library.

#### `UserService` component

`UserService` implements following business requirements:

* Users forgot their passwords from time to time, application should
 provide a way to reset forgotten passwords.
* To reset their passwords users must provide email address they use
 to login to our system.
* If provided email address does not belong to any user, application 
 should do nothing. Otherwise application should generate unique
 password reset token and send
 to provided email address message with link to reset password form.
 Link should contain reset password token.
 In both cases application should show to user success message.
* Password reset tokens should be unique. Tokens should be hard to
 guess or enumerate (no numbers here). Token may be used only once
 to reset password. If we want to reset password again we need a new token.
 Token is valid for 24 hours starting from the date it was created, after 24
 hours token cannot be used to change password.
* When user open reset password link in her browser it should be presented
 with a form that allows to enter a new password. After clicking OK,
 application should validate token used in link, and if it is still
 valid application should change user password and make token invalid.
 Then application should send password change confirmation message to user.
 In case of expired token application should show warning to user.

![Password change flow](assets/images/2017-02-19/flow.svg)

WARNING Before implementing real password reset feature please read
[Everything you ever wanted to know about building a secure password reset feature](https://www.troyhunt.com/everything-you-ever-wanted-to-know/).

Now when we understand business requirements we may attempt to implement
`UserService` component:
{% highlight java %}
public class UserServiceImpl implements UserService {
    private final UserRepository userRepository;
    private final NotificationService notificationService;
    private final DateTimeProvider dateTimeProvider;
    private final CryptoService cryptoService;

    public UserServiceImpl(
		UserRepository userRepository,
		DateTimeProvider dateTimeProvider,
		CryptoService cryptoService,
		NotificationService notificationService)
    {
        this.userRepository = requireNonNull(userRepository);
        this.notificationService = requireNonNull(notificationService);
        this.dateTimeProvider = requireNonNull(dateTimeProvider);
        this.cryptoService = requireNonNull(cryptoService);
    }

    @Override
    public void startResetPasswordProcess(String userEmailAddress) {
        User user = userRepository.findByEmailAddress(userEmailAddress);
        if (user == null)
            return;

        UUID token = UUID.randomUUID();
        LocalDateTime tokenValidityEndDate =
                dateTimeProvider.now().plusDays(1);

        user.setResetPasswordToken(token);
        user.setResetPasswordTokenValidityEndDate(
                tokenValidityEndDate);

        ResetPasswordNotificationData notificationData = 
            new ResetPasswordNotificationData(
                user.getEmail(),
                token,
                tokenValidityEndDate);

        notificationService
            .sendResetPasswordNotification(notificationData);
    }

    @Override
    public void finishResetPasswordProcess(
            String userEmailAddress,
            String newPassword,
            UUID resetPasswordToken)
    {
        User user = userRepository.findByEmailAddress(userEmailAddress);
        if (user == null)
            return;

        if (user.getResetPasswordToken() == null)
            return;

        if (!user.getResetPasswordToken().equals(resetPasswordToken))
            return;

        if (user.getResetPasswordTokenValidityEndDate()
                .isBefore(dateTimeProvider.now()))
            return;

        user.setResetPasswordToken(null);
        user.setResetPasswordTokenValidityEndDate(null);

        String newPasswordHash = cryptoService.sha1(newPassword);
        user.setPasswordHash(newPasswordHash);

        notificationService
            .sendPasswordChangedConfirmation(user.getEmail());
    }
}
{% endhighlight %}
`UserService` operates on the following `User` entity:
{% highlight java %}
public class User {
    private Long id;
    
    private String email;
    private String passwordHash;
    
    private UUID resetPasswordToken;
    private LocalDateTime resetPasswordTokenValidityEndDate;
    
    // getter, setter, etc.
}
{% endhighlight %}
And requires four other components to work, namely: `UserRepository`,
`NotificationService`, `DateTimeProvider` and `CryptoService`:
{% highlight java %}
public interface UserRepository {
    User findByEmailAddress(String emailAddress);
}
    
public interface NotificationService {
    void sendResetPasswordNotification(
            ResetPasswordNotificationData data);
    void sendPasswordChangedConfirmation(String email);
}
    
public interface DateTimeProvider {
    LocalDateTime now();
}
    
public interface CryptoService {
    String sha1(String input);
}
{% endhighlight %}
`DateTimeProvider` dependency was introduced solely for the purpose
of easier unit testing, as we will find out later.

Design of `UserService` follows principles of DI, component advertises
all dependencies it needs as constructor parameters.
DI containers may then use [constructor based dependency injection](https://www.tutorialspoint.com/spring/constructor_based_dependency_injection.htm) to
provide implementations of these dependencies.
Right now we have only implemented `UserService`, `UserRepository` and
other dependencies are not implemented yet.
Nevertheless with usage of stubs and
mocks we may test `UserService` implementation right now.

#### Writing tests for `startResetPasswordProcess`

By convention we should put tests for `ComponentName` into `ComponentNameTest`
class. For example tests for `UserServiceImpl` should be put 
into `UserServiceImplTest` class.

When you use Maven you should put your test class in 
the same package that contains tested component.
For example `UserServiceImpl`
is part of `io.mc.letsmock.demo` package, so `UserServiceImplTest`
should also belong to `io.mc.letsmock.demo` package.
With Maven the only difference between application code and test code is the
directory in which code resides. Application code will be in `src/main/java`
directory and test code will be in `src/test/java` directory:
{% highlight no-highlight %}
.
`-- src
    |-- main
    |   `-- java
    |       `-- io
    |           `-- mc
    |               `-- letsmock
    |                   `-- demo
    |                       |-- UserServiceImpl.java
    |                       `-- UserService.java
    `-- test
        `-- java
            `-- io
                `-- mc
                    `-- letsmock
                        `-- demo
                            `-- UserServiceImplTest.java
{% endhighlight %}
Another popular
convention used with e.g. Ant is to put applicaiton code into
`mycompany.productA.xx.yy` package and test code
into `mycompany.productA.test.xx.yy` package.

The important thing here is that team should choose one particular convention
how to name tests and where to put test classes and stick to it.
If you use Maven I strongly encourage using conventions that I described above.

##### Naming tests

After reading requirements we come to conclusion that we need the following
test cases to be sure that `startResetPasswordProcess` method works:

* When we couldn't find `User` with specified email address, component should
 do not nothing, in particular is should not crash
* When there is `User` with specified email address, component should set
 `resetPasswordToken` and `resetPasswordTokenValidityEndDate` fields on `User`
 instance to respectively 
 newly generated token, and `LocalDateTime` instance that represent point
 in time 24 hours later than now.
* When there is `User` with specified email address, component should send
 message with token to user using `NotificationService`.

Notice that each of these test cases test only single thing, this is
very important if we want to have clean and independent tests.
As method should do only one thing, 
test should test only one "outcome" of a method.
When you gain more experience you may want to relax this rule, 
but if you just started unit testing
you should stick with it for some time.

There are two schools when it comes to naming test methods, first
school teaches that test name should consists of three parts:
{% highlight java %}
@Test
void scenario_conditions_outcome()
{% endhighlight %}
`scenario` is the thing that we want to test, this in most cases
will be the name of the method that we want to test.
`conditions` describe the state of program that tested method
may expect when it is called. `outcome` is the state of the program
that we expect after tested method returns.

To give you a feeling how this naming scheme works here
are some dummy tests for Java `+` operator:
{% highlight java %}
void plusOperator_given1And5_returns6()
void plusOperator_given1AndMinus7_returnsMinus6()
void plusOperator_whenResultIsGreaterThanMAXINT_wrapsResultsUsingMod2Arithmetic()
{% endhighlight %}

The second school took inspiration for thier naming scheme from 
[BDD](https://en.wikipedia.org/wiki/Behavior-driven_development)
movement.
This school advices that 
test names should consists of full sentences that describe both
conditions and outcome of tested method. 
Names for `+` operator tests following this
scheme looks like:
{% highlight java %}
void _1_plus_5_should_return_6()
void _1_plus_minus_7_should_return_minus_6()
void when_result_of_addition_is_greater_than_MAXINT_plus_operator_should_wrap_result_using_mod_2_arithmetic()
{% endhighlight %}
As you can see test names generated using this approach 
can be quite verbose at times. Verbosity of this schema is it great advantage 
because the main purpose of test name is to tell you
what exactly is not working when given test fails. 

I prefer first school with scenario/conditions/outcome division of test name,
so I will use it exclusively in the rest of this post.

Returning to `startResetPasswordProcess` we should create three tests:
{% highlight java %}
void startResetPasswordProcess_givenEmailNotBelongingToAnyUser_doesNothing()
void startResetPasswordProcess_givenEmailOfExistingUser_generatesToken()
void startResetPasswordProcess_givenEmailOfExistingUser_sendsNotificationToUser()
{% endhighlight %}
These test names are not as descriptive as they may be, but are close
to what you may expect in average enterprise application.

##### Anatomy of test method

Our first test will check that `startResetPasswordProcess` won't throw
exceptions when called with email address of non-existing user.
But to test `UserServiceImpl` class we must create it's instance and this
will require providing all necessary dependencies.
Fortunately we may use Mockito library to 
to generate 
dummy implementations of `UserRepository`, `NotificationService` 
and others. By default these dummy implementations do nothing and
are similar to handcrafted test stubs like:
{% highlight java %}
public class UserRepositoryStub implements UserRepository {
    @Override
    public User findByEmailAddress(String emailAddress) {
        return null;
    }
}
{% endhighlight %}
But we will soon see that we can instruct Mockito to return
values from these stubs or to check if a given method was called
on dummy object.

Below you can see our first test code:
{% highlight java %}
@Test
public void startResetPasswordProcess_givenEmailNotBelongingToAnyUser_doesNothing() {
   // arrange
   UserRepository userRepository = mock(UserRepository.class);
   DateTimeProvider dateTimeProvider = mock(DateTimeProvider.class);
   CryptoService cryptoService = mock(CryptoService.class);
   NotificationService notificationService = mock(NotificationService.class);

   when(userRepository.findByEmailAddress("unknown@example.com"))
	   .thenReturn(null);

   UserServiceImpl userService = new UserServiceImpl(
	   userRepository,
	   dateTimeProvider,
	   cryptoService,
	   notificationService);
   // act
   userService.startResetPasswordProcess("unknown@example.com");

   // assert
   verify(notificationService, never())
	   .sendResetPasswordNotification(any());

   verify(notificationService, never())
	   .sendPasswordChangedConfirmation(anyString());
}
{% endhighlight %}
Before we dig into details let's look at this test from high level
point of view. Almost every test method can be divided into three
parts called Arrange-Act-Assert or Given-When-Then. I used comments
to signify when each of these parts start. Each of these parts has
different purpose. In Arrange part we must create instance of
tested component and all necessary test data and
also we must set up Mockito mocks.
If we may compare test method to theater play, then Arrange is like 
preparing scene, costumes and lights.

The first four lines of our test Arrange section are responsible for
creating dummy implementations of `UserServiceImpl` dependencies:
{% highlight java %}
UserRepository userRepository = mock(UserRepository.class);
DateTimeProvider dateTimeProvider = mock(DateTimeProvider.class);
CryptoService cryptoService = mock(CryptoService.class);
NotificationService notificationService = mock(NotificationService.class);
{% endhighlight %}
Then we set up one of our stub objects:
{% highlight java %}
when(userRepository.findByEmailAddress("unknown@example.com"))
	.thenReturn(null);
{% endhighlight %}
Here we instruct Mockito that dummy implementation generated for 
`UserRepository::findByEmailAddress`
should return `null` when called with `"unknown@example.com"` string.
But to be honest these lines are redundant because
method stubs generated by Mockito by default return `null` for
reference types, default values for primitives and empty collections
for methods returning collections. 
Still I leave them because they 
make purpose of our test more evident.

After Arrange section we have an Act section. Again (so many AAAAs)
returning to our theater play analogy (another A, no pun intended)
Act section is like the actual play, we invoke tested component and let
the code be alive. Act part is usually very short, in most cases
it consists of single line of code:
{% highlight java %}
userService.startResetPasswordProcess("unknown@example.com");
{% endhighlight %}

The last section in the test method is Assert when we want to
check results produced by tested code. In our test we check two
assumptions:

1. Invocation of `startResetPasswordProcess` does not throw any exceptions.
 This is tested implicitly by JUnit - test fails when test method throwns
 exception. Since our test passes we are certain that `startResetPasswordProcess`
 doesn't throw any.
2. We want to be certain that no notification was send to provided email address
 so we asses with the help of Mockit that none of the methods on `NotificationService`
 was called.

Mockito verification syntax is a bit unintuitive, so let's take a closer
look at one of our assertions:
{% highlight java %}
verify(notificationService, never())
	   .sendResetPasswordNotification(any());
{% endhighlight %}
We use `verify` to tell Mockit that we want to preform verification.
`never()` means that we expect that method was not called on dummy object.
Then we specify method that should not be called,
in our case `sendResetPasswordNotification`. 
We pass `any()` as method parameter to tell Mockito that method
should just not be called, and that we don't care about parameters
that was passed to it. Mockito is quite flexible here
and we may for example verify that method should not be called with given
set of parameters but must be called with another. We may also replace
`never()` with one of several predicates like e.g. `times(2)` to assert that
method was called twice.

#### Testing with assertions

Our first test assured us that `startResetPasswordProcess` works correctly
with email address of unknown user. Now it is time to check if
it also works correctly given email addresses of existing user.
Our second test will check if given valid email address `UserServiceImpl`
generates a new token for `User` and sets it expiry date correctly.
We also will check that user password is not altered in any way by
starting reset password process (it should change only when we *finish*
password change process).
Here is our second test code:
{% highlight java %}
@Test
public void startResetPasswordProcess_givenEmailOfExistingUser_generatesToken() {
   // arrange
   UserRepository userRepository = mock(UserRepository.class);
   DateTimeProvider dateTimeProvider = mock(DateTimeProvider.class);
   CryptoService cryptoService = mock(CryptoService.class);
   NotificationService notificationService = mock(NotificationService.class);

   UserServiceImpl userService = new UserServiceImpl(
	   userRepository,
	   dateTimeProvider,
	   cryptoService,
	   notificationService);

   User joe = new User();
   joe.setEmail("joe@example.com");
   joe.setResetPasswordToken(null);
   joe.setResetPasswordTokenValidityEndDate(null);
   joe.setPasswordHash("old-password-hash");

   when(userRepository.findByEmailAddress("joe@example.com"))
	   .thenReturn(joe);

   when(dateTimeProvider.now())
	   .thenReturn(LocalDateTime.of(2017,3,10, 0,0));

   // act
   userService.startResetPasswordProcess("joe@example.com");

   // assert
   assertThat(joe.getResetPasswordToken())
	   .isNotNull();

   assertThat(joe.getResetPasswordTokenValidityEndDate())
	   .isEqualTo(LocalDateTime.of(2017,3,11, 0,0));

   assertThat(joe.getPasswordHash())
	   .withFailMessage("Password should not be changed")
	   .isEqualTo("old-password-hash");
}
{% endhighlight %}
Arrange section of our second test does not differ much from Arrange
section of our first test, except that we added code for creation
of an `User` instance. Notice that we populate `User` with carefully 
chosen data that will allow us to test `startResetPasswordProcess`
implementation easily e.g. we set both `resetPasswordToken` and
`resetPasswordTokenValidityEndDate` to `null`.
Then we instruct Mockito to return our `User` instance when we
ask `UserRepository` for user with `joe@example.com` email address:
{% highlight java %}
when(userRepository.findByEmailAddress("joe@example.com"))
	.thenReturn(joe);
{% endhighlight %}

We should strive to make our unit tests as much deterministic as possible.
Unit test that sometimes fails without a reason is burden rather than
a benefit, and should be either fixed or removed.
To make unit more robust we should avoid depending on external input
like information about current time. To facilitate that I decided to
introduce `DateTimeProvider` component with sole purpose of making
unit tests more predictable. With small help of Mockito we are now
masters of time:
{% highlight java %}
when(dateTimeProvider.now())
	.thenReturn(LocalDateTime.of(2017,3,10, 0,0));
{% endhighlight %}

After all this preparations, we are now free to invoke `startResetPasswordProcess`
and check it's outcome. In unit tests we mainly use assertions to check
correctness of tested code. JUnit already comes with handy assertion library
that we may use like this:
{% highlight java %}
import static org.junit.Assert.*;

assertNotNull(joe.getResetPasswordToken());
assertEquals("old-password-hash", joe.getPasswordHash());
{% endhighlight %} 
When JUnit assertion fails it throws `AssertionError`, test fails and
we get error similar to:
{% highlight java %}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertNotNull(Assert.java:712)
	at org.junit.Assert.assertNotNull(Assert.java:722)
	at io.mc.letsmock.demo.UserServiceImplTest.startResetPasswordProcess_givenEmailOfExistingUser_generatesToken(UserServiceImplTest.java:113)
{% endhighlight %}
Unfortunately error messages generated by JUnit assertions are not
always the best way to find out what went wrong with failing tests.
JUnit assertions are also cumbersome to use at times. From these
and other reasons I prefer to use assertions from assertJ library
and I used them when I wrote our second test:
{% highlight java %}
import static org.assertj.core.api.Assertions.assertThat;

assertThat(joe.getResetPasswordToken())
	.isNotNull();

assertThat(joe.getResetPasswordTokenValidityEndDate())
	.isEqualTo(LocalDateTime.of(2017,3,11, 0,0));

assertThat(joe.getPasswordHash())
	.withFailMessage("Password should not be changed")
	.isEqualTo("old-password-hash");
{% endhighlight %}
Here we check three things:

1. New password reset token was generated and assigned to `resetPasswordToken`
 property
2. Expiry date of password reset token was set correctly (token should be
 valid for the next 24 hours)
3. Current user password was not changed

Notice also that we use `withFailMessage` to provide additional
information in case our third assertion fails.
Without `withFailMessage` we would get following error:
{% highlight no-highlight %}
org.junit.ComparisonFailure: 
Expected :"old-password-hash"
Actual   :"xxx"
{% endhighlight %}
With `withFailMessage` we get:
{% highlight no-highlight %}
java.lang.AssertionError: Password should not be changed
{% endhighlight %}

#### Merciless refactoring

Right now both of our tests pass, but we see a lot of code duplication
between them. Now it is a good time to extract common parts of both
tests into `setUp` method and to create some fields in our test class:
{% highlight java %}
public class UserServiceImplTestAfterRefactoring {
    private UserRepository userRepository;
    private DateTimeProvider dateTimeProvider;
    private CryptoService cryptoService;
    private NotificationService notificationService;

    private UserServiceImpl userService;

    @Before
    public void setUp() {
        userRepository = mock(UserRepository.class);
        dateTimeProvider = mock(DateTimeProvider.class);
        cryptoService = mock(CryptoService.class);
        notificationService = mock(NotificationService.class);

        userService = new UserServiceImpl(
                userRepository,
                dateTimeProvider,
                cryptoService,
                notificationService);
    }

    @Test
    public void startResetPasswordProcess_givenEmailNotBelongingToAnyUser_doesNothing() {
        // arrange
        when(userRepository.findByEmailAddress("unknown@example.com"))
                .thenReturn(null);

        // act
        userService.startResetPasswordProcess("unknown@example.com");

        // assert
        verify(notificationService, never())
                .sendResetPasswordNotification(any());

        verify(notificationService, never())
                .sendPasswordChangedConfirmation(anyString());
    }

    @Test
    public void startResetPasswordProcess_givenEmailOfExistingUser_generatesToken() {
        // arrange
        User joe = Fixtures.userJoe();

        when(userRepository.findByEmailAddress("joe@example.com"))
                .thenReturn(joe);

        when(dateTimeProvider.now())
                .thenReturn(LocalDateTime.of(2017,3,10, 0,0));

        // act
        userService.startResetPasswordProcess("joe@example.com");

        // assert
        assertThat(joe.getResetPasswordToken())
                .isNotNull();

        assertThat(joe.getResetPasswordTokenValidityEndDate())
                .isEqualTo(LocalDateTime.of(2017,3,11, 0,0));

        assertThat(joe.getPasswordHash())
                .withFailMessage("Password should not be changed")
                .isEqualTo("old-password-hash");
    }
}
{% endhighlight %}
After refactoring both dependencies and tested components are
now stored in fields of test class. 
JUnit calls any method annotated by `@Before` before executing each
of test methods contained in test class. 
This makes `setUp` method suitable place to initialize fields
that will be used by many tests. 

Now you may be tempted to move initialization code to the test class
constructor, but don't do that. Unit tests should be independent of
each other. One of the worst sins when writing unit tests is to write
a test that depends on some data created by other test methods. 
Such incorrect test may pass when we ran all tests but will
fail when run it alone. This is one of the worst things that may happen
when writing unit tests, and clearly shows that we do something wrong.
Instead every test should create it's own test data and should use 
fresh Mockito stubs. Later you will appreciate this independence of
tests when you will try to run tests in parallel.

Unit tests often require some dummy data, instead of creating the
same object again and again in various tests we should group them
into library of test objects. Such library of test data is often called
a fixture. Since I expected that we will need `User` instance in other
test, I extracted code that created dummy user into `Fixtures` class:
{% highlight java %}
public class Fixtures {
   public static User userJoe() {
	  User joe = new User();

	  joe.setEmail("joe@example.com");
	  joe.setPasswordHash("old-password-hash");
	  joe.setResetPasswordToken(null);
	  joe.setResetPasswordTokenValidityEndDate(null);

	  return joe;
   }
}
{% endhighlight %}

##### Terminology

When reading about unit testing you may encounter terms *fake*, *mock* and *stub*.
Fake is any object that is used only by test code, fake may be implemented as
concrete class like `UserRepositoryStub` or as anonymous class generated at runtime.
In this last category we find all dummy implementations generated by Mockito.

Fakes can be divided into two groups stubs and mocks. Form practical point of
view we use mock to test interactions, and stubs to provide dummy data or
do-nothing implementation. We used `NotificationService` as a mock in our first
test because we used it to assert that no interaction took place (no message was
send to user). On the other hand all dummy implementations generated
by Mockito for `UserRepository`, `DateTimeProvider` etc. are examples of stubs.

More information about difference between mocks and stubs
can be found in Martin Fowler article
[Mocks aren't stubs](https://www.martinfowler.com/articles/mocksArentStubs.html).

##### Code coverage

When unit testing it is important to test all execution paths in our code.
Sometimes we may be convinced that we covered all corner cases only to
find out (usually in production) that we overlooked testing some obscure conditions.
In such situation after fixing bug, we should add missing test.
But we could do better, almost any popular Java IDE can measure
and show us code coverage of tested component. IDE can usually highlight
in red lines that were not tested, for example here how it looks like in IntelliJ:
![Code coverage in IntelliJ](assets/images/2017-02-19/code_cov.png)
Greenish bar next to line number tells us that line of code was *executed*
when running unit tests (being executed doesn't automatically mean that
the line of code is well tested, it is only a heuristic). On the other hand 
red bar tells that lines of code was not reached by tests and certainly is not tested.

When we are at it, you may heard that the higher code coverage the better.
Having 100% code coverage is impossible in any reasonable sized enterprise application.
There is an ongoing debate about how much code coverage is enough.
For me code coverage is just a tool that I use to check that I tested
all execution paths in code and nothing more.

##### It's your turn now

Right now we have only two tests for our `UserServiceImpl` component,
of course it is not enough to assure us that all of the business requirements
were fulfilled. When I tested `UserServiceImpl` I wrote seven more tests:

* `startResetPasswordProcess_givenEmailOfExistingUser_sendsNotificationToUser`
* `finishResetPasswordProcess_noUserHasSpecifiedEmail_doesNothing`
* `finishResetPasswordProcess_userHasNoTokenSet_doesNothing`
* `finishResetPasswordProcess_tokenExpired_doesNothing`
* `finishResetPasswordProcess_tokenNotMatch_doesNothing`
* `finishResetPasswordProcess_validToken_changesPassword`
* `finishResetPasswordProcess_validToken_sendsConfirmationToUser`

and only now I am certain that `UserServiceImpl` works correctly.

You may find source code for all these tests (with other goodies)
[HERE](https://github.com/marcin-chwedczuk/mockito-unit-test-demo).
But before you look at what I wrote, please try to implement these tests
yourself and then compare your code with mine. I am certain that you will
learn more this way.

Thanks for reading. If you liked this post please start my Github repository.
And see you soon again!


	  ]]></description>
	</item>

	<item>
	  <title>Hello, Hibernate Validator</title>
	  <link>//hello-hibernate-validator</link>
	  <author></author>
	  <pubDate>2017-02-05T01:00:00+01:00</pubDate>
	  <guid>//hello-hibernate-validator</guid>
	  <description><![CDATA[
	     In every enterprise application there is a need for
validation. You may want to validate data send by user to
your REST service, messages coming to your application from some
other system, or your own entities before saving them to database.

Standard
[JSR 303](http://beanvalidation.org/1.0/spec)
defines API for validating Java Beans without tying us to any
particular implementation.
Nevertheless some implementations are more polished than others,
and subject of this post -
Hibernate Validator is considered one of the best.

#### Project setup

Before we can use Hibernate Validator we must do
some groundwork.

##### Maven dependencies

To use Hibernate Validator we need following Maven dependencies:
{% highlight xml %}
<dependency>
    <groupId>org.hibernate</groupId>
    <artifactId>hibernate-validator</artifactId>
    <version>5.3.4.Final</version>
</dependency>

<dependency>
    <groupId>javax.el</groupId>
    <artifactId>el-api</artifactId>
    <version>2.2</version>
</dependency>
<dependency>
    <groupId>org.glassfish.web</groupId>
    <artifactId>javax.el</artifactId>
    <version>RELEASE</version>
</dependency>
{% endhighlight %}
Hibernate Validator uses Java Unified Expression Language (JavaEL)
to format validation messages. When your application runs
inside JEE container, container already provides JavaEL 
implementation.
Since we want to create a command line application we must provide 
JavaEL implementation ourselves and that's the reason
why we included `javax.el:el-api` and `org.glassfish.web:javax.el` as
dependencies.

Later on to demonstrate all features of Hibernate Validator we will need
Spring DI container and `commons-beanutils` library:
{% highlight xml %}
<dependency>
    <groupId>commons-beanutils</groupId>
    <artifactId>commons-beanutils</artifactId>
    <version>1.9.3</version>
</dependency>
<dependency>
    <groupId>org.springframework</groupId>
    <artifactId>spring-context</artifactId>
    <version>4.3.5.RELEASE</version>
</dependency>
{% endhighlight %}

##### Obtaining `Validator` instance

After all these preparations we are ready to create `Validator`
instance:
{% highlight java %}
import javax.validation.Validation;
import javax.validation.Validator;

public static void main(String[] args) {
    Validator validator = Validation
                              .buildDefaultValidatorFactory()
                              .getValidator();
}
{% endhighlight %}
Note that we don't have any reference to Hibernate Validator in
our code, instead we are relying on classes and interfaces defined in
JSR 303 (Bean Validation).
This is very similar to how JDBC providers works.

Returned `Validator` instance is thread safe and may be assigned to
static field or registered as a singleton in DI container for later use.

#### Validating beans

##### Property level constraints

The easiest way to define validation rules for a bean
is to use JSR 303 annotations.
We may put annotations on both fields and getters, for example:
{% highlight java %}
public class Person {
    @NotNull           
    private String name;
}
// or:
public class Person {
    @NotNull
    public String getName() {             
        return name;                      
    }                                     
    public void setName(String name) {    
        this.name = name;                 
    }                                     
}
{% endhighlight %}
We should prefer putting annotations on getters since this will
allow for greater flexibility when later we will want to
change our beans.
Said that, to conserve space in this post I will
put annotations on fields from now on.

Here is a simple bean representing a person,
annotated with JSR 303 constraints:
{% highlight java %}
public class Person {
    @NotNull
    @Length(min=1)
    private String name;

    @NotNull
    @Length(min=1)
    private String surname;

    @Range(min=1, max=200)
    private int age;
  
    // getters, setters 
}
{% endhighlight %}
Validation rules should be self evident. There is nothing fancy -
we check that a person must have a non empty name and a non empty
surname, and that an age of a person falls within a range of 1 and 200.

Then we may use Hibernate Validator to check if 
a `Person` instance is valid:
{% highlight java %}
Validator validator = Validation
       .buildDefaultValidatorFactory()
       .getValidator();

Person joe = new Person();
joe.setName("Joe");
joe.setSurname("Doe");
joe.setAge(43);

Set<ConstraintViolation<Person>> constraintViolations =
       validator.validate(joe);

assert constraintViolations.size() == 0; // yeah, no errors
{% endhighlight %}

In rare cases when `Person` is invalid, Hibernate Validator
provides us with all necessary information about what
properties and values are wrong:
{% highlight java %}
Person joe = new Person();
joe.setName(null);
joe.setSurname("Doe");
joe.setAge(1024);

Set<ConstraintViolation<Person>> constraintViolations =
       validator.validate(joe);

for (ConstraintViolation<?> violation: constraintViolations) {
   System.out.format("%10s | %30s | is %10s%n",
           violation.getPropertyPath(),
           violation.getMessage(),
           violation.getInvalidValue()
           );
}
// OUTPUT:
//       age |      must be between 1 and 200 | is       1024
//      name |                may not be null | is       null
{% endhighlight %}

##### Bean level constraints

Some validation rules may be expressed only by using
values of two or more properties, for such rules 
Hibernate Validator provides class-level constrains.
Returning to our `Person` example, suppose that we want to add
two new properties to `Person`: `dateOfBirth` and `dateOfDeath`, with
condition that `dateOfBirth` cannot be later than `dateOfDeath`
(when both dates are present):
{% highlight java %}
public class Person {
    @NotNull
    private LocalDate dateOfBirth;
    private LocalDate dateOfDeath;
    
    // ...
}
{% endhighlight %}
We can express our rule using proprietary (not included in JSR 303)
class-level `@ScriptAssert` annotation:
{% highlight java %}
import org.hibernate.validator.constraints.ScriptAssert;

@ScriptAssert(lang = "javascript",
        script="_.dateOfBirth == null || _.dateOfDeath == null || _.dateOfBirth <= _.dateOfDeath",
        alias="_",
        message = "date of death cannot be before date of birth")
public class Person {
   // ...
} 
{% endhighlight %}
Here I decided to use JavaScript scripting engine (`lang = "javascript"`)
because it
is already shipped with Java SE, moreover JavaScript syntax should be
familiar to any Java developer. Hibernate Validator supports
any implementation adhering to JSR 223 standard
(scripting for the Java platform).

JavaScript expression used as value of `script` argument:
{% highlight javascript %}
_.dateOfBirth == null || 
   _.dateOfDeath == null || 
   _.dateOfBirth <= _.dateOfDeath
{% endhighlight %}
must *always* return either `true` when validation rule is
fullfiled or `false`.
We must also take care of handling `null` values otherwise we may
get pesky `javax.script.ScriptException`.

Inside `script` we may refer to currently validated bean by name of `_this`,
or by name of our choosing if we set `alias` argument like we do in
our example.

`@ScriptAssert` is a duct tape of validation. You should
use it only when performance is not a concern, and you must
provide a solution quickly. In most cases you should prefer
to write you own constraint and validator. Anyway `@ScriptAssert` is
a great example of class-level constraint.

##### Validating child beans

To demonstrate parent-child bean validation we will
add `Address` to `Person` class.
`Address` will be optional so not every `Person` instance will have one,
we only require that if a `Person` has an address it must be a
valid one.
`Address` will be represented by the following bean:
{% highlight java %}
public class Address {
    @NotBlank
    private String street;

    @NotBlank
    private String zipCode;

    @NotBlank
    private String city;

    // getter,setters
}
{% endhighlight %}
Also we must add `address` property to `Person` bean:
{% highlight java %}
public class Person {
    @Valid
    private Address address;
}
{% endhighlight %}
`@Valid` annotation that we put on `address` field
tells Hibernate Validator that
when validating a `Person` the `Address` should also be
validated, but only when address is provided (`address` is non null).
If we require that a `Person` must always have an address we may use
`@NotNull` to enforce that rule:
{% highlight java %}
public class Person {
    @NotNull
    @Valid
    private Address address;
}
{% endhighlight %}

Now when validating person with an invalid address we get:
{% highlight java %}
// ...
Address joeHomeAddress = new Address();
joeHomeAddress.setCity("Warsaw");
joeHomeAddress.setZipCode("00-120");
joe.setAddress(joeHomeAddress);

validator.validate(joe);
// CONSTRAINT VIOLATIONS:
// address.street |               may not be empty | is       null
{% endhighlight %}

##### Validating collections

To demonstrate how collection validation works
we will add a list of contacts
to `Person` bean:
{% highlight java %}
public class Person {
    @Valid
    private List<Contact> contacts;
    // getters,setters,...
}

public abstract class Contact { }

public class EmailContact extends Contact {
    @Email
    private String email;

    public EmailContact() { }
    public EmailContact(String email) {
        this.email = email;
    }

    public String getEmail() { return email; }
    public void setEmail(String email) { this.email = email; }
}

public class PhoneContact extends Contact {
    @Pattern(regexp = "\\d{3}-\\d{3}-\\d{3}",
             message = "invalid phone number")
    private String phoneNumber;

    public PhoneContact() { }
    public PhoneContact(String phoneNumber) {
        this.phoneNumber = phoneNumber;
    }

    public String getPhoneNumber() { return phoneNumber; }
    public void setPhoneNumber(String phoneNumber) { this.phoneNumber = phoneNumber; }
}
{% endhighlight %}
Again we used `@Valid` annotation to tell Hibernate Validator to
validate all non null beans contained in `contacts` collection.
Now we may check if all `Person` contacts are valid:
{% highlight java %}
joe.setContacts(Arrays.asList(
    new EmailContact("joe@example.com"),
    new PhoneContact("123-123-123"),
    new EmailContact("invalid_email"),
    new PhoneContact("invali_phone")
));

validator.validate(joe);
// CONSTRAINT VIOLATIONS:
// contacts[3].phoneNumber |           invalid phone number  | is invali_phone
// contacts[2].email       | not a well-formed email address | is invalid_email
{% endhighlight %}

Unfortunately there is no build-in annotation that would protect
us from collections containing `null`s:
{% highlight java %}
joe.setContacts(Collections.singletonList(null));
assert validator.validate(joe).size() == 0;
{% endhighlight %}
To fix that problem we must write a custom constraint ourselves.

##### Customizing validation messages

The easiest way to customize validation message is to
set it explicitly via 
`message` parameter:
{% highlight java %}
@Range(min=1, max=200, 
    message = "person age must be between 1 and 200 years")
private int age;
{% endhighlight %}
This approach is inflexible and you should avoid it, instead
try to load validation messages from application resources.
Hibernate Validator by default will load validation messages from
`resources/ValidationMessages.properties` file.
We may use this file to either add new validation message or
customize existing:
{% highlight no-highlight %}
# Override existing message
org.hibernate.validator.constraints.Range.message=${validatedValue} is not in range (min: {min}, max: {max})

# Create new message
invalid_person_age=person age must be between 1 and 200 years 
{% endhighlight %}
Then we may use are new message:
{% highlight java %}
@Range(min=1, max=200, message = "{invalid_person_age}")
private int age;
{% endhighlight %}

#### Extending Hibernate Validator

##### Constraint composition

Earlier we used the following code to validate phone number:
{% highlight java %}
@Pattern(regexp = "\\d{3}-\\d{3}-\\d{3}",
         message = "invalid phone number")
private String phoneNumber;
{% endhighlight %}
We certainly don't want to repeat this annotation with regex expression and
message accross all codebase, that would violate 
[DRY principle](https://en.wikipedia.org/wiki/Don't_repeat_yourself).
On the other hand the following code validated person name:
{% highlight java %}
@NotNull
@Length(min=1)
private String name;
{% endhighlight %}
Here we see that to validate name we need two constraints, again
repeating two constraints in various DTO's is not a receipt for
a good code.

To solve above problems JSR 303 introduces constraint composition.
In short you create a new constraint annotation and put
on it all required constraints, you may also adjust
message, payload and/or groups to which constraint belongs.
For example we may create `ValidPhoneNumber` constraint:
{% highlight java %}
@Pattern(regexp = "\\d{3}-\\d{3}-\\d{3}")
@ReportAsSingleViolation
@Constraint(validatedBy = { })
@Target({ METHOD, FIELD, ANNOTATION_TYPE })
@Retention(RUNTIME)
@Documented
public @interface ValidPhoneNumber {
    String message() default "phone number should be in format 999-999-999";
    Class<?>[] groups() default { };
    Class<? extends Payload>[] payload() default { };
}
{% endhighlight %}
And then use it accross our codebase:
{% highlight java %}
public class PhoneContact extends Contact {
    @ValidPhoneNumber
    private String phoneNumber;
    //...
}
{% endhighlight %}
Not only this adheres to DRY princible but our code
is now more readable.

When we put multiple constraints on composed constraint:
{% highlight java %}
@NotNull
@Length(min=1)
@Target({ METHOD, FIELD, ANNOTATION_TYPE })
@Retention(RUNTIME)
@Constraint(validatedBy = { })
@Documented
// @ReportAsSingleViolation
public @interface ValidPersonName {
    String message() default "person must have a name";
    Class<?>[] groups() default { };
    Class<? extends Payload>[] payload() default { };
}
{% endhighlight %}
And then use it on a field:
{% highlight java %}
@ValidPersonName
private String name;
{% endhighlight %}
Each of composing constrains will be reported independently:
{% highlight java %}
Person joe = new Person();
joe.setName("");
//       name | length must be between 1 and 2147483647 | is     

joe.setName(null);
//       name |                may not be null | is       null
{% endhighlight %}
We may add `@ReportAsSingleViolation` annotation to our
composed constrain to report all violations as a single error.
With `@ReportAsSingleViolation` we get:
{% highlight java %}
Person joe = new Person();
joe.setName("");
//       name |        person must have a name | is       
joe.setName(null);
//       name |        person must have a name | is       null
{% endhighlight %}
Notice that this time message was taken from composed constraint.

##### Using payloads

We may use payloads to pass some additional informations
with validation errors. Canonical example of using payloads is
to differentiate between errors and warnings.

First we must define our payload values:
{% highlight java %}
import javax.validation.Payload;

public interface SEVERITY {
    interface WARNING extends Payload { }
    interface ERROR extends Payload { }
}
{% endhighlight %}
Then we may use them with constraints:
{% highlight java %}
import io.mc.validationdemo.constraints.SEVERITY.ERROR;
import io.mc.validationdemo.constraints.SEVERITY.WARNING;
import org.hibernate.validator.constraints.NotBlank;

public class SeverityDTO {
    @NotBlank(payload = ERROR.class)
    public String important;
    
    @NotBlank(payload = WARNING.class)
    public String unimportant;

    // ...
}
{% endhighlight %}
Finally we may use them to decide if given `ConstraintViolation`
is warning or error:
{% highlight java %}
public static boolean isWarning(ConstraintViolation<?> violation) {
    boolean isWarning = violation.getConstraintDescriptor()
            .getPayload()
            .contains(SEVERITY.WARNING.class);

    return isWarning;
}
{% endhighlight %}

I am certain that you will find some creative usages of payloads
in you application.

##### Creating new constraints

To demonstrate how to create a new constraint,
we will create `@NotContain` validation rule that
checks that `String` doesn't contains specified value.

We will start by creating annotation (here it is best
to follow example from [official documentation](https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/#validator-customconstraints-constraintannotation)):
{% highlight java %}
@Target({FIELD, METHOD, ANNOTATION_TYPE})
@Retention(RUNTIME)
@Documented
@Constraint(validatedBy = NotContainValidator.class)
public @interface NotContain {
    String message() default "{validation.NotContain}";
    Class<?>[] groups() default { };
    Class<? extends Payload>[] payload() default { };
    String value();

    @Target({ FIELD, METHOD, ANNOTATION_TYPE })
    @Retention(RUNTIME)
    @Documented
    @interface List {
        NotContain[] value();
    }
}
{% endhighlight %}
Then we must implement `NotContainValidator`:
{% highlight java %}
public class NotContainValidator 
    implements ConstraintValidator<NotContain, String>
{
    private String bannedPhrase;
    public void initialize(NotContain constraintAnnotation) {
        bannedPhrase = constraintAnnotation.value();
    }

    public boolean isValid(String value, ConstraintValidatorContext context) {
        boolean isValid =
            value == null || !value.contains(bannedPhrase);
        return isValid;
    }
}
{% endhighlight %}
Then we should define our validation message
in `resources/ValidationMessages.properties` file, and we are done:
{% highlight java %}
public class Person {
    @ValidPersonName
    @NotContain("f**k")
    private String name;
    // ...
}

Person joe = new Person();
joe.setName("f**k");

validator.validate(joe);
// VIOLATED CONSTRAINTS:
// name | Property should not contain f**k | is       f**k
{% endhighlight %}

##### Value unwrappers

Sometimes we want to validate value that is contained in some other
type. For example we may want to validate a `String` contained
in `Optional<String>`.
This is possible in Hibernate Validator thanks to value unwrappers.

Hibernate Validator out of the box supports `Optional<T>` type, so
for a sake of example we will create our own "wrapper" type:
{% highlight java %}
public class Box<T> {
    private T value;

    public T getValue() {
        return value;
    }
    public void setValue(T value) {
        this.value = value;
    }
}
{% endhighlight %}
Now we may use our wapper type in DTOs:
{% highlight java %}
public class UnwrappingDTO {
    @Length(min=3,max=10)
    private Box<String> name;

    @Min(1)
    private Box<Long> age;

    // getters, setters 
}
{% endhighlight %}
If we try to validate `UnwrappingDTO` instance we will get
an exception:
{% highlight no-highlight %}
javax.validation.UnexpectedTypeException: HV000030: 
    No validator could be found for constraint 'Length' 
    validating type 'Box<String>'.
{% endhighlight %}
To make validation work again we must create are
own type unwrapper:
{% highlight java %}
public class BoxUnwrapper extends ValidatedValueUnwrapper<Box<?>> {
    @Override
    public Object handleValidatedValue(Box<?> property) {
        return property.getValue();
    }

    @Override
    public Type getValidatedValueType(Type type) {
        // return generic parameter T of Box<T>
        Class<?> clazz = (Class<?>)
                ((ParameterizedType)type).getActualTypeArguments()[0];

        return clazz;
    }
}
{% endhighlight %}
And register it in Hibernate Validatior framework:
{% highlight java %}
Validator validator = Validation.byProvider(HibernateValidator.class)
        .configure()
        .addValidatedValueHandler(new BoxUnwrapper())
        .buildValidatorFactory()
        .getValidator();
{% endhighlight %}
The last thing that we should do, is to annotate `Box<T>` properties with
`@UnwrapValidatedValue`:
{% highlight java %}
@Length(min=3,max=10)
@UnwrapValidatedValue
private Box<String> name;

@Min(1)
@UnwrapValidatedValue
private Box<Long> age;
{% endhighlight %}
And now we can validate `Box`ed values, yay!

##### Integrating Hibernate Validator with Spring DI

This section shows how to quickly integrate Hibernate Validator
with Spring. This is not the offical way of how you should integrate
with DI, just a quick and dirty solution that you may find helpful.
You have been warned. Also remember that Spring provides it's
own validation framework, fully complaint with JSR 303 and called
[Spring Validation](http://docs.spring.io/spring/docs/current/spring-framework-reference/html/validation.html#validation-beanvalidation).

First we must create validator factory and register it in Spring
and in Hibernate Validator framework:
{% highlight java %}
@Component
public class SpringConstrainValidationFactory 
implements ConstraintValidatorFactory {
    @Autowired
    private ApplicationContext context;

    @Override
    public <T extends ConstraintValidator<?, ?>> T getInstance(Class<T> key) {
        if (key.getPackage().getName().startsWith("javax.validation") ||
            key.getPackage().getName().startsWith("org.hibernate.validator"))
        {
            try {
                // create standard validators by calling
                // default constructor
                return key.newInstance();
            } catch (Exception ex) {
                throw new RuntimeException(ex);
            }
        }

        // Use Spring to create validator bean
        return context.getBean(key);
    }

    @Override
    public void releaseInstance(ConstraintValidator<?, ?> instance) {
        // DO NOTHING
    }
}
{% endhighlight %}
And in application configuration we should have:
{% highlight java %}
@Configuration
@ComponentScan("your.package.name")
public class AppConfig {
    @Bean
    public Validator getHibernateValidator(
        SpringConstrainValidationFactory factory)
    {
       Validator validatorEx = Validation.byProvider(HibernateValidator.class)
                .configure()
                .addValidatedValueHandler(new BoxUnwrapper())
                // register Spring based validator factory
                .constraintValidatorFactory(factory)
                .buildValidatorFactory()
                .getValidator();

       return validatorEx;
    }
}
{% endhighlight %}
Also do not forget to mark validators as `@Component`, now we may
use dependency injection inside validators.



	  ]]></description>
	</item>

	<item>
	  <title>Comparing with nullsFirst and nullsLast</title>
	  <link>//comparing-with-nullsFirst-and-nullsLast</link>
	  <author></author>
	  <pubDate>2017-01-14T01:00:00+01:00</pubDate>
	  <guid>//comparing-with-nullsFirst-and-nullsLast</guid>
	  <description><![CDATA[
	     Sorting in Java is easy:
{% highlight java %}
public class Data {
    private final String value;
    public Data(String value) {
        this.value = value;
    }
 
    public String getValue() { return value; }
 
    @Override public String toString() {
        return String.format("Data(%s)", this.value);
    }
}
 
public static void main(String[] args) {
   List<Data> listOfData = Arrays.asList(
          new Data("foo"),
          new Data("bar"),
          new Data("nyu"));
 
   listOfData.sort(comparing(Data::getValue));
   listOfData.forEach(System.out::println);
}
//OUTPUT:
// Data(bar)
// Data(foo)
// Data(nyu)
{% endhighlight %}
...unless we try to sort a collection containing null values:
{% highlight java %}
List<Data> listOfData = Arrays.asList(
       new Data("foo"),
       null,
       new Data("bar"),
       new Data("nyu"));
 
listOfData.sort(comparing(Data::getValue));
listOfData.forEach(System.out::println);
//OUTPUT:
// Exception in thread "main" java.lang.NullPointerException
//    at java.util.Comparator.lambda$comparing$77a9974f$1(Comparator.java:469)
{% endhighlight %}
Fortunately there is easy solution to this problem. But first we must
decide whenever we want `null`s to be first or last in sorted collection.
After we made our mind we may use nifty `nullsFirst` or `nullsLast`
decorators provided by `Comparator` interface:
{% highlight java %}
import static java.util.Comparator.*;
 
List<Data> listOfData = Arrays.asList(
       new Data("foo"),
       null,
       new Data("bar"),
       new Data("nyu"));
 
listOfData.sort(nullsFirst(comparing(Data::getValue)));
listOfData.forEach(System.out::println);
//OUTPUT:
// null
// Data(bar)
// Data(foo)
// Data(nyu)
{% endhighlight %}
`nullsFirst` is great example of decorator design pattern
(it adds functionality but doesn't change interface).
`nullsFirst` works by wrapping provided comparator in code similar to:
{% highlight java %}
public static <T> Comparator<T> nullsFirst(Comparator<T> comparator) {
  return (a, b) -> {
    if (a == null)
        return (b == null) ? 0 : -1;
 
    if (b == null)
      return 1;
 
    // a and b are not null here
    return comparator.compare(a, b);
  };
}
{% endhighlight %}

Previous example works great unless we try to sort a collection
containing `Data(null)`:
{% highlight java %}
List<Data> listOfData = Arrays.asList(
       new Data("foo"),
       new Data(null),
       new Data("bar"),
       new Data("nyu"));

listOfData.sort(nullsFirst(comparing(Data::getValue)));
listOfData.forEach(System.out::println);
//OUTPUT:
// Exception in thread "main" java.lang.NullPointerException
//  at java.util.Comparator.lambda$comparing$77a9974f$1(Comparator.java:469)
//  at java.util.Comparators$NullComparator.compare(Comparators.java:83)
{% endhighlight %}
But do not despair `nullsFirst` can help us again:
{% highlight java %}
listOfData.sort(nullsFirst(
    comparing(Data::getValue, nullsFirst(naturalOrder()))));

listOfData.forEach(System.out::println);
//OUTPUT:
// Data(null)
// Data(bar)
// Data(foo)
// Data(nyu)
{% endhighlight %}
Ta da! It works but readability suffers greatly... You may ask what is
this thing:
{% highlight java %}
comparing(Data::getValue, nullsFirst(naturalOrder()))
{% endhighlight %}
First: we use the following overload of `comparing` method:
{% highlight java %}
public static <T, U> Comparator<T> comparing(
   Function<? super T, ? extends U> keyExtractor,
   Comparator<? super U>            keyComparator)
{
    return (c1, c2) -> keyComparator.compare(
          keyExtractor.apply(c1),
          keyExtractor.apply(c2));
}
{% endhighlight %}
Second: in our example `nullsFirst(naturalOrder())` is a comparator that can
compare nullable `String`s:
{% highlight java %}
Comparator<String> cmp = nullsFirst(naturalOrder());
cmp.compare("foo", "zzz"); // -1
cmp.compare("foo", null);  // 1
{% endhighlight %}

Now everything should be clear (I hope).

To sum up in this post we get to know two
little methods `nullsFirst` and `nullsLast`.
I admit that they are a bit unintuitive to use, but definitely worth
to bear in mind.


	  ]]></description>
	</item>


</channel>
</rss>
