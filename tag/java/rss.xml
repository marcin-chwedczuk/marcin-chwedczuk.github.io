<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>marcin-chwedczuk.github.io/</title>
   
   <link>https://marcin-chwedczuk.github.io/</link>
   <description>A place where I can share my thoughts about programming</description>
   <language>en-uk</language>
   <managingEditor> marcin-chwedczuk</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Java streams best practices</title>
	  <link>//java-streams-best-practices</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2017-11-08T01:00:00+01:00</pubDate>
	  <guid>//java-streams-best-practices</guid>
	  <description><![CDATA[
	     In this short post I am going to present Java 8 streams 
best practices. Most of them either I figured out myself or
learned from my colleagues.

Let's start with some "obvious" things about code formatting:

* You should have at most one stream method call per line.
 This will make stream operations like `map`, `filter` and 
 `collect` easily recognizable.
{% highlight java %}
// BAD CODE:
strings.stream().filter(s -> s.length() > 2).sorted()
	.map(s -> s.substring(0, 2)).collect(Collectors.toList());

// GOOD CODE:
strings.stream()
	.filter(s -> s.length() > 2)
	.sorted()
	.map(s -> s.substring(0, 2))
	.collect(Collectors.toList());
{% endhighlight %}

* You should `import static` all of the standard 
 stream related methods. This will make code shorter, 
 easier to read and easier to understand by removing all 
 unnecessary visual noise.
{% highlight java %}
// BAD CODE:
strings.stream()
	.sorted(Comparator.reverseOrder())
	.limit(10)
	.collect(Collectors.toMap(Function.identity(), String::length));

// GOOD CODE:
strings.stream()
	.sorted(reverseOrder())
	.limit(10)
	.collect(toMap(identity(), String::length));
{% endhighlight %}

* You should prefer method references to lambdas.
{% highlight java %}
// AVOID:
strings.stream()
	.map(s -> s.length())
	.collect(toList());

// PREFER:
strings.stream()
	.map(String::length)
	.collect(toList());
{% endhighlight %}
Method references are easier to read since we
avoid all the visual noise generated by `->` and `()` operators.
They are also handled more efficiently by current version of Java.
Lambda expressions like `s -> s.length()` are compiled
to a private static method and an `invokedynamic` instruction.
{% highlight java %}
// s -> s.lenght() is translated into:
private static Integer lambda$main$0(String s) {
	return s.length();
}
{% endhighlight %}
Method references are compiled to only `invokedynamic` instruction.

* You should use methods from `Class<T>` to filter stream elements by a type
 and to cast stream elements to a type.
{% highlight java %}
Stream<Object> objects = Stream.of(
	"a string",
	42,
	new String[] { "an array" },
	"another string");

List<String> strings = objects
	.filter(String.class::isInstance)
	.map(String.class::cast)
	.collect(toList());
{% endhighlight %}
Also rember that `Class<T>::isInstance` only checks if 
the value can be assigned to a variable of type `T`. For example
`Object.class.isInstance("foo")` returns `true` because string
`"foo"` can be assigned to a variable of type `Object`.
If you want to check that stream elements have exactly type `T`
you must use expression:
{% highlight java %}
.filter(x -> (x != null) && x.getClass().equals(T.class))
{% endhighlight %}

* Give meaningful names to frequently used collector expressions.
 In most cases this means extracting collector expression into
 its own method.
{% highlight java %}
// USED FROM TIME TO TIME:
Map<Integer, Entity> entityById = entities.stream()
	.collect(toMap(Entity::getId, identity()));

// USED FREQUENTLY:
Map<Integer, Entity> entityById = entities.stream()
	.collect(ExtraCollectors.toByIdMap());

private static class ExtraCollectors {
  public static Collector<Entity,?,Map<Integer,Entity>> toByIdMap() {
	return Collectors.toMap(Entity::getId, identity());
  }
}
{% endhighlight %}
You may also consider using static import for your own frequently
used collectors.

* Use the following pattern when you sort stream values at hoc:
{% highlight java %}
List<Student> result = students.stream()
	.sorted(
	  comparing(Student::getSurname)
		.thenComparing(Student::getName, reverseOrder())
		.thenComparing(Student::getAge)
		.thenComparing(Student::getId, reverseOrder())
	)
	.collect(toList());
{% endhighlight %}
Notice how we used `reverseOrder()` to reverse order of sorting
by name and id. Also bear in mind that it is always a good idea
to extract complicated comparers to its own method or a final field.

* Use `IntStream`, `LongStream` and `DoubleStream` when working with
 primitive types. They are faster (they avoid boxing) and easier to
 use (they add useful methods like `sum`).
{% highlight java %}
Stream<String> strings = Stream.of("a", "foo", "bar", "baz");

double averageLength = strings
		.mapToInt(String::length)
		.summaryStatistics()
		.getAverage();
{% endhighlight %}
Use `mapTo[Int|Long|Double]` and `mapToObj` to convert 
between a stream and a specialized primitive stream.

Also learn about static helper methods exposed by specialized stream
classes:
{% highlight java %}
// prints: 0 1 2 3 4 5 6 7 8 9
IntStream.range(0, 10)
	.forEach(System.out::println);

// prints: 1 2 4 8 16 32 64 128 256 512
IntStream.iterate(1, i -> 2*i)
	.limit(10)
	.forEach(System.out::println);

ThreadLocalRandom random = ThreadLocalRandom.current();

// prints: -376368599 2112239618
// just to demo generate method:
IntStream.generate(random::nextInt)
	.limit(2)
	.forEach(System.out::println);

// prints: -1134353240 2007034835
// stream of random int's - more idiomatic way:
random.ints()
	.limit(2)
	.forEach(System.out::println);
{% endhighlight %}

* Avoid using `peek()`.
 Try to make your streams free of side-effects.

This list is by no means complete. I will try to add some more
practices in the future. Bye!



	  ]]></description>
	</item>

	<item>
	  <title>Hibernate HHH000179 warning&#58 Narrowing proxy to class this operation breaks ==</title>
	  <link>//HHH000179-narrowing-proxy-to-class-this-operation-breaks-equality</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2017-07-30T02:00:00+02:00</pubDate>
	  <guid>//HHH000179-narrowing-proxy-to-class-this-operation-breaks-equality</guid>
	  <description><![CDATA[
	     In this post I will explain why Hibernate is generating the HHH000179
warning and when ignoring it may introduce bugs in your code.

To understand what this "Narrowing proxy" is all about,
first we must learn about Hibernate proxies.
When we read a value of lazy loaded property or when we call
`EntityManager::getReference` Hibernate returns a proxy object.
This proxy is an instance of a class that was generated at runtime using
library like [Javassit](http://jboss-javassist.github.io/javassist/).

For example for a simple entity:
{% highlight java %}
@Entity
@Table(name = "person")
public class Person extends BaseEntity {
    @Column(name = "person_name", nullable = false)
    private String name;

    @ManyToOne(optional = false, fetch = FetchType.LAZY, cascade = CascadeType.ALL)
    @JoinColumn(name = "house_id")
    private House house;

    @OneToMany(mappedBy = "owner", fetch = FetchType.LAZY, cascade = CascadeType.ALL, orphanRemoval = true)
    private Set<Pet> pets = new HashSet<>(0);

    // ...
}
{% endhighlight %}
Generated proxy class looks similar to:
{% highlight java %}
public class Person_$$_jvst5ed_2 
        extends Person 
        implements HibernateProxy, ProxyObject {
 
    private MethodHandler handler;
    private static Method[] _methods_;
 
    // plenty of other stuff here
 
    public final UUID _d7getId() {
        return super.getId();
    }
 
    public final UUID getId() {
        Method[] var1 = _methods_;
        return (UUID)this.handler.invoke(this, var1[14], var1[15], new Object[0]);
    }
}
{% endhighlight %}

TIP: In Hibernate 5.1 you may write generated 
proxy classes to disk by putting a breakpoint
in [`JavassistProxyFactory::buildJavassistProxyFactory`](https://github.com/hibernate/hibernate-orm/blob/ba3359fe62be258638554fe23a2a0a6a50f7e732/hibernate-core/src/main/java/org/hibernate/proxy/pojo/javassist/JavassistProxyFactory.java#L102)
method and setting 
`factory.writeDirectory` field to a valid path. 
You may want to use a conditional
breakpoint to avoid doing this manually every time a proxy is generated.

The most important point here is that proxy class *extends* entity class.

Now let's see what happens when we mix proxies with inheritance.
Given a simple class hierarchy:
{% highlight java %}
@Entity
@Inheritance(strategy = InheritanceType.SINGLE_TABLE)
@DiscriminatorColumn(name = "animal_type")
public abstract class Pet extends BaseEntity {
    @Column
    private String name;

    @JoinColumn(name = "owner_id", nullable = false)
    @OneToOne(optional = false, fetch = FetchType.LAZY)
    private Person owner;

    public abstract String makeNoise();
    // ...
}

@Entity
@DiscriminatorValue("cat")
public class Cat extends Pet { /* ... */ }

@Entity
@DiscriminatorValue("dog")
public class Dog extends Pet { /* ... */ }
{% endhighlight %}
When we use `EntityManager::getReference` to load a `Pet` we will
get a proxy that extends `Pet` class because Hibernate does not know yet
whatever our pet is a `Cat` or a `Dog`:
{% highlight java %}
// In some earlier transaction:
Cat gerard = new Cat("gerard");
entityManager.persist(gerard);

gerardId = gerard.getId();

// In current transaction:
Pet pet = entityManager.getReference(Pet.class, gerardId);

assertThat(pet)
        .is(hibernateProxy())
        .is(uninitialized())
        .isInstanceOf(Pet.class)
        .isNotInstanceOf(Cat.class);
{% endhighlight %}
We may force Hiberante to query database to load proxied entity
state but that doesn't change proxy identity:
{% highlight java %}
// makeNoise() will access field *via getter* to initialize proxy
logger.info("Pet is a cat: " + pet.makeNoise()); // meow meeeow

assertThat(pet)
        .isNot(uninitialized())
        .isNotInstanceOf(Cat.class);
{% endhighlight java %}
Even though now Hibernate knows that our pet is a `Cat` it cannot
change already loaded proxy class definition,
`Pet` proxy continues to be so.
This may cause you problems because tests like `pet instanceof Cat` will
fail although pet indeed represents a cat.

There is also a second issue that may come up when working with proxies.
If `makeNoise()` method would access pet data via field, proxy would not
be notified about that data access and it wouldn't load data from DB,
causing our method to read an uninitialized field value.
_The moral is that we should always use getters and setters 
when dealing with entity state_.

Now you may think that if we try to load `Pet` again (after proxy was
initialized), Hibernate will return instance of the `Cat` entity.
The behavior displayed by Hibernate is slightly different
because of Hibernate first level cache
that prefers returning already
loaded entity instance than creating a new one:
{% highlight java %}
Pet pet2 = entityManager.getReference(Pet.class, gerardId);

assertThat(pet2)
        .isNotInstanceOf(Cat.class)
        .isSameAs(pet);
{% endhighlight %}

What will happen when we try to explicitly load a `Cat` entity:
{% highlight java %}
// HHH000179: Narrowing proxy to class Cat - this operation breaks ==
Pet pet3 = entityManager.getReference(Cat.class, gerardId);
assertThat(pet3)
        .isInstanceOf(Cat.class)
        .isNot(hibernateProxy());
{% endhighlight %}
Now we got the famous HHH000179 warning, and Hiberante handled
us unproxied `Cat` instance.
But why was this warning generated? Because right now we 
we have two different object (the proxy and the `Cat` instance)
in our session that point to exactly the same entity.

Of course the pet proxy is pointing to the cat instance,
and changes applied to e.g. entity instance are reflected in the proxy state:
{% highlight java %}
assertThat(pet.getName())
    .isEqualTo("gerard");

assertThat(pet)
    .isNotSameAs(pet3);

// set via Cat entity
pet3.setName("proton");

// reflected via proxy
assertThat(pet.getName())
    .isEqualTo("proton");
{% endhighlight %}

So you may think that having two representation of the same DB row 
in memory is OK,
but the real troubles begin if we do not override `equals()` and `hashCode()`
methods properly. This is demonstrated by example:
{% highlight java %}
// Alice is owner of the cat
Person alice = entityManager.find(Person.class, aliceId);

// Alice can own and not own the same cat...
assertThat(alice.getPets().contains(pet))
        .isFalse();

assertThat(alice.getPets().contains(pet3))
        .isTrue();

// But only if we rely on default equals() and 
// hashCode() implementation
{% endhighlight %}
Fortunately this can be easily fixed by providing `equals()` implementation
that is based either on primary key or business key equality, for example:
{% highlight java %}
@MappedSuperclass
public abstract class BaseEntity {
    @Id
    @Type(type="binary(16)")
    private UUID id;

    protected BaseEntity() {
        this.id = UUID.randomUUID();
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || !(o instanceof BaseEntity)) return false;

        BaseEntity that = (BaseEntity) o;

        // remember to use *getters*
        return getId().equals(that.getId());
    }

    @Override
    public int hashCode() {
        return getId().hashCode();
    }
}
{% endhighlight %}

We may also reproduce above behaviour with lazy loading,
you can find an example of how to do this in the attached source code.

#### Significance in the real world application

Recently I developed a module in an application that was based on huge
in-house framework (Ughhh). This framework let's call it X
contained some of the entities that we used, but we have no way of
modifying them. The only way to add some fields to an already existing entity
was to extend it (fortunately for us, most entities in X were declared
as base classes with inheritance strategy SINGLE_TABLE).
At the end of this project we had plenty of small class hierarchies
consisting only of super class and a single subclass.
We also had plenty of references from other entities to either
this sup or super classes. As you may expect this was a fertile 
ground for Hibernate HHH000179 warnings, and so I devoted a few hours of
my time to figure out what this warning is all about. In our case
providing proper `equals()` and `hashCode()` was all that was needed.
But just to sum up I want to present the last, more real world example.

Shipped with framework X:
{% highlight java %}
@Entity
@Table(name = "extensible_user")
@Inheritance(strategy = InheritanceType.SINGLE_TABLE)
@DiscriminatorColumn(name = "discriminator")
@DiscriminatorValue("NOT_USED")
public class LegacyUser {
    @Id
    @GeneratedValue
    private Long id;

    @Column
    private String userPreference1;

    @Column
    private String userPreference2;
    // ...
}

@Entity
@Table(name = "document")
public class LegacyDocument {
    @Id
    @GeneratedValue
    private Long id;

    @Column
    private String contents;

    @ManyToOne(optional = false, fetch = FetchType.LAZY)
    @JoinColumn(name = "owner_id")
    // !!! Entity referes to super class !!!
    private LegacyUser owner;

    // ...
}
{% endhighlight %}
Shipped with my module:
{% highlight java %}
@Entity
@DiscriminatorValue("EXTENDED")
public class ExtendedUser extends LegacyUser {
    @Column
    private String userPreference3;
    // ...
}

@Entity
@Table(name = "comment")
public class Comment {
    @Id
    @GeneratedValue
    private Long id;

    @ManyToOne(/*...*/)
    @JoinColumn(name = "document_id")
    private LegacyDocument document;

    @ManyToOne(/*...*/
    @JoinColumn(name = "author_id")
    // !!! Entity refers to subclass !!!
    private ExtendedUser author;

    @Column
    private String contents;
    // ...
}
{% endhighlight %}
As you can see legacy class `Document` is using `LegacyUser` to refer to
a system user. New class `Comment` is using `ExtendedUser` to refer to
a system user.

Without proper `equals()` implementation we may get into troubles:
{% highlight java %}
LegacyDocument document = 
    entityManager.find(LegacyDocument.class, documentId);

// we load some data from document owner
LegacyUser documentOwner = document.getOwner();
doSomethingWithOwner(documentOwner);

// HHH000179: Narrowing proxy to class ExtendedUser 
//  - this operation breaks ==
// When Hibernate loads comment that has 
// field of type ExtendedUser with the same Id as LegacyUser 
// it realizes that documentOwner is indeed ExtendedUser.
// So this time Hibernate could figure out that 
// it generated wrong proxy without querying DB.
List<Comment> comments = entityManager.createQuery(
            "select c from Comment c where c.document.id = :docId",
            Comment.class)
        .setParameter("docId", document.getId())
        .getResultList();

// Now the most interesting part
ExtendedUser commentAuthor = comments.get(0).getAuthor();

// comment author and doc author is the same user
assertThat(commentAuthor.getId())
        .isEqualTo(documentOwner.getId());

// but...
assertThat(commentAuthor)
        .isNotSameAs(documentOwner);

// Now without overloading hashCode()/equals() we may
// expect troubles...
Set<LegacyUser> users = new HashSet<>();
users.add(commentAuthor);
users.add(documentOwner);

assertThat(users).hasSize(2);
{% endhighlight %}

And that is all that I wanted to say about HHH000179. 
The most important thing that
you should remember from this article is that with 
good `equals()` and `hashCode()` implementation
HHH000179 warning can be safely ignored.

Source code: [https://github.com/marcin-chwedczuk/hibernate_narrowing_proxy_warning_demo](https://github.com/marcin-chwedczuk/hibernate_narrowing_proxy_warning_demo)


	  ]]></description>
	</item>

	<item>
	  <title>Debugging OpenJDK 8 with NetBeans on Ubuntu</title>
	  <link>//debugging-openjdk8-with-netbeans-on-ubuntu</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2017-06-24T02:00:00+02:00</pubDate>
	  <guid>//debugging-openjdk8-with-netbeans-on-ubuntu</guid>
	  <description><![CDATA[
	     In this post we will learn how to download, compile and debug OpenJDK 8
using Ubuntu and NetBeans IDE.

#### Downloading and compiling OpenJDK 8

[OpenJDK](http://openjdk.java.net/) project uses Mercurial for source
code versioning. To get sources using Mercurial follow instructions described 
[in this SO answer](https://stackoverflow.com/a/29845834/1779504).

To get OpenJDK sources using Git, we need to clone OpenJDK repository mirror
provided by [AdoptOpenJDK project](https://adoptopenjdk.net/about.html).
To speed things up we will only clone `master` branch without commit history:
{% highlight no-highlight %}
$ git clone \
	--depth 1 \
	-b master \
	git@github.com:AdoptOpenJDK/openjdk-jdk8u.git
{% endhighlight %}

Now when we have sources, its time to compile OpenJDK.
First we need to install all required dependencies:
{% highlight no-highlight %}
$ sudo apt install \
        libx11-dev \
        libxext-dev \
        libxrender-dev \
        libxtst-dev \
        libxt-dev \
        libcups2-dev \
        libfreetype6-dev \
        libasound2-dev
{% endhighlight %}
Then we must run `configure` script:
{% highlight no-highlight %}
$ cd openjdk-jdk8u/
$ chmod +x ./configure
$ ./configure \
	--with-debug-level=slowdebug \
	--with-target-bits=64
{% endhighlight %}
We call `configure` with two options:

* `--with-debug-level=slowdebug` - enables generating debug information
 when compiling OpenJDK
* `--with-target-bits=64` - we will generate 64-bit binaries

It may happen than `configure` will return error telling you that you need
to install some additional tool/library. This is something to be expected,
just follow instructions printed by `configure`.
You may need to do this several times until you will 
have all required dependencies installed on your system.

Now it's time to actually build OpenJDK:
{% highlight no-highlight %}
$ make
{% endhighlight %}
This may take some time...
{% highlight no-highlight %}
----- Build times -------
Start 2017-06-24 17:45:26
End   2017-06-24 17:48:53
00:00:12 corba
00:01:25 hotspot
00:00:08 jaxp
00:00:12 jaxws
00:01:13 jdk
00:00:17 langtools
00:03:27 TOTAL
-------------------------
Finished building OpenJDK for target 'default'
{% endhighlight %}

Now we may use our newly built `java` to run "Hello, world!" program:
{% highlight no-highlight %}
$ ./build/linux-x86_64-normal-server-slowdebug/jdk/bin/java \
	-cp "/home/me/dev/java/helloWorld/" \
	App
Hello, world!
{% endhighlight %}

#### Creating project for OpenJDK 8 in NetBeans

You need to [download](https://netbeans.org/downloads/)
and install NetBeans IDE. Since HotSpot is written in C++ we will need
NetBeans with C/C++ support.

Now it is time to create project for OpenJDK in NetBeans.
Select File->New Project...->C/C++ Project with Existing Sources...
![New project dialog window.](assets/images/2017-06-24/new_proj.png)

Then select "Custom" configuration mode:
![New project dialog window 2 step.](assets/images/2017-06-24/new_proj2.png)

We must use the same `configure` arguments that we used on command line:
![Configure options.](assets/images/2017-06-24/new_proj3.png)

Now click "Next" a few more times and then click "Finish".
NetBeans should now run `configure` and build OpenJDK, you should
see compiler output in Build tab:
![Build window.](assets/images/2017-06-24/new_proj4.png)

After build ends you should see output similar to:
{% highlight no-highlight %}
----- Build times -------
Start 2017-06-24 18:07:15
End   2017-06-24 18:11:17
00:00:14 corba
00:01:45 hotspot
00:00:08 jaxp
00:00:13 jaxws
00:01:22 jdk
00:00:20 langtools
00:04:02 TOTAL
-------------------------
Finished building OpenJDK for target 'default'

BUILD SUCCESSFUL (total time: 4m 2s)
{% endhighlight %}

Now we should try to run our "Hello, World!" program from NetBeans.
Click on project and then select "Properties":
![Run command.](assets/images/2017-06-24/run_1.png)
Then go to "Run" category and click on "..." next to "Run command", then
write any command that you want to run. Assume that `"${OUTPUT_PATH}"`
refers to `java` binary:
![Run command step 2.](assets/images/2017-06-24/run_2.png)

Now select Run->Run Project, NetBeans will ask you what binary you want to
run, select `java`:
![Run command step 3.](assets/images/2017-06-24/run_3.png)

Now you should see "Hello, world!" written in Output window:
![Run command step 4.](assets/images/2017-06-24/run_4.png)

#### Debugging with NetBeans

Call to `System.out.println(...)` in Java will ultimately be handled
by `writeBytes` function in `jdk/src/share/native/java/io/io_util.c` file
(this is only valid for Linux builds of OpenJDK).

Lets put a breakpoint inside that function and see what will happen when we
try to debug Hello world program:
![Debug step 1.](assets/images/2017-06-24/debug_1.png)

Select Debug->Debug Main Project. After executing this command you
may see window:
![Debug step 2.](assets/images/2017-06-24/debug_2.png)
JVM uses `SIGSEGV` for its internal purposes, from our point of view
we may just ignore it (select "Don't Catch this Singla Again" and 
"Forward and Continue"). After a few seconds we should be able to
catch a breakpoint and see what JVM is doing:
![Debug step 3.](assets/images/2017-06-24/debug_3.png)

And that's it! 
Now you will be able to check and understand how JVM is working under cover.

#### References

* [http://marcelinorc.com/2016/02/17/using-netbeans-to-hack-openjdk9-in-ubuntu/](http://marcelinorc.com/2016/02/17/using-netbeans-to-hack-openjdk9-in-ubuntu/)
* [https://neugens.wordpress.com/2015/02/26/debugging-the-jdk-with-gdb/](https://neugens.wordpress.com/2015/02/26/debugging-the-jdk-with-gdb/)
* [https://github.com/AdoptOpenJDK/openjdk-build](https://github.com/AdoptOpenJDK/openjdk-build)


	  ]]></description>
	</item>

	<item>
	  <title>Zen and the Art of Unit Testing</title>
	  <link>//zen-and-the-art-of-unit-testing</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2017-02-19T01:00:00+01:00</pubDate>
	  <guid>//zen-and-the-art-of-unit-testing</guid>
	  <description><![CDATA[
	     In this blog post we will concern ourselves with unit testing of
classic 3-layer business applications. We will assume that
all business logic lives in services and components,
that these services operate on entities that are stored and retrieved
from relational database, 
and that these entities doesn't contain any logic.
Moreover we assume usage of 
DTO ([Data Transfer Object](https://en.wikipedia.org/wiki/Data_transfer_object))
to pass data between GUI and application services.

![High level overview of 3-layer architecture](assets/images/2017-02-19/L3arch.svg)

[Dependency Injection](https://en.wikipedia.org/wiki/Dependency_injection)
is indispensable when it comes to unit testing of
modern business applications. Without DI you are forced to write slow
and difficult to maintain integration tests instead of unit tests.
If you don't know what DI
is or if you don't used it before please read articles on [Wikipedia](https://en.wikipedia.org/wiki/Dependency_injection) and [Martin Fowler site](https://martinfowler.com/articles/injection.html),
and return here after you are comfortable with both idea and usage of DI.

Now when we are ready to start, we will follow Confucius advice:

> By three methods we may learn wisdom: First, by reflection, which is noblest;
> Second, by imitation, which is easiest; 
> and third by experience, which is the bitterest.
>
> Confucius

and learn by imitation,
by observing how we may unit test `UserService` component.
We will use popular [JUnit](http://junit.org/junit4/) unit testing framework
with [Mockito](http://site.mockito.org/) mocking library.

#### `UserService` component

`UserService` implements following business requirements:

* Users forgot their passwords from time to time, application should
 provide a way to reset forgotten passwords.
* To reset their passwords users must provide email address they use
 to login to our system.
* If provided email address does not belong to any user, application 
 should do nothing. Otherwise application should generate unique
 password reset token and send
 to provided email address message with link to reset password form.
 Link should contain reset password token.
 In both cases application should show to user success message.
* Password reset tokens should be unique. Tokens should be hard to
 guess or enumerate (no numbers here). Token may be used only once
 to reset password. If we want to reset password again we need a new token.
 Token is valid for 24 hours starting from the date it was created, after 24
 hours token cannot be used to change password.
* When user open reset password link in her browser it should be presented
 with a form that allows to enter a new password. After clicking OK,
 application should validate token used in link, and if it is still
 valid application should change user password and make token invalid.
 Then application should send password change confirmation message to user.
 In case of expired token application should show warning to user.

![Password change flow](assets/images/2017-02-19/flow.svg)

WARNING Before implementing real password reset feature please read
[Everything you ever wanted to know about building a secure password reset feature](https://www.troyhunt.com/everything-you-ever-wanted-to-know/).

Now when we understand business requirements we may attempt to implement
`UserService` component:
{% highlight java %}
public class UserServiceImpl implements UserService {
    private final UserRepository userRepository;
    private final NotificationService notificationService;
    private final DateTimeProvider dateTimeProvider;
    private final CryptoService cryptoService;

    public UserServiceImpl(
		UserRepository userRepository,
		DateTimeProvider dateTimeProvider,
		CryptoService cryptoService,
		NotificationService notificationService)
    {
        this.userRepository = requireNonNull(userRepository);
        this.notificationService = requireNonNull(notificationService);
        this.dateTimeProvider = requireNonNull(dateTimeProvider);
        this.cryptoService = requireNonNull(cryptoService);
    }

    @Override
    public void startResetPasswordProcess(String userEmailAddress) {
        User user = userRepository.findByEmailAddress(userEmailAddress);
        if (user == null)
            return;

        UUID token = UUID.randomUUID();
        LocalDateTime tokenValidityEndDate =
                dateTimeProvider.now().plusDays(1);

        user.setResetPasswordToken(token);
        user.setResetPasswordTokenValidityEndDate(
                tokenValidityEndDate);

        ResetPasswordNotificationData notificationData = 
            new ResetPasswordNotificationData(
                user.getEmail(),
                token,
                tokenValidityEndDate);

        notificationService
            .sendResetPasswordNotification(notificationData);
    }

    @Override
    public void finishResetPasswordProcess(
            String userEmailAddress,
            String newPassword,
            UUID resetPasswordToken)
    {
        User user = userRepository.findByEmailAddress(userEmailAddress);
        if (user == null)
            return;

        if (user.getResetPasswordToken() == null)
            return;

        if (!user.getResetPasswordToken().equals(resetPasswordToken))
            return;

        if (user.getResetPasswordTokenValidityEndDate()
                .isBefore(dateTimeProvider.now()))
            return;

        user.setResetPasswordToken(null);
        user.setResetPasswordTokenValidityEndDate(null);

        String newPasswordHash = cryptoService.sha1(newPassword);
        user.setPasswordHash(newPasswordHash);

        notificationService
            .sendPasswordChangedConfirmation(user.getEmail());
    }
}
{% endhighlight %}
`UserService` operates on the following `User` entity:
{% highlight java %}
public class User {
    private Long id;
    
    private String email;
    private String passwordHash;
    
    private UUID resetPasswordToken;
    private LocalDateTime resetPasswordTokenValidityEndDate;
    
    // getter, setter, etc.
}
{% endhighlight %}
And requires four other components to work, namely: `UserRepository`,
`NotificationService`, `DateTimeProvider` and `CryptoService`:
{% highlight java %}
public interface UserRepository {
    User findByEmailAddress(String emailAddress);
}
    
public interface NotificationService {
    void sendResetPasswordNotification(
            ResetPasswordNotificationData data);
    void sendPasswordChangedConfirmation(String email);
}
    
public interface DateTimeProvider {
    LocalDateTime now();
}
    
public interface CryptoService {
    String sha1(String input);
}
{% endhighlight %}
`DateTimeProvider` dependency was introduced solely for the purpose
of easier unit testing, as we will find out later.

Design of `UserService` follows principles of DI, component advertises
all dependencies it needs as constructor parameters.
DI containers may then use [constructor based dependency injection](https://www.tutorialspoint.com/spring/constructor_based_dependency_injection.htm) to
provide implementations of these dependencies.
Right now we have only implemented `UserService`, `UserRepository` and
other dependencies are not implemented yet.
Nevertheless with usage of stubs and
mocks we may test `UserService` implementation right now.

#### Writing tests for `startResetPasswordProcess`

By convention we should put tests for `ComponentName` into `ComponentNameTest`
class. For example tests for `UserServiceImpl` should be put 
into `UserServiceImplTest` class.

When you use Maven you should put your test class in 
the same package that contains tested component.
For example `UserServiceImpl`
is part of `io.mc.letsmock.demo` package, so `UserServiceImplTest`
should also belong to `io.mc.letsmock.demo` package.
With Maven the only difference between application code and test code is the
directory in which code resides. Application code will be in `src/main/java`
directory and test code will be in `src/test/java` directory:
{% highlight no-highlight %}
.
`-- src
    |-- main
    |   `-- java
    |       `-- io
    |           `-- mc
    |               `-- letsmock
    |                   `-- demo
    |                       |-- UserServiceImpl.java
    |                       `-- UserService.java
    `-- test
        `-- java
            `-- io
                `-- mc
                    `-- letsmock
                        `-- demo
                            `-- UserServiceImplTest.java
{% endhighlight %}
Another popular
convention used with e.g. Ant is to put applicaiton code into
`mycompany.productA.xx.yy` package and test code
into `mycompany.productA.test.xx.yy` package.

The important thing here is that team should choose one particular convention
how to name tests and where to put test classes and stick to it.
If you use Maven I strongly encourage using conventions that I described above.

##### Naming tests

After reading requirements we come to conclusion that we need the following
test cases to be sure that `startResetPasswordProcess` method works:

* When we couldn't find `User` with specified email address, component should
 do not nothing, in particular is should not crash
* When there is `User` with specified email address, component should set
 `resetPasswordToken` and `resetPasswordTokenValidityEndDate` fields on `User`
 instance to respectively 
 newly generated token, and `LocalDateTime` instance that represent point
 in time 24 hours later than now.
* When there is `User` with specified email address, component should send
 message with token to user using `NotificationService`.

Notice that each of these test cases test only single thing, this is
very important if we want to have clean and independent tests.
As method should do only one thing, 
test should test only one "outcome" of a method.
When you gain more experience you may want to relax this rule, 
but if you just started unit testing
you should stick with it for some time.

There are two schools when it comes to naming test methods, first
school teaches that test name should consists of three parts:
{% highlight java %}
@Test
void scenario_conditions_outcome()
{% endhighlight %}
`scenario` is the thing that we want to test, this in most cases
will be the name of the method that we want to test.
`conditions` describe the state of program that tested method
may expect when it is called. `outcome` is the state of the program
that we expect after tested method returns.

To give you a feeling how this naming scheme works here
are some dummy tests for Java `+` operator:
{% highlight java %}
void plusOperator_given1And5_returns6()
void plusOperator_given1AndMinus7_returnsMinus6()
void plusOperator_whenResultIsGreaterThanMAXINT_wrapsResultsUsingMod2Arithmetic()
{% endhighlight %}

The second school took inspiration for thier naming scheme from 
[BDD](https://en.wikipedia.org/wiki/Behavior-driven_development)
movement.
This school advices that 
test names should consists of full sentences that describe both
conditions and outcome of tested method. 
Names for `+` operator tests following this
scheme looks like:
{% highlight java %}
void _1_plus_5_should_return_6()
void _1_plus_minus_7_should_return_minus_6()
void when_result_of_addition_is_greater_than_MAXINT_plus_operator_should_wrap_result_using_mod_2_arithmetic()
{% endhighlight %}
As you can see test names generated using this approach 
can be quite verbose at times. Verbosity of this schema is it great advantage 
because the main purpose of test name is to tell you
what exactly is not working when given test fails. 

I prefer first school with scenario/conditions/outcome division of test name,
so I will use it exclusively in the rest of this post.

Returning to `startResetPasswordProcess` we should create three tests:
{% highlight java %}
void startResetPasswordProcess_givenEmailNotBelongingToAnyUser_doesNothing()
void startResetPasswordProcess_givenEmailOfExistingUser_generatesToken()
void startResetPasswordProcess_givenEmailOfExistingUser_sendsNotificationToUser()
{% endhighlight %}
These test names are not as descriptive as they may be, but are close
to what you may expect in average enterprise application.

##### Anatomy of test method

Our first test will check that `startResetPasswordProcess` won't throw
exceptions when called with email address of non-existing user.
But to test `UserServiceImpl` class we must create it's instance and this
will require providing all necessary dependencies.
Fortunately we may use Mockito library to 
to generate 
dummy implementations of `UserRepository`, `NotificationService` 
and others. By default these dummy implementations do nothing and
are similar to handcrafted test stubs like:
{% highlight java %}
public class UserRepositoryStub implements UserRepository {
    @Override
    public User findByEmailAddress(String emailAddress) {
        return null;
    }
}
{% endhighlight %}
But we will soon see that we can instruct Mockito to return
values from these stubs or to check if a given method was called
on dummy object.

Below you can see our first test code:
{% highlight java %}
@Test
public void startResetPasswordProcess_givenEmailNotBelongingToAnyUser_doesNothing() {
   // arrange
   UserRepository userRepository = mock(UserRepository.class);
   DateTimeProvider dateTimeProvider = mock(DateTimeProvider.class);
   CryptoService cryptoService = mock(CryptoService.class);
   NotificationService notificationService = mock(NotificationService.class);

   when(userRepository.findByEmailAddress("unknown@example.com"))
	   .thenReturn(null);

   UserServiceImpl userService = new UserServiceImpl(
	   userRepository,
	   dateTimeProvider,
	   cryptoService,
	   notificationService);
   // act
   userService.startResetPasswordProcess("unknown@example.com");

   // assert
   verify(notificationService, never())
	   .sendResetPasswordNotification(any());

   verify(notificationService, never())
	   .sendPasswordChangedConfirmation(anyString());
}
{% endhighlight %}
Before we dig into details let's look at this test from high level
point of view. Almost every test method can be divided into three
parts called Arrange-Act-Assert or Given-When-Then. I used comments
to signify when each of these parts start. Each of these parts has
different purpose. In Arrange part we must create instance of
tested component and all necessary test data and
also we must set up Mockito mocks.
If we may compare test method to theater play, then Arrange is like 
preparing scene, costumes and lights.

The first four lines of our test Arrange section are responsible for
creating dummy implementations of `UserServiceImpl` dependencies:
{% highlight java %}
UserRepository userRepository = mock(UserRepository.class);
DateTimeProvider dateTimeProvider = mock(DateTimeProvider.class);
CryptoService cryptoService = mock(CryptoService.class);
NotificationService notificationService = mock(NotificationService.class);
{% endhighlight %}
Then we set up one of our stub objects:
{% highlight java %}
when(userRepository.findByEmailAddress("unknown@example.com"))
	.thenReturn(null);
{% endhighlight %}
Here we instruct Mockito that dummy implementation generated for 
`UserRepository::findByEmailAddress`
should return `null` when called with `"unknown@example.com"` string.
But to be honest these lines are redundant because
method stubs generated by Mockito by default return `null` for
reference types, default values for primitives and empty collections
for methods returning collections. 
Still I leave them because they 
make purpose of our test more evident.

After Arrange section we have an Act section. Again (so many AAAAs)
returning to our theater play analogy (another A, no pun intended)
Act section is like the actual play, we invoke tested component and let
the code be alive. Act part is usually very short, in most cases
it consists of single line of code:
{% highlight java %}
userService.startResetPasswordProcess("unknown@example.com");
{% endhighlight %}

The last section in the test method is Assert when we want to
check results produced by tested code. In our test we check two
assumptions:

1. Invocation of `startResetPasswordProcess` does not throw any exceptions.
 This is tested implicitly by JUnit - test fails when test method throwns
 exception. Since our test passes we are certain that `startResetPasswordProcess`
 doesn't throw any.
2. We want to be certain that no notification was send to provided email address
 so we asses with the help of Mockit that none of the methods on `NotificationService`
 was called.

Mockito verification syntax is a bit unintuitive, so let's take a closer
look at one of our assertions:
{% highlight java %}
verify(notificationService, never())
	   .sendResetPasswordNotification(any());
{% endhighlight %}
We use `verify` to tell Mockit that we want to preform verification.
`never()` means that we expect that method was not called on dummy object.
Then we specify method that should not be called,
in our case `sendResetPasswordNotification`. 
We pass `any()` as method parameter to tell Mockito that method
should just not be called, and that we don't care about parameters
that was passed to it. Mockito is quite flexible here
and we may for example verify that method should not be called with given
set of parameters but must be called with another. We may also replace
`never()` with one of several predicates like e.g. `times(2)` to assert that
method was called twice.

#### Testing with assertions

Our first test assured us that `startResetPasswordProcess` works correctly
with email address of unknown user. Now it is time to check if
it also works correctly given email addresses of existing user.
Our second test will check if given valid email address `UserServiceImpl`
generates a new token for `User` and sets it expiry date correctly.
We also will check that user password is not altered in any way by
starting reset password process (it should change only when we *finish*
password change process).
Here is our second test code:
{% highlight java %}
@Test
public void startResetPasswordProcess_givenEmailOfExistingUser_generatesToken() {
   // arrange
   UserRepository userRepository = mock(UserRepository.class);
   DateTimeProvider dateTimeProvider = mock(DateTimeProvider.class);
   CryptoService cryptoService = mock(CryptoService.class);
   NotificationService notificationService = mock(NotificationService.class);

   UserServiceImpl userService = new UserServiceImpl(
	   userRepository,
	   dateTimeProvider,
	   cryptoService,
	   notificationService);

   User joe = new User();
   joe.setEmail("joe@example.com");
   joe.setResetPasswordToken(null);
   joe.setResetPasswordTokenValidityEndDate(null);
   joe.setPasswordHash("old-password-hash");

   when(userRepository.findByEmailAddress("joe@example.com"))
	   .thenReturn(joe);

   when(dateTimeProvider.now())
	   .thenReturn(LocalDateTime.of(2017,3,10, 0,0));

   // act
   userService.startResetPasswordProcess("joe@example.com");

   // assert
   assertThat(joe.getResetPasswordToken())
	   .isNotNull();

   assertThat(joe.getResetPasswordTokenValidityEndDate())
	   .isEqualTo(LocalDateTime.of(2017,3,11, 0,0));

   assertThat(joe.getPasswordHash())
	   .withFailMessage("Password should not be changed")
	   .isEqualTo("old-password-hash");
}
{% endhighlight %}
Arrange section of our second test does not differ much from Arrange
section of our first test, except that we added code for creation
of an `User` instance. Notice that we populate `User` with carefully 
chosen data that will allow us to test `startResetPasswordProcess`
implementation easily e.g. we set both `resetPasswordToken` and
`resetPasswordTokenValidityEndDate` to `null`.
Then we instruct Mockito to return our `User` instance when we
ask `UserRepository` for user with `joe@example.com` email address:
{% highlight java %}
when(userRepository.findByEmailAddress("joe@example.com"))
	.thenReturn(joe);
{% endhighlight %}

We should strive to make our unit tests as much deterministic as possible.
Unit test that sometimes fails without a reason is burden rather than
a benefit, and should be either fixed or removed.
To make unit more robust we should avoid depending on external input
like information about current time. To facilitate that I decided to
introduce `DateTimeProvider` component with sole purpose of making
unit tests more predictable. With small help of Mockito we are now
masters of time:
{% highlight java %}
when(dateTimeProvider.now())
	.thenReturn(LocalDateTime.of(2017,3,10, 0,0));
{% endhighlight %}

After all this preparations, we are now free to invoke `startResetPasswordProcess`
and check it's outcome. In unit tests we mainly use assertions to check
correctness of tested code. JUnit already comes with handy assertion library
that we may use like this:
{% highlight java %}
import static org.junit.Assert.*;

assertNotNull(joe.getResetPasswordToken());
assertEquals("old-password-hash", joe.getPasswordHash());
{% endhighlight %} 
When JUnit assertion fails it throws `AssertionError`, test fails and
we get error similar to:
{% highlight java %}
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertNotNull(Assert.java:712)
	at org.junit.Assert.assertNotNull(Assert.java:722)
	at io.mc.letsmock.demo.UserServiceImplTest.startResetPasswordProcess_givenEmailOfExistingUser_generatesToken(UserServiceImplTest.java:113)
{% endhighlight %}
Unfortunately error messages generated by JUnit assertions are not
always the best way to find out what went wrong with failing tests.
JUnit assertions are also cumbersome to use at times. From these
and other reasons I prefer to use assertions from assertJ library
and I used them when I wrote our second test:
{% highlight java %}
import static org.assertj.core.api.Assertions.assertThat;

assertThat(joe.getResetPasswordToken())
	.isNotNull();

assertThat(joe.getResetPasswordTokenValidityEndDate())
	.isEqualTo(LocalDateTime.of(2017,3,11, 0,0));

assertThat(joe.getPasswordHash())
	.withFailMessage("Password should not be changed")
	.isEqualTo("old-password-hash");
{% endhighlight %}
Here we check three things:

1. New password reset token was generated and assigned to `resetPasswordToken`
 property
2. Expiry date of password reset token was set correctly (token should be
 valid for the next 24 hours)
3. Current user password was not changed

Notice also that we use `withFailMessage` to provide additional
information in case our third assertion fails.
Without `withFailMessage` we would get following error:
{% highlight no-highlight %}
org.junit.ComparisonFailure: 
Expected :"old-password-hash"
Actual   :"xxx"
{% endhighlight %}
With `withFailMessage` we get:
{% highlight no-highlight %}
java.lang.AssertionError: Password should not be changed
{% endhighlight %}

#### Merciless refactoring

Right now both of our tests pass, but we see a lot of code duplication
between them. Now it is a good time to extract common parts of both
tests into `setUp` method and to create some fields in our test class:
{% highlight java %}
public class UserServiceImplTestAfterRefactoring {
    private UserRepository userRepository;
    private DateTimeProvider dateTimeProvider;
    private CryptoService cryptoService;
    private NotificationService notificationService;

    private UserServiceImpl userService;

    @Before
    public void setUp() {
        userRepository = mock(UserRepository.class);
        dateTimeProvider = mock(DateTimeProvider.class);
        cryptoService = mock(CryptoService.class);
        notificationService = mock(NotificationService.class);

        userService = new UserServiceImpl(
                userRepository,
                dateTimeProvider,
                cryptoService,
                notificationService);
    }

    @Test
    public void startResetPasswordProcess_givenEmailNotBelongingToAnyUser_doesNothing() {
        // arrange
        when(userRepository.findByEmailAddress("unknown@example.com"))
                .thenReturn(null);

        // act
        userService.startResetPasswordProcess("unknown@example.com");

        // assert
        verify(notificationService, never())
                .sendResetPasswordNotification(any());

        verify(notificationService, never())
                .sendPasswordChangedConfirmation(anyString());
    }

    @Test
    public void startResetPasswordProcess_givenEmailOfExistingUser_generatesToken() {
        // arrange
        User joe = Fixtures.userJoe();

        when(userRepository.findByEmailAddress("joe@example.com"))
                .thenReturn(joe);

        when(dateTimeProvider.now())
                .thenReturn(LocalDateTime.of(2017,3,10, 0,0));

        // act
        userService.startResetPasswordProcess("joe@example.com");

        // assert
        assertThat(joe.getResetPasswordToken())
                .isNotNull();

        assertThat(joe.getResetPasswordTokenValidityEndDate())
                .isEqualTo(LocalDateTime.of(2017,3,11, 0,0));

        assertThat(joe.getPasswordHash())
                .withFailMessage("Password should not be changed")
                .isEqualTo("old-password-hash");
    }
}
{% endhighlight %}
After refactoring both dependencies and tested components are
now stored in fields of test class. 
JUnit calls any method annotated by `@Before` before executing each
of test methods contained in test class. 
This makes `setUp` method suitable place to initialize fields
that will be used by many tests. 

Now you may be tempted to move initialization code to the test class
constructor, but don't do that. Unit tests should be independent of
each other. One of the worst sins when writing unit tests is to write
a test that depends on some data created by other test methods. 
Such incorrect test may pass when we ran all tests but will
fail when run it alone. This is one of the worst things that may happen
when writing unit tests, and clearly shows that we do something wrong.
Instead every test should create it's own test data and should use 
fresh Mockito stubs. Later you will appreciate this independence of
tests when you will try to run tests in parallel.

Unit tests often require some dummy data, instead of creating the
same object again and again in various tests we should group them
into library of test objects. Such library of test data is often called
a fixture. Since I expected that we will need `User` instance in other
test, I extracted code that created dummy user into `Fixtures` class:
{% highlight java %}
public class Fixtures {
   public static User userJoe() {
	  User joe = new User();

	  joe.setEmail("joe@example.com");
	  joe.setPasswordHash("old-password-hash");
	  joe.setResetPasswordToken(null);
	  joe.setResetPasswordTokenValidityEndDate(null);

	  return joe;
   }
}
{% endhighlight %}

##### Terminology

When reading about unit testing you may encounter terms *fake*, *mock* and *stub*.
Fake is any object that is used only by test code, fake may be implemented as
concrete class like `UserRepositoryStub` or as anonymous class generated at runtime.
In this last category we find all dummy implementations generated by Mockito.

Fakes can be divided into two groups stubs and mocks. Form practical point of
view we use mock to test interactions, and stubs to provide dummy data or
do-nothing implementation. We used `NotificationService` as a mock in our first
test because we used it to assert that no interaction took place (no message was
send to user). On the other hand all dummy implementations generated
by Mockito for `UserRepository`, `DateTimeProvider` etc. are examples of stubs.

More information about difference between mocks and stubs
can be found in Martin Fowler article
[Mocks aren't stubs](https://www.martinfowler.com/articles/mocksArentStubs.html).

##### Code coverage

When unit testing it is important to test all execution paths in our code.
Sometimes we may be convinced that we covered all corner cases only to
find out (usually in production) that we overlooked testing some obscure conditions.
In such situation after fixing bug, we should add missing test.
But we could do better, almost any popular Java IDE can measure
and show us code coverage of tested component. IDE can usually highlight
in red lines that were not tested, for example here how it looks like in IntelliJ:
![Code coverage in IntelliJ](assets/images/2017-02-19/code_cov.png)
Greenish bar next to line number tells us that line of code was *executed*
when running unit tests (being executed doesn't automatically mean that
the line of code is well tested, it is only a heuristic). On the other hand 
red bar tells that lines of code was not reached by tests and certainly is not tested.

When we are at it, you may heard that the higher code coverage the better.
Having 100% code coverage is impossible in any reasonable sized enterprise application.
There is an ongoing debate about how much code coverage is enough.
For me code coverage is just a tool that I use to check that I tested
all execution paths in code and nothing more.

##### It's your turn now

Right now we have only two tests for our `UserServiceImpl` component,
of course it is not enough to assure us that all of the business requirements
were fulfilled. When I tested `UserServiceImpl` I wrote seven more tests:

* `startResetPasswordProcess_givenEmailOfExistingUser_sendsNotificationToUser`
* `finishResetPasswordProcess_noUserHasSpecifiedEmail_doesNothing`
* `finishResetPasswordProcess_userHasNoTokenSet_doesNothing`
* `finishResetPasswordProcess_tokenExpired_doesNothing`
* `finishResetPasswordProcess_tokenNotMatch_doesNothing`
* `finishResetPasswordProcess_validToken_changesPassword`
* `finishResetPasswordProcess_validToken_sendsConfirmationToUser`

and only now I am certain that `UserServiceImpl` works correctly.

You may find source code for all these tests (with other goodies)
[HERE](https://github.com/marcin-chwedczuk/mockito-unit-test-demo).
But before you look at what I wrote, please try to implement these tests
yourself and then compare your code with mine. I am certain that you will
learn more this way.

Thanks for reading. If you liked this post please start my Github repository.
And see you soon again!


	  ]]></description>
	</item>

	<item>
	  <title>Hello, Hibernate Validator</title>
	  <link>//hello-hibernate-validator</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2017-02-05T01:00:00+01:00</pubDate>
	  <guid>//hello-hibernate-validator</guid>
	  <description><![CDATA[
	     In every enterprise application there is a need for
validation. You may want to validate data send by user to
your REST service, messages coming to your application from some
other system, or your own entities before saving them to database.

Standard
[JSR 303](http://beanvalidation.org/1.0/spec)
defines API for validating Java Beans without tying us to any
particular implementation.
Nevertheless some implementations are more polished than others,
and subject of this post -
Hibernate Validator is considered one of the best.

#### Project setup

Before we can use Hibernate Validator we must do
some groundwork.

##### Maven dependencies

To use Hibernate Validator we need following Maven dependencies:
{% highlight xml %}
<dependency>
    <groupId>org.hibernate</groupId>
    <artifactId>hibernate-validator</artifactId>
    <version>5.3.4.Final</version>
</dependency>

<dependency>
    <groupId>javax.el</groupId>
    <artifactId>el-api</artifactId>
    <version>2.2</version>
</dependency>
<dependency>
    <groupId>org.glassfish.web</groupId>
    <artifactId>javax.el</artifactId>
    <version>RELEASE</version>
</dependency>
{% endhighlight %}
Hibernate Validator uses Java Unified Expression Language (JavaEL)
to format validation messages. When your application runs
inside JEE container, container already provides JavaEL 
implementation.
Since we want to create a command line application we must provide 
JavaEL implementation ourselves and that's the reason
why we included `javax.el:el-api` and `org.glassfish.web:javax.el` as
dependencies.

Later on to demonstrate all features of Hibernate Validator we will need
Spring DI container and `commons-beanutils` library:
{% highlight xml %}
<dependency>
    <groupId>commons-beanutils</groupId>
    <artifactId>commons-beanutils</artifactId>
    <version>1.9.3</version>
</dependency>
<dependency>
    <groupId>org.springframework</groupId>
    <artifactId>spring-context</artifactId>
    <version>4.3.5.RELEASE</version>
</dependency>
{% endhighlight %}

##### Obtaining `Validator` instance

After all these preparations we are ready to create `Validator`
instance:
{% highlight java %}
import javax.validation.Validation;
import javax.validation.Validator;

public static void main(String[] args) {
    Validator validator = Validation
                              .buildDefaultValidatorFactory()
                              .getValidator();
}
{% endhighlight %}
Note that we don't have any reference to Hibernate Validator in
our code, instead we are relying on classes and interfaces defined in
JSR 303 (Bean Validation).
This is very similar to how JDBC providers works.

Returned `Validator` instance is thread safe and may be assigned to
static field or registered as a singleton in DI container for later use.

#### Validating beans

##### Property level constraints

The easiest way to define validation rules for a bean
is to use JSR 303 annotations.
We may put annotations on both fields and getters, for example:
{% highlight java %}
public class Person {
    @NotNull           
    private String name;
}
// or:
public class Person {
    @NotNull
    public String getName() {             
        return name;                      
    }                                     
    public void setName(String name) {    
        this.name = name;                 
    }                                     
}
{% endhighlight %}
We should prefer putting annotations on getters since this will
allow for greater flexibility when later we will want to
change our beans.
Said that, to conserve space in this post I will
put annotations on fields from now on.

Here is a simple bean representing a person,
annotated with JSR 303 constraints:
{% highlight java %}
public class Person {
    @NotNull
    @Length(min=1)
    private String name;

    @NotNull
    @Length(min=1)
    private String surname;

    @Range(min=1, max=200)
    private int age;
  
    // getters, setters 
}
{% endhighlight %}
Validation rules should be self evident. There is nothing fancy -
we check that a person must have a non empty name and a non empty
surname, and that an age of a person falls within a range of 1 and 200.

Then we may use Hibernate Validator to check if 
a `Person` instance is valid:
{% highlight java %}
Validator validator = Validation
       .buildDefaultValidatorFactory()
       .getValidator();

Person joe = new Person();
joe.setName("Joe");
joe.setSurname("Doe");
joe.setAge(43);

Set<ConstraintViolation<Person>> constraintViolations =
       validator.validate(joe);

assert constraintViolations.size() == 0; // yeah, no errors
{% endhighlight %}

In rare cases when `Person` is invalid, Hibernate Validator
provides us with all necessary information about what
properties and values are wrong:
{% highlight java %}
Person joe = new Person();
joe.setName(null);
joe.setSurname("Doe");
joe.setAge(1024);

Set<ConstraintViolation<Person>> constraintViolations =
       validator.validate(joe);

for (ConstraintViolation<?> violation: constraintViolations) {
   System.out.format("%10s | %30s | is %10s%n",
           violation.getPropertyPath(),
           violation.getMessage(),
           violation.getInvalidValue()
           );
}
// OUTPUT:
//       age |      must be between 1 and 200 | is       1024
//      name |                may not be null | is       null
{% endhighlight %}

##### Bean level constraints

Some validation rules may be expressed only by using
values of two or more properties, for such rules 
Hibernate Validator provides class-level constrains.
Returning to our `Person` example, suppose that we want to add
two new properties to `Person`: `dateOfBirth` and `dateOfDeath`, with
condition that `dateOfBirth` cannot be later than `dateOfDeath`
(when both dates are present):
{% highlight java %}
public class Person {
    @NotNull
    private LocalDate dateOfBirth;
    private LocalDate dateOfDeath;
    
    // ...
}
{% endhighlight %}
We can express our rule using proprietary (not included in JSR 303)
class-level `@ScriptAssert` annotation:
{% highlight java %}
import org.hibernate.validator.constraints.ScriptAssert;

@ScriptAssert(lang = "javascript",
        script="_.dateOfBirth == null || _.dateOfDeath == null || _.dateOfBirth <= _.dateOfDeath",
        alias="_",
        message = "date of death cannot be before date of birth")
public class Person {
   // ...
} 
{% endhighlight %}
Here I decided to use JavaScript scripting engine (`lang = "javascript"`)
because it
is already shipped with Java SE, moreover JavaScript syntax should be
familiar to any Java developer. Hibernate Validator supports
any implementation adhering to JSR 223 standard
(scripting for the Java platform).

JavaScript expression used as value of `script` argument:
{% highlight javascript %}
_.dateOfBirth == null || 
   _.dateOfDeath == null || 
   _.dateOfBirth <= _.dateOfDeath
{% endhighlight %}
must *always* return either `true` when validation rule is
fullfiled or `false`.
We must also take care of handling `null` values otherwise we may
get pesky `javax.script.ScriptException`.

Inside `script` we may refer to currently validated bean by name of `_this`,
or by name of our choosing if we set `alias` argument like we do in
our example.

`@ScriptAssert` is a duct tape of validation. You should
use it only when performance is not a concern, and you must
provide a solution quickly. In most cases you should prefer
to write you own constraint and validator. Anyway `@ScriptAssert` is
a great example of class-level constraint.

##### Validating child beans

To demonstrate parent-child bean validation we will
add `Address` to `Person` class.
`Address` will be optional so not every `Person` instance will have one,
we only require that if a `Person` has an address it must be a
valid one.
`Address` will be represented by the following bean:
{% highlight java %}
public class Address {
    @NotBlank
    private String street;

    @NotBlank
    private String zipCode;

    @NotBlank
    private String city;

    // getter,setters
}
{% endhighlight %}
Also we must add `address` property to `Person` bean:
{% highlight java %}
public class Person {
    @Valid
    private Address address;
}
{% endhighlight %}
`@Valid` annotation that we put on `address` field
tells Hibernate Validator that
when validating a `Person` the `Address` should also be
validated, but only when address is provided (`address` is non null).
If we require that a `Person` must always have an address we may use
`@NotNull` to enforce that rule:
{% highlight java %}
public class Person {
    @NotNull
    @Valid
    private Address address;
}
{% endhighlight %}

Now when validating person with an invalid address we get:
{% highlight java %}
// ...
Address joeHomeAddress = new Address();
joeHomeAddress.setCity("Warsaw");
joeHomeAddress.setZipCode("00-120");
joe.setAddress(joeHomeAddress);

validator.validate(joe);
// CONSTRAINT VIOLATIONS:
// address.street |               may not be empty | is       null
{% endhighlight %}

##### Validating collections

To demonstrate how collection validation works
we will add a list of contacts
to `Person` bean:
{% highlight java %}
public class Person {
    @Valid
    private List<Contact> contacts;
    // getters,setters,...
}

public abstract class Contact { }

public class EmailContact extends Contact {
    @Email
    private String email;

    public EmailContact() { }
    public EmailContact(String email) {
        this.email = email;
    }

    public String getEmail() { return email; }
    public void setEmail(String email) { this.email = email; }
}

public class PhoneContact extends Contact {
    @Pattern(regexp = "\\d{3}-\\d{3}-\\d{3}",
             message = "invalid phone number")
    private String phoneNumber;

    public PhoneContact() { }
    public PhoneContact(String phoneNumber) {
        this.phoneNumber = phoneNumber;
    }

    public String getPhoneNumber() { return phoneNumber; }
    public void setPhoneNumber(String phoneNumber) { this.phoneNumber = phoneNumber; }
}
{% endhighlight %}
Again we used `@Valid` annotation to tell Hibernate Validator to
validate all non null beans contained in `contacts` collection.
Now we may check if all `Person` contacts are valid:
{% highlight java %}
joe.setContacts(Arrays.asList(
    new EmailContact("joe@example.com"),
    new PhoneContact("123-123-123"),
    new EmailContact("invalid_email"),
    new PhoneContact("invali_phone")
));

validator.validate(joe);
// CONSTRAINT VIOLATIONS:
// contacts[3].phoneNumber |           invalid phone number  | is invali_phone
// contacts[2].email       | not a well-formed email address | is invalid_email
{% endhighlight %}

Unfortunately there is no build-in annotation that would protect
us from collections containing `null`s:
{% highlight java %}
joe.setContacts(Collections.singletonList(null));
assert validator.validate(joe).size() == 0;
{% endhighlight %}
To fix that problem we must write a custom constraint ourselves.

##### Customizing validation messages

The easiest way to customize validation message is to
set it explicitly via 
`message` parameter:
{% highlight java %}
@Range(min=1, max=200, 
    message = "person age must be between 1 and 200 years")
private int age;
{% endhighlight %}
This approach is inflexible and you should avoid it, instead
try to load validation messages from application resources.
Hibernate Validator by default will load validation messages from
`resources/ValidationMessages.properties` file.
We may use this file to either add new validation message or
customize existing:
{% highlight no-highlight %}
# Override existing message
org.hibernate.validator.constraints.Range.message=${validatedValue} is not in range (min: {min}, max: {max})

# Create new message
invalid_person_age=person age must be between 1 and 200 years 
{% endhighlight %}
Then we may use are new message:
{% highlight java %}
@Range(min=1, max=200, message = "{invalid_person_age}")
private int age;
{% endhighlight %}

#### Extending Hibernate Validator

##### Constraint composition

Earlier we used the following code to validate phone number:
{% highlight java %}
@Pattern(regexp = "\\d{3}-\\d{3}-\\d{3}",
         message = "invalid phone number")
private String phoneNumber;
{% endhighlight %}
We certainly don't want to repeat this annotation with regex expression and
message accross all codebase, that would violate 
[DRY principle](https://en.wikipedia.org/wiki/Don't_repeat_yourself).
On the other hand the following code validated person name:
{% highlight java %}
@NotNull
@Length(min=1)
private String name;
{% endhighlight %}
Here we see that to validate name we need two constraints, again
repeating two constraints in various DTO's is not a receipt for
a good code.

To solve above problems JSR 303 introduces constraint composition.
In short you create a new constraint annotation and put
on it all required constraints, you may also adjust
message, payload and/or groups to which constraint belongs.
For example we may create `ValidPhoneNumber` constraint:
{% highlight java %}
@Pattern(regexp = "\\d{3}-\\d{3}-\\d{3}")
@ReportAsSingleViolation
@Constraint(validatedBy = { })
@Target({ METHOD, FIELD, ANNOTATION_TYPE })
@Retention(RUNTIME)
@Documented
public @interface ValidPhoneNumber {
    String message() default "phone number should be in format 999-999-999";
    Class<?>[] groups() default { };
    Class<? extends Payload>[] payload() default { };
}
{% endhighlight %}
And then use it accross our codebase:
{% highlight java %}
public class PhoneContact extends Contact {
    @ValidPhoneNumber
    private String phoneNumber;
    //...
}
{% endhighlight %}
Not only this adheres to DRY princible but our code
is now more readable.

When we put multiple constraints on composed constraint:
{% highlight java %}
@NotNull
@Length(min=1)
@Target({ METHOD, FIELD, ANNOTATION_TYPE })
@Retention(RUNTIME)
@Constraint(validatedBy = { })
@Documented
// @ReportAsSingleViolation
public @interface ValidPersonName {
    String message() default "person must have a name";
    Class<?>[] groups() default { };
    Class<? extends Payload>[] payload() default { };
}
{% endhighlight %}
And then use it on a field:
{% highlight java %}
@ValidPersonName
private String name;
{% endhighlight %}
Each of composing constrains will be reported independently:
{% highlight java %}
Person joe = new Person();
joe.setName("");
//       name | length must be between 1 and 2147483647 | is     

joe.setName(null);
//       name |                may not be null | is       null
{% endhighlight %}
We may add `@ReportAsSingleViolation` annotation to our
composed constrain to report all violations as a single error.
With `@ReportAsSingleViolation` we get:
{% highlight java %}
Person joe = new Person();
joe.setName("");
//       name |        person must have a name | is       
joe.setName(null);
//       name |        person must have a name | is       null
{% endhighlight %}
Notice that this time message was taken from composed constraint.

##### Using payloads

We may use payloads to pass some additional informations
with validation errors. Canonical example of using payloads is
to differentiate between errors and warnings.

First we must define our payload values:
{% highlight java %}
import javax.validation.Payload;

public interface SEVERITY {
    interface WARNING extends Payload { }
    interface ERROR extends Payload { }
}
{% endhighlight %}
Then we may use them with constraints:
{% highlight java %}
import io.mc.validationdemo.constraints.SEVERITY.ERROR;
import io.mc.validationdemo.constraints.SEVERITY.WARNING;
import org.hibernate.validator.constraints.NotBlank;

public class SeverityDTO {
    @NotBlank(payload = ERROR.class)
    public String important;
    
    @NotBlank(payload = WARNING.class)
    public String unimportant;

    // ...
}
{% endhighlight %}
Finally we may use them to decide if given `ConstraintViolation`
is warning or error:
{% highlight java %}
public static boolean isWarning(ConstraintViolation<?> violation) {
    boolean isWarning = violation.getConstraintDescriptor()
            .getPayload()
            .contains(SEVERITY.WARNING.class);

    return isWarning;
}
{% endhighlight %}

I am certain that you will find some creative usages of payloads
in you application.

##### Creating new constraints

To demonstrate how to create a new constraint,
we will create `@NotContain` validation rule that
checks that `String` doesn't contains specified value.

We will start by creating annotation (here it is best
to follow example from [official documentation](https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/#validator-customconstraints-constraintannotation)):
{% highlight java %}
@Target({FIELD, METHOD, ANNOTATION_TYPE})
@Retention(RUNTIME)
@Documented
@Constraint(validatedBy = NotContainValidator.class)
public @interface NotContain {
    String message() default "{validation.NotContain}";
    Class<?>[] groups() default { };
    Class<? extends Payload>[] payload() default { };
    String value();

    @Target({ FIELD, METHOD, ANNOTATION_TYPE })
    @Retention(RUNTIME)
    @Documented
    @interface List {
        NotContain[] value();
    }
}
{% endhighlight %}
Then we must implement `NotContainValidator`:
{% highlight java %}
public class NotContainValidator 
    implements ConstraintValidator<NotContain, String>
{
    private String bannedPhrase;
    public void initialize(NotContain constraintAnnotation) {
        bannedPhrase = constraintAnnotation.value();
    }

    public boolean isValid(String value, ConstraintValidatorContext context) {
        boolean isValid =
            value == null || !value.contains(bannedPhrase);
        return isValid;
    }
}
{% endhighlight %}
Then we should define our validation message
in `resources/ValidationMessages.properties` file, and we are done:
{% highlight java %}
public class Person {
    @ValidPersonName
    @NotContain("f**k")
    private String name;
    // ...
}

Person joe = new Person();
joe.setName("f**k");

validator.validate(joe);
// VIOLATED CONSTRAINTS:
// name | Property should not contain f**k | is       f**k
{% endhighlight %}

##### Value unwrappers

Sometimes we want to validate value that is contained in some other
type. For example we may want to validate a `String` contained
in `Optional<String>`.
This is possible in Hibernate Validator thanks to value unwrappers.

Hibernate Validator out of the box supports `Optional<T>` type, so
for a sake of example we will create our own "wrapper" type:
{% highlight java %}
public class Box<T> {
    private T value;

    public T getValue() {
        return value;
    }
    public void setValue(T value) {
        this.value = value;
    }
}
{% endhighlight %}
Now we may use our wapper type in DTOs:
{% highlight java %}
public class UnwrappingDTO {
    @Length(min=3,max=10)
    private Box<String> name;

    @Min(1)
    private Box<Long> age;

    // getters, setters 
}
{% endhighlight %}
If we try to validate `UnwrappingDTO` instance we will get
an exception:
{% highlight no-highlight %}
javax.validation.UnexpectedTypeException: HV000030: 
    No validator could be found for constraint 'Length' 
    validating type 'Box<String>'.
{% endhighlight %}
To make validation work again we must create are
own type unwrapper:
{% highlight java %}
public class BoxUnwrapper extends ValidatedValueUnwrapper<Box<?>> {
    @Override
    public Object handleValidatedValue(Box<?> property) {
        return property.getValue();
    }

    @Override
    public Type getValidatedValueType(Type type) {
        // return generic parameter T of Box<T>
        Class<?> clazz = (Class<?>)
                ((ParameterizedType)type).getActualTypeArguments()[0];

        return clazz;
    }
}
{% endhighlight %}
And register it in Hibernate Validatior framework:
{% highlight java %}
Validator validator = Validation.byProvider(HibernateValidator.class)
        .configure()
        .addValidatedValueHandler(new BoxUnwrapper())
        .buildValidatorFactory()
        .getValidator();
{% endhighlight %}
The last thing that we should do, is to annotate `Box<T>` properties with
`@UnwrapValidatedValue`:
{% highlight java %}
@Length(min=3,max=10)
@UnwrapValidatedValue
private Box<String> name;

@Min(1)
@UnwrapValidatedValue
private Box<Long> age;
{% endhighlight %}
And now we can validate `Box`ed values, yay!

##### Integrating Hibernate Validator with Spring DI

This section shows how to quickly integrate Hibernate Validator
with Spring. This is not the offical way of how you should integrate
with DI, just a quick and dirty solution that you may find helpful.
You have been warned. Also remember that Spring provides it's
own validation framework, fully complaint with JSR 303 and called
[Spring Validation](http://docs.spring.io/spring/docs/current/spring-framework-reference/html/validation.html#validation-beanvalidation).

First we must create validator factory and register it in Spring
and in Hibernate Validator framework:
{% highlight java %}
@Component
public class SpringConstrainValidationFactory 
implements ConstraintValidatorFactory {
    @Autowired
    private ApplicationContext context;

    @Override
    public <T extends ConstraintValidator<?, ?>> T getInstance(Class<T> key) {
        if (key.getPackage().getName().startsWith("javax.validation") ||
            key.getPackage().getName().startsWith("org.hibernate.validator"))
        {
            try {
                // create standard validators by calling
                // default constructor
                return key.newInstance();
            } catch (Exception ex) {
                throw new RuntimeException(ex);
            }
        }

        // Use Spring to create validator bean
        return context.getBean(key);
    }

    @Override
    public void releaseInstance(ConstraintValidator<?, ?> instance) {
        // DO NOTHING
    }
}
{% endhighlight %}
And in application configuration we should have:
{% highlight java %}
@Configuration
@ComponentScan("your.package.name")
public class AppConfig {
    @Bean
    public Validator getHibernateValidator(
        SpringConstrainValidationFactory factory)
    {
       Validator validatorEx = Validation.byProvider(HibernateValidator.class)
                .configure()
                .addValidatedValueHandler(new BoxUnwrapper())
                // register Spring based validator factory
                .constraintValidatorFactory(factory)
                .buildValidatorFactory()
                .getValidator();

       return validatorEx;
    }
}
{% endhighlight %}
Also do not forget to mark validators as `@Component`, now we may
use dependency injection inside validators.



	  ]]></description>
	</item>

	<item>
	  <title>Comparing with nullsFirst and nullsLast</title>
	  <link>//comparing-with-nullsFirst-and-nullsLast</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2017-01-14T01:00:00+01:00</pubDate>
	  <guid>//comparing-with-nullsFirst-and-nullsLast</guid>
	  <description><![CDATA[
	     Sorting in Java is easy:
{% highlight java %}
public class Data {
    private final String value;
    public Data(String value) {
        this.value = value;
    }
 
    public String getValue() { return value; }
 
    @Override public String toString() {
        return String.format("Data(%s)", this.value);
    }
}
 
public static void main(String[] args) {
   List<Data> listOfData = Arrays.asList(
          new Data("foo"),
          new Data("bar"),
          new Data("nyu"));
 
   listOfData.sort(comparing(Data::getValue));
   listOfData.forEach(System.out::println);
}
//OUTPUT:
// Data(bar)
// Data(foo)
// Data(nyu)
{% endhighlight %}
...unless we try to sort a collection containing null values:
{% highlight java %}
List<Data> listOfData = Arrays.asList(
       new Data("foo"),
       null,
       new Data("bar"),
       new Data("nyu"));
 
listOfData.sort(comparing(Data::getValue));
listOfData.forEach(System.out::println);
//OUTPUT:
// Exception in thread "main" java.lang.NullPointerException
//    at java.util.Comparator.lambda$comparing$77a9974f$1(Comparator.java:469)
{% endhighlight %}
Fortunately there is easy solution to this problem. But first we must
decide whenever we want `null`s to be first or last in sorted collection.
After we made our mind we may use nifty `nullsFirst` or `nullsLast`
decorators provided by `Comparator` interface:
{% highlight java %}
import static java.util.Comparator.*;
 
List<Data> listOfData = Arrays.asList(
       new Data("foo"),
       null,
       new Data("bar"),
       new Data("nyu"));
 
listOfData.sort(nullsFirst(comparing(Data::getValue)));
listOfData.forEach(System.out::println);
//OUTPUT:
// null
// Data(bar)
// Data(foo)
// Data(nyu)
{% endhighlight %}
`nullsFirst` is great example of decorator design pattern
(it adds functionality but doesn't change interface).
`nullsFirst` works by wrapping provided comparator in code similar to:
{% highlight java %}
public static <T> Comparator<T> nullsFirst(Comparator<T> comparator) {
  return (a, b) -> {
    if (a == null)
        return (b == null) ? 0 : -1;
 
    if (b == null)
      return 1;
 
    // a and b are not null here
    return comparator.compare(a, b);
  };
}
{% endhighlight %}

Previous example works great unless we try to sort a collection
containing `Data(null)`:
{% highlight java %}
List<Data> listOfData = Arrays.asList(
       new Data("foo"),
       new Data(null),
       new Data("bar"),
       new Data("nyu"));

listOfData.sort(nullsFirst(comparing(Data::getValue)));
listOfData.forEach(System.out::println);
//OUTPUT:
// Exception in thread "main" java.lang.NullPointerException
//  at java.util.Comparator.lambda$comparing$77a9974f$1(Comparator.java:469)
//  at java.util.Comparators$NullComparator.compare(Comparators.java:83)
{% endhighlight %}
But do not despair `nullsFirst` can help us again:
{% highlight java %}
listOfData.sort(nullsFirst(
    comparing(Data::getValue, nullsFirst(naturalOrder()))));

listOfData.forEach(System.out::println);
//OUTPUT:
// Data(null)
// Data(bar)
// Data(foo)
// Data(nyu)
{% endhighlight %}
Ta da! It works but readability suffers greatly... You may ask what is
this thing:
{% highlight java %}
comparing(Data::getValue, nullsFirst(naturalOrder()))
{% endhighlight %}
First: we use the following overload of `comparing` method:
{% highlight java %}
public static <T, U> Comparator<T> comparing(
   Function<? super T, ? extends U> keyExtractor,
   Comparator<? super U>            keyComparator)
{
    return (c1, c2) -> keyComparator.compare(
          keyExtractor.apply(c1),
          keyExtractor.apply(c2));
}
{% endhighlight %}
Second: in our example `nullsFirst(naturalOrder())` is a comparator that can
compare nullable `String`s:
{% highlight java %}
Comparator<String> cmp = nullsFirst(naturalOrder());
cmp.compare("foo", "zzz"); // -1
cmp.compare("foo", null);  // 1
{% endhighlight %}

Now everything should be clear (I hope).

To sum up in this post we get to know two
little methods `nullsFirst` and `nullsLast`.
I admit that they are a bit unintuitive to use, but definitely worth
to bear in mind.


	  ]]></description>
	</item>

	<item>
	  <title>Spring @Transactional cheat sheet</title>
	  <link>//spring-transactional-cheat-sheet</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2017-01-07T01:00:00+01:00</pubDate>
	  <guid>//spring-transactional-cheat-sheet</guid>
	  <description><![CDATA[
	     #### @Transactional(propagation=...)

`MANDATORY`
: Method must run within transaction. If there is no
currently active transaction going on an exception is thrown.

`REQUIRED`
: Method must run within transaction. If there is already started
transaction method will run within that transaction, otherwise
new transaction will be started.

`REQUIRES_NEW`
: Method must run within it's own transaction. Spring will
always create a new transaction for this method. If there is
already started transaction going on, it will be suspended for
duration of this method.

`NESTED`
: Method will be run within nested transaction. If no transaction is
present new transaction will be started, otherwise a nested transaction
will be started.

`NOT_SUPPORTED`
: Method should not run within transaction. If there is active transaction
going on it will be suspended for duration of this method call.

`NEVER`
: Method should not run within transaction.
An exception will be thrown if method is called and
there is active transaction going on.

#### @Transactional(isolation=...)

| Isolation Level | Dirty Reads | Nonrepeatable reads | Phantom reads |
| --------------- | :---------: | :-----------------: | :-----------: |
| `READ_UNCOMMITTED` | :x: | :x: | :x: |
| `READ_COMMITTED` | :heavy_check_mark: | :x: | :x: |
| `REPEATABLE_READ` | :heavy_check_mark: | :heavy_check_mark: | :x: |
| `SERIALIZABLE` | :heavy_check_mark: |:heavy_check_mark:|:heavy_check_mark: |

`DEFAULT` isolation level uses transaction isolation level provided
by underlying implementation.

Dirty Reads
: Transaction may read data written
but not yet committed by other transactions.

Nonrepeatable
reads
: Performing the same query twice may return different data.
Usually this happens because some other transaction
updated data and was successfully committed after first
but before second query.

Phantom reads
: When we query for set of rows twice second query may return
rows not present in result returned by first query.
Usually this happens because some other transaction inserted rows
to queried table and was successfully committed between our queries.

#### @Transactional(rollbackFor=..., noRollbackFor=)

By default transaction are rolled back only 
on uncaught runtime exceptions.
`rollbackFor` and `noRollbackFor` properties allows us to
set additional exceptions types for which transaction should
or should not rolled back.

#### @Transactional(readOnly=...)

Set `readOnly=true` when transaction doesn't write back
to database. This will allow underlying implementation to
possibly optimize data access.

This settings make sense only on methods that start new
transaction (with propagation `REQUIRED`, `REQUIRES_NEW` and `NESTED`).

#### @Transactional(timeout=...)

Transaction timeout in seconds.


	  ]]></description>
	</item>

	<item>
	  <title>Crudest CRUD using Spring</title>
	  <link>//crudest-curd-using-spring</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2016-12-27T01:00:00+01:00</pubDate>
	  <guid>//crudest-curd-using-spring</guid>
	  <description><![CDATA[
	     EDIT: In this post I'll use Spring XML configuration, in new
applications you should definitely use Spring JavaConfig configuration (via
annotations and Java classes).
For more info see reddit comment discussion [here](https://www.reddit.com/r/springsource/comments/5mjwa2/100_crudest_crud_using_spring_and_jdbc/).

In this blog post we will create simple CRUD (Create Retrieve Update Delete)
application using Spring and JDBC.
Before we start we need to setup our database.
I will assume that you already have Postgres running on your box.

#### Setup database

Because we want to follow good programming practices we will create a
separate user in Postgres database dedicated only for our application.
Open pgAdmin and execute following SQL to create user `crud`:
{% highlight sql %}
create user crud
  with password 'crud';
{% endhighlight %}
Next create `cruddb` database with `crud` as db owner:
{% highlight sql %}
create database cruddb
  with owner crud
       encoding 'utf-8';
{% endhighlight %}
Now it's time to switch to `cruddb` database and create
`app_data` table:
{% highlight sql %}
create table app_data (
  id serial primary key,
  index int not null,
  value text not null
);
{% endhighlight %}
We should create this table logged as `crud` user,
otherwise `curd` will be denied access to the table.
If you don't want to login as `curd` you may create
table from superuser account and then grant permissions
to `curd` user:
{% highlight sql %}
grant all on table app_data to crud

-- needed to autogenerate primary key
grant all on sequence app_data_id_seq to crud
{% endhighlight %}

#### Setup application

I assume that you already have Maven installed because
we are going to use it to create our CRUD application:
{% highlight no-highlight %}
$ mvn archetype:generate \
  -DgroupId="io.mc.crudapp" \
  -DartifactId=crudapp \
  -Dversion=1.0 \
  -DarchetypeArtifactId=maven-archetype-quickstart \
  -DinteractiveMode=false

$ tree crudapp/
crudapp
|-- pom.xml
`-- src
    |-- main
    |   `-- java
    |       `-- io
    |           `-- mc
    |               `-- crudapp
    |                   `-- App.java
    `-- test
        `-- java
            `-- io
                `-- mc
                    `-- crudapp
                        `-- AppTest.java

11 directories, 3 files
{% endhighlight %}
NOTE: Try to use `archetype:create` instead of `archetype:generate` if you
get an error using above command

Now we may load our application into our favorite IDE or just stick
to command line.

Since we will be using Spring and Postgres JDBC driver we need to
add them as a dependencies to our POM. We also want to use connection
pooling (database connections are expensive to create so we want to
reuse them whenever possible) so we will add a dependency on 
HikariCP library:
{% highlight xml %}
<!-- pom.xml -->
<dependencies>
   <dependency>
      <groupId>org.springframework</groupId>
      <artifactId>spring-context</artifactId>
      <version>4.3.5.RELEASE</version>
   </dependency>
   <dependency>
      <groupId>org.springframework</groupId>
      <artifactId>spring-jdbc</artifactId>
      <version>4.3.5.RELEASE</version>
   </dependency>

   <dependency>
      <groupId>org.postgresql</groupId>
      <artifactId>postgresql</artifactId>
      <version>9.4-1200-jdbc41</version>
   </dependency>

   <dependency>
      <groupId>com.zaxxer</groupId>
      <artifactId>HikariCP</artifactId>
      <version>2.5.1</version>
   </dependency>
</dependencies>
{% endhighlight %}
We should also change to using Java 8
so we may use lambdas and all cool stuff, we do this
by adding to our POM:
{% highlight xml %}
<properties>
   <maven.compiler.source>1.8</maven.compiler.source>
   <maven.compiler.target>1.8</maven.compiler.target>
   <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
</properties>
{% endhighlight %}
And finally we will use `exec-maven-plugin` 
to strightforward running our application from
command line:
{% highlight xml %}
<build>
  <plugins>
    <plugin>
      <groupId>org.codehaus.mojo</groupId>
      <artifactId>exec-maven-plugin</artifactId>
      <version>1.5.0</version>
      <executions>
        <execution>
          <goals>
            <goal>java</goal>
          </goals>
        </execution>
      </executions>
      <configuration>
        <mainClass>io.mc.crudapp.Main</mainClass>
      </configuration>
    </plugin>
  </plugins>
</build>
{% endhighlight %}
NOTE: You may find complete `pom.xml` in attached source code

You may write
{% highlight no-highlight %}
$ mvn clean install
{% endhighlight %}
to rebuild CURD application and
{% highlight no-highlight %}
$ mvn exec:java
{% endhighlight %}
to start it.

#### Setup Spring

Add following code to the `main` method:
{% highlight java %}
public class Main {
    public static void main(String[] args) {
        ClassPathXmlApplicationContext appContext =
                new ClassPathXmlApplicationContext(new String[] {
                        "spring/app-context.xml"
                });

        // We can use Spring context here

        appContext.close();
    }
}
{% endhighlight %}
We must also create `resource/spring/app-context.xml` file:
{% highlight xml %}
<?xml version="1.0" encoding="UTF-8"?>
<beans 
  xmlns="http://www.springframework.org/schema/beans"
  xmlns:context="http://www.springframework.org/schema/context"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://www.springframework.org/schema/beans     http://www.springframework.org/schema/beans/spring-beans-3.0.xsd     http://www.springframework.org/schema/context     http://www.springframework.org/schema/context/spring-context-3.0.xsd">
  <context:annotation-config />
</beans>
{% endhighlight %}

After these two steps we should have working Spring application.
Right now no beans are registered in Spring container, this will
change in the next section.

#### Setup Spring JDBC Data source

To enable Spring to access database
we must define data source in `app-context.xml`: 
{% highlight xml %}
<!-- Without pooling: -->
<bean id="dataSource"
    class="org.springframework.jdbc.datasource.DriverManagerDataSource">

  <property name="driverClassName" value="org.postgresql.Driver" />
  <property name="url" value="jdbc:postgresql://localhost:5432/cruddb" />
  <property name="username" value="crud" />
  <property name="password" value="crud" />
</bean>
{% endhighlight %}
`DriverManagerDataSource` class is provided by Spring as one
of several implementations of `DataSource` interface.
`DriverManagerDataSource` returns a new connection to database
every time application asks for a connection.
Connection is created using specified JDBC driver.
`SingleConnectionDataSource` is another DataSource implementation
provided by Spring
that returns always the
same connection (having single connection 
has serious implications in multithreaded
apps - when two threads want to
access database concurrently one of them must wait).

Now we may use `dataSource` bean to insert row into `app_data` table:
{% highlight java %}
final String sql = "insert into app_data(index,value) values(?,?)";

DataSource ds = appContext.getBean(DataSource.class);
try (Connection conn = ds.getConnection();
    PreparedStatement stmt =
         conn.prepareStatement(sql, Statement.RETURN_GENERATED_KEYS)) {

       stmt.setInt(1, 101);
       stmt.setString(2, "foo");

       stmt.executeUpdate();

       // retrieve id of inserted row
       try(ResultSet rs = stmt.getGeneratedKeys()) {
           rs.next();
           Long id = rs.getLong(1);
           System.out.println("id: " + id);
       }
}
catch (SQLException ex) {
   ex.printStackTrace();
}
{% endhighlight %}

#### Writing simple DAO

It is always a good idea to isolate data access code into
a separate component, in our case we will create `AppDataDAO` bean that
will be responsible for CURD operations on `app_data` table.

To make passing and retrieving data via `AppDataDAO` easier we will define
`AppData` class that will represent a single row from `app_data` table:
{% highlight java %}
public class AppData {
    private final int id;
    private final int index;
    private final String value;

    public AppData(int id, int index, String value) {
        this.id = id;
        this.index = index;
        this.value = value;
    }

    public int getId() { return id; }
    public int getIndex() { return index; }
    public String getValue() { return value; }
}
{% endhighlight %}
It is a good practice to program to interface, so
instead of creating a single bean `AppDataDAO` we will create
`AppDataDAO` interface and then provide an implementation:
{% highlight java %}
public interface AppDataDAO {
    int insert(int index, String value);
    void update(int id, int newIndex, String newValue);
    boolean delete(int id);
    List<AppData> selectAll();
}
{% endhighlight %}
Finally we may create `JDBCAppDataDAO` class that will implement `AppDataDAO`
interface:
{% highlight java %}
public class JDBCAppDataDAO implements AppDataDAO {
    private DataSource ds;
    
    @Autowired
    public JDBCAppDataDAO(DataSource ds) {
        this.ds = Objects.requireNonNull(ds);
    }

    private interface ConnectionConsumer<T> {
        T consume(Connection conn) throws SQLException;
    }

    private <T> T usingConnection(ConnectionConsumer<T> consumer) {
        Connection connection = DataSourceUtils.getConnection(ds);

        try {
            return consumer.consume(connection);
        }
        catch (SQLException ex) {
            throw new RuntimeException(ex);
        }
        finally {
            DataSourceUtils.releaseConnection(connection, ds);
        }
    }

    @Override
    public int insert(int index, String value) {
        return usingConnection(conn -> {
            String sql = "insert into app_data(index,value) values(?,?)";
            try (PreparedStatement stmt =
                    conn.prepareStatement(sql, PreparedStatement.RETURN_GENERATED_KEYS)) {
                stmt.setInt(1, index);
                stmt.setString(2, value);

                stmt.executeUpdate();

                try(ResultSet rs = stmt.getGeneratedKeys()) {
                    if (rs.next()) {
                        return rs.getInt(1);
                    }
                    else
                        throw new RuntimeException("no generated key!");
                }
            }
        });
    }
{% endhighlight %}
A few things to notice: logic responsible for acquiring and releasing
a db connection was encapsulated in `usingConnection` method.
Instead of getting connection straight from `DataSource` we use
`DataSourceUtils` class to get and release connection. This become important
when we later start using transactions, because transactions are
attached to connections we will no longer be responsible for creating
and closing connection - a transaction manager will do that for
us. When `DataSourceUtils` is asked for a new connection it first checks
if any transaction is running and if it is it returns connection used
by that transaction. If no transaction is active 
a new connection is created.

The last thing that we must do is to register our bean in Spring container:
{% highlight xml %}
 <bean name="AppDataDAO"
     class="io.mc.crudapp.JDBCAppDataDAO" />
{% endhighlight %}
and use it to insert a row:
{% highlight java %}
AppDataDAO appDataDAO = appContext.getBean(AppDataDAO.class);
appDataDAO.insert(102, "bar");
{% endhighlight %}

#### Using HikariCP

Opening a new connection to database is expensive operation.
Instead of constantly opening and closing connections we should
reuse them whenever possible. Because manually managing and resetting
connections
(before we can reuse connection we must reset it state - this will
for example clear any pending errors on connection) is error-prone
it is wise to use one of many connection pool libraries.
Here we will use HikariCP library (CP stands for Connection Pool).

Let's start by creating HikariCP configuration file `resources/db/hikari.properties`:
{% highlight no-highlight %}
dataSourceClassName=org.postgresql.ds.PGSimpleDataSource
dataSource.user=crud
dataSource.password=crud
dataSource.databaseName=cruddb
dataSource.portNumber=5432
dataSource.serverName=localhost
{% endhighlight %}
Then we must change our `dataSource` bean definition to:
{% highlight xml %}
<bean id="dataSource"
    class="com.zaxxer.hikari.HikariDataSource">
  <constructor-arg>
      <bean class="com.zaxxer.hikari.HikariConfig">
          <constructor-arg value="/db/hikari.properties" />
      </bean>
  </constructor-arg>
</bean>
{% endhighlight %}
That's all - now our application draws connections from connection pool!

#### Adding transactions to CRUD app

Let's clear `app_data` table:
{% highlight sql %}
truncate table app_data;
{% endhighlight %}
and exeucte the following code in `main`:
{% highlight java %}
AppDataDAO appDataDAO = appContext.getBean(AppDataDAO.class);
appDataDAO.insert(101, "foo");
someOperation();
appDataDAO.insert(102, "bar");

// given:
private static void someOperation() {
  throw new RuntimeException("uber error");
}
{% endhighlight %}
Of course running this program results in error and only one row
is inserted to database:
{% highlight sql %}
select * from app_data 
{% endhighlight %}
![select query result](assets/images/2017-01-07/select_result.png)

In real life application we often want to perform either all of
database operations or none of them. In our example this will mean that
we either want to insert both rows to db or none of them should be inserted.
Transactions can solve these problem for us. Transactions also offers
some level of isolation between database operations performed by
different users - but this topic is
beyond this simple tutorial.
For more information please [check Wikipedia](https://en.wikipedia.org/wiki/Isolation_(database_systems)).

Transactions are usually handled at application service level, we will
follow this pattern. As usually we will start by creating
`CRUDAppDemoService` interface:
{% highlight java %}
public interface CRUDAppDemoService {
    void doDemo();
}
{% endhighlight %}
Then we may write implementation of `CRUDAppDemoService`:
{% highlight java %}
public class CRUDAppDemoServiceImpl implements CRUDAppDemoService {
    private final TransactionTemplate txTemplate;
    private final AppDataDAO appDataDAO;

    @Autowired
    public CRUDAppDemoServiceImpl(
      TransactionTemplate txTemplate, AppDataDAO appDataDAO) {
        this.txTemplate = Objects.requireNonNull(txTemplate);
        this.appDataDAO = Objects.requireNonNull(appDataDAO);
    }

    @Override
    public void doDemo() {
        txTemplate.execute(ts -> {
            appDataDAO.insert(101, "foo");
            someOperation();
            appDataDAO.insert(102, "bar"); 

            return null;
        });
    }

    private static void someOperation() {
        throw new RuntimeException("uber error");
    }
}
{% endhighlight %}
To define boundaries of transaction we use Spring provided
`TransactionTemplate` class. All database operations executed
in callback passed to `execute` method
will be performed within transaction. In callback we have access
to `ts` parameter that allows us to manually rollback current transaction.

When we throw runtime exception from callback, transaction will be
rolled back automatically. This behaviour doesn't occur for
checked exceptions, if we want to rollback transaction in that case
we must catch exception manually and then invoke `ts.setRollbackOnly()`.

Before we can run this code we need to register `TransactionTemplate` and
`TransactionManager` in Spring container:
{% highlight xml %}
<bean name="transactionManager"
    class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
  <property name="dataSource" ref="dataSource" />
</bean>

<bean id="TransactionTemplate"
    class="org.springframework.transaction.support.TransactionTemplate"
    >
  <property name="transactionManager" ref="transactionManager" />
</bean>

<bean name="CRUDAppDemoService"
    class="io.mc.crudapp.CRUDAppDemoServiceImpl" />
{% endhighlight %}

Finally we may add to the `main` method:
{% highlight java %}
CRUDAppDemoService service = appContext.getBean(CRUDAppDemoService.class);
service.doDemo();
{% endhighlight %}
Again running our program results in error but this time neither of rows
is inserted in `app_data` table.
When we comment out call to `someOperation()` both rows
are inserted - just as we wanted.

#### Annotation driven transactions

Using `TransactionManager` is cumbersome so Spring provides a better
alternative, we may declare transaction boundaries using annotations.
Let's change our `CRUDAppDemoServiceImpl` class to:
{% highlight java %}
public class CRUDAppDemoServiceImpl implements CRUDAppDemoService {
    private final AppDataDAO appDataDAO;

    @Autowired
    public CRUDAppDemoServiceImpl(AppDataDAO appDataDAO) {
        this.appDataDAO = Objects.requireNonNull(appDataDAO);
    }

    @Override
    @Transactional(propagation = Propagation.REQUIRED)
    public void doDemo() {
        appDataDAO.insert(101, "foo");
        someOperation();
        appDataDAO.insert(102, "bar");
    }

    private static void someOperation() {
        throw new RuntimeException("uber error");
    }
}
{% endhighlight %}
We may see that `TransactionTemplate` is gone, and a new annotation
appeared on `doDemo()` method. `@Transactional` means that we
want to start transaction when we call this method and commit it
when we return from it. As with `TransactionTemplate` if method
trows `RuntimeException` transaction will be rolled back.
To `@Transactional` we pass a single parameter `Propagation.REQUIRED`
that means that we want Spring to use existing transaction if one
is currently active or start a new one otherwise.
If Spring will use already active transaction,
then transaction will be committed or rolled
back not at our method level but at method that started it.
`@Transactional` has
plenty of options you may want to consult official documentation to
see them all.

To make `@Transactional` work we also need to enable it in Spring
configuration file. First we must add `tx` namespace to Spring XML:
{% highlight xml %}
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:context="http://www.springframework.org/schema/context"
       xmlns:tx="http://www.springframework.org/schema/tx"
       xsi:schemaLocation="http://www.springframework.org/schema/beans
    http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
    http://www.springframework.org/schema/context
    http://www.springframework.org/schema/context/spring-context-3.0.xsd
    http://www.springframework.org/schema/tx
    http://www.springframework.org/schema/tx/spring-tx-2.0.xsd">
{% endhighlight %}
And then we must enable annotation driven transactions:
{% highlight xml %}
<tx:annotation-driven transaction-manager="transactionManager"/>
{% endhighlight %}
That's it! Now we can use transactions without using `TransactionTemplate`.

#### Source code

[DOWNLOAD SOURCE CODE](assets/data/2017-01-07/crudest_crud.zip)


	  ]]></description>
	</item>

	<item>
	  <title>Generics in Java</title>
	  <link>//generics-in-java</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2016-12-27T01:00:00+01:00</pubDate>
	  <guid>//generics-in-java</guid>
	  <description><![CDATA[
	     Generics were introduced with Java 6 and quickly
become indispensable tool of every Java programmer.
In this blog post I gathered the most important
facts about generics in Java. After reading this post you
you should be able to comfortable use generics in
your code.

#### Generic classes

We can declare generic `Pair` class using syntax:
{% highlight java %}
public class Pair<E1,E2> {
    private final E1 first;
    private final E2 second;

    public Pair(E1 first, E2 second) {
        this.first = first;
        this.second = second;
    }

    public E1 getFirst()  { return first;  }
    public E2 getSecond() { return second; }
}
{% endhighlight %}
Then we can use `Pair` as follows:
{% highlight java %}
// java 6:
Pair<String,Integer> p1 = new Pair<String,Integer>("foo", 10);
  
String first = p1.getFirst();
int second = p1.getSecond();
  
// java 7+ - using diamond operator <>
Pair<String,Integer> p2 = new Pair<>("foo", 10);
{% endhighlight %}
In Java 7 and later we can let compiler infer values of generic parameters
in `new` expression by using diamond operator (`<>`).

##### Bounds

We can reduce possible values of generic parameters by using bounds.
For example to reduce values of parameter `T` to types that
implement `Serializable` interface we can write:
{% highlight java %}
public class SerializableList<T extends Serializable> { }
{% endhighlight %}
When using bounds we are not limited to single type.
For example we may
require that types allowed for `T` must extend `MyBaseClass` and
implement `Serializable` and `Cloneable` interfaces:
{% highlight java %}
public class SerializableList2<
   T extends MyBaseClass & Serializable & Cloneable> { }
{% endhighlight %}
When we try to use `SerializableList` with types that doesn't
conform to our bounds we will get compile-time error:
{% highlight java %}
// ok
SerializableList<Integer> ints = new SerializableList<>();

// error: type argument java.lang.Object is not within bounds of type-variable T
SerializableList<Object> objs = new SerializableList<Object>();
{% endhighlight %}

##### Type erasure

In Java generics are implemented via type erasure, this means that
generics exists only in Java source code and not in JVM bytecode.
When Java compiler translates generic classes to bytecode it
substitutes generic parameters in class body with `Object`
or if generic parameter has bounds with value of the first bound.
For example our `Pair` class would be translated by compiler into:
{% highlight java %}
public class Pair {
    private final Object first;
    private final Object second;

    public Pair(Object first, Object second) {
        this.first = first;
        this.second = second;
    }

    public Object getFirst()  { return first;  }
    public Object getSecond() { return second; }
}
{% endhighlight %}
Compiler also inserts necessary casts, and converts between primitives 
and wrappers (e.g. between `int` and `Integer`) - a process
called (un)boxing. Continuing our example:
{% highlight java %}
pair = new Pair<String,Integer>("foo", 10);

String first = pair.getFirst();
int second = pair.getSecond();
{% endhighlight %}
is translated by compiler into:
{% highlight java %}
pair = new Pair("foo", 10);

String first = (String)pair.getFirst();
int second = ((Integer)pair.getSecond()).intValue();
{% endhighlight %}

Generics were implemented via type erasure to preserve binary
compatibility with pre Java 6 code (binary compatibility means that
your old code will work with generic types out of the box - you
don't need to change or recompile your legacy libraries).

##### Shortcomings of type erasure

Type erasure is not the best way to implement generics, and IMHO Java
should take a different approach (e.g. reification).
But Java didn't and we are stuck with "type erasure" generics.
Below is a list of Java generics shortcomings:

* Primitive types like `int` cannot be used with generics.
 We may use generics with wrapper types e.g. `Integer` but this
 will incur performance penalty caused by casts and boxing/unboxing operations.
* We cannot use generic parameters in declarations of static class
 members. Static class members are shared between all instances of generic
 class regardless of generic parameters values. To stress this fact
 Java allows to access static members only via class name without
 generic parameters:

{% highlight java %}
class Example<T> {
    // error: non-static type variable T cannot be referenced from a static context
    // private static T last;

    private static int counter = 0;
    public static void printCounter() {
        System.out.println("counter: " + counter);
    }

    public Example() { counter++; }
}

new Example<Integer>();
new Example<String>();

// error: not a statement
// Example<Integer>.printCounter();

// prints counter: 2
Example.printCounter();
{% endhighlight %}

* Sometimes Java compiler must create synthetic methods
 (in this case called bridge methods) to make overriding
 work with generic types. For example:

{% highlight java %}
interface TestInterface<T> {
    void consume(T value);
}

class TestClass implements TestInterface<Integer> {
    @Override
    public void consume(Integer value) {
        System.out.println(value);
    }
}
{% endhighlight %}
after type erasure becomes:
{% highlight java %}
interface TestInterface {
	void consume(Object value);
}

class TestClass implements TestInterface {
    public void consume(Integer value) {
        System.out.println(value);
    }
}
{% endhighlight %}
and we can see that `TestClass` no longer overrides
`consume` method from `TestInterface`. To solve this
problem compiler adds following method to `TestClass`:
{% highlight java %}
class TestClass implements TestInterface {
   // bridge method added by compiler:
   @Override public void consume(Object value) {
	 this.consume((Integer)value);
   }

   public void consume(Integer value) { ... }
}
{% endhighlight %}

* Generics don't work well with overloading, for example following
 overloads are forbidden:

{% highlight java %}
public void check(List<Integer> ints) { }
public void check(List<String> strings) { }
{% endhighlight %}
because after type erasure both methods have exactly the same signature
{% highlight java %}
public void check(List list) { }
{% endhighlight %}

Similarly we cannot implement the same interface twice
with different generic parameters. Again type erasure is our culprit:
{% highlight java %}
public interface Test<T> { }
// error: Test cannot be inherited with 
//	  different arguments: <Integer> and <String>
public class TestImpl 
	implements Test<Integer>, Test<String> { }
{% endhighlight %}

##### Raw types and unchecked warnings

To maintain backward compatibility Java allows us to use generic types
without specifying generic parameters. Such types are called raw types,
for example:
{% highlight java %}
// preferred usage of generics:
List<Integer> typedList = new ArrayList<Integer>();

// raw type:
List rawList = new ArrayList<Object>();
rawList.add("foo"); // unchecked warning
{% endhighlight %}
Raw types can be treated like generic types after type erasure.
Raw types should only be used to interact with legacy code.

When working with raw types compiler may generate an unchecked warning:
{% highlight nohighlight %}
warning: unchecked call to add(E) as a member of the raw type java.util.List
{% endhighlight %}
This warning means that compiler is not sure if we used generic type
correctly and in case that we didn't we should expect `ClassCastException`
at runtime. For example:
{% highlight java %}
public static void main(String[] args) {
  List<Integer> ints = new ArrayList<Integer>();

  List rawList = ints;
  legacyCode(rawList);

  int x = ints.get(0); // ClassCastException
}

public static void legacyCode(List list) {
  list.add("foo"); // unchecked warning
}
{% endhighlight %}
The problem here is that the client of `legacyCode` expected that `legacyCode`
will add integer to provided list. A simple solution is to use
`List<Object>` instead of `List<Integer>`
if `legacyCode` may add different types to list.
Notice also that line which generated unchecked warning didn't throw
any exception, exception was thrown later when the
client wanted to access list element.

We may suppress unchecked warning at the method or class level by using
`@SuppressWarnings("unchecked")` annotation.

#### Generic methods

We can declare generic method as follows:
{% highlight java %}
public static <E1,E2> Pair<E1,E2> pair(E1 first, E2 second) {
   return new Pair<E1,E2>(first, second);
}
{% endhighlight %}

Generic methods are invoked like ordinary methods:
{% highlight java %}
Pair<String,Integer> p1 = pair("foo", 10);
{% endhighlight %}
In most cases compiler will be able to infer proper values of
generic parameters. When it won't we can override compiler by
explicitly specifying generic parameters values:
{% highlight java %}
ClassName.<String,Number>staticMethod(arg1, arg2);
// or
this.<String,Integer>instanceMethod(arg1, arg2);

// syntax error:
// <String,Integer>method(arg1, arg2);
{% endhighlight %}

#### Wildcards

Let's consider method that copies elements from one list to
another:
{% highlight java %}
public static <T> void copy(List<T> dest, List<T> src) {
   for (T element: src) {
	  dest.add(element);
   }
}
{% endhighlight %}
It works perfectly with lists of integers:
{% highlight java %}
List<Integer> src = Arrays.asList(1,2,3);
List<Integer> dest = new ArrayList<>();
copy(dest, src);
{% endhighlight %}
But fails when we want to copy integers to list of numbers:
{% highlight java %}
List<Integer> src = Arrays.asList(1,2,3);
List<Number> nums = new ArrayList<>();
// error: method cannot be applied to given types
copy(nums, src);
{% endhighlight %}
We may fix method by adding second generic parameter:
{% highlight java %}
public static <D,S extends D>
void copy(List<D> dest, List<S> src) {
   for (S element: src) {
	  dest.add(element);
   }
}
{% endhighlight %}
This is so common situation that Java introduces a shortcut:
{% highlight java %}
public static <T> void copy(List<T> dest, List<? extends T> src) {
  for (T element: src) {
	  dest.add(element);
  }
}
{% endhighlight %}
Type `List<? extends T>` means that this is a list of elements that
extends or implements type `T`.

Wildcards allows us to reduce number of required generic parameters and
made method declarations more clear, for example:
{% highlight java %}
public static <T> boolean isNullOrEmpty(Collection<T> coll) {
  return coll == null || coll.isEmpty();
}

public static boolean isNullOrEmptyWildcards(Collection<?> coll) {
  return coll == null || coll.isEmpty();
}
{% endhighlight %}
Here `Collections<?>` means collection of elements of some certain type 
e.g. this may be
`Collection<Object>` or `Collection<MyClass>`.

##### super bound

`super` bound may be used only with wildcards.
`super` bound restricts values of wildcard to given class
and all of its superclasses, for example method:
{% highlight java %}
void process(List<? super Integer> list) { }
{% endhighlight %}
can only be used with `List<Integer>`, `List<Number>` and `List<Object>`.
Calling method with `List<String>` results in compile time error.

While `extends` bound is useful when we want to get values
from generic type instance,
`super` bound is needed when we want to pass values to generic type instance.
For example:
{% highlight java %}
static <T> void produceConsume(
	  Producer<? extends T> producer,
	  Consumer<? super T> consumer)
{
  for(;;) {
	  T value = producer.produce();
	  consumer.consume(value);
  }
}
{% endhighlight %}
Here `Producer` may produce type `T` or more derived type, and `Consumer`
may consume type `T` or more general type e.g. `Object`. Thanks to
wildcards we may use `produceConsume` with `Producer<Integer>` and
`Consumer<Object>`.

NOTE: Java compiler tries to infer the most specific type for
generic parameters. In call to `produceConsume` with `Producer<Integer>`
and `Consumer<Object>` `Integer` will be used as `T` parameter value.

##### Wildcard capture

Let's say that we want to create a method that swaps elements of
the list, we may write:
{% highlight java %}
public static void swap(List<?> list, int i1, int i2) {
   // doesn't compile
   ? tmp = list.get(i1);
   list.set(i1, list.get(i2));
   list.set(i2, tmp);
}
{% endhighlight %}
Unfortunately above code doesn't compile. We may either
introduce generic parameter to method signature or create
a helper method with generic parameter that 
will "capture" wildcard value:
{% highlight java %}
public static void swap(List<?> list, int i1, int i2) {
   swapImpl(list, i1, i2);
}
private static <T> void swapImpl(List<T> list, int i1, int i2) {
   T tmp = list.get(i1);
   list.set(i1, list.get(i2));
   list.set(i2, tmp);
}
{% endhighlight %}

Introducing generic parameter is always better solution than
using wildcard capture. I only mention above technique because
it is often used in Java Collection Framework.

#### Covariance and contravariance

With Java arrays we may write:
{% highlight java %}
String[] strings = { "foo", "bar" };
Object[] objects = strings;
{% endhighlight %}
We say that Java arrays are covariant.

Generics in Java are invariant this means that below
code doesn't compile:
{% highlight java %}
List<String> strings = Arrays.asList("foo", "bar");
// error: incompatible types
List<Object> objects = strings;
{% endhighlight %}
We must tread `List<String>` and `List<Object>` as two
distinct types.

Still we may use wildcards to refer to either
`List<String>` or `List<Object>`:
{% highlight java %}
List<String> strings = Arrays.asList("foo", "bar");
List<Object> objects = Arrays.asList(true, 1, "foo");

List<?> list = strings;
list = objects;
{% endhighlight %}
`List<?>` should be treated as superclass of any `List<T>`,
because it represents list of objects of some certain type.

We can't do much with `List<?>`, we can only get `Objects` from it,
add `null`s and ask for size (operations allowed for any list):
{% highlight java %}
List<?> list = strings;

list.add(null);
Object value = list.get(0);
list.size();
{% endhighlight %}
Operations on `List<?>` are limited because we don't know what types list contains.
We may limit range of possible types with bounds thus gaining
more functionality:
{% highlight java %}
List<? extends Number> numbers = Arrays.asList(1.2, 3.5);
Number num = numbers.get(0);
{% endhighlight %}
Now compiler knows that list elements are at least numbers so
we may assign result of `get()` to variable of type `Number`.
Still we are not able to put anything beyond `null` into list,
because we don't know if this is a list of doubles or a list of integers.

When we want to add elements to list we should use `super` bound:
{% highlight java %}
List<? super Number> numbers =
   new ArrayList<Object>(Arrays.asList("foo", true));

numbers.add(3);
numbers.add(3.2);
{% endhighlight %}
Now compiler knows that list holds numbers or elements more general
than numbers e.g. objects, so adding number to list is safe.

#### How to use generic types with `instanceof` and `class` 

Because of type erasure types `List<Object>` and `List<Integer>` are
indistinguishable to JVM. To check if value is instance of `List` we
may write:
{% highlight java %}
Object value = new ArrayList<Integer>();

if (value instanceof List<?>) {
   // do something
}
{% endhighlight %}
Similarly types `List<Object>` and `List<Integer>` are represented
by the same class token:
{% highlight java %}
List<Integer> integers = new ArrayList<Integer>();
List<Object> objects = new ArrayList<Object>();

Class<? extends List> integersClazz = integers.getClass();
Class<? extends List> objectsClazz = objects.getClass();
Class<ArrayList> arrayListClazz = ArrayList.class;

// true
System.out.println(integersClazz.equals(objectsClazz));
// true
System.out.println(integersClazz.equals(arrayListClazz));
{% endhighlight %}
Notice that in instance test we should use type with wildcard (`List<?>`) but to
get class token we should use raw type (`ArrayList.class`).

#### Generics and arrays

Let's consider this innocent looking code:
{% highlight java %}
public static <T> T[] toArray(T v1) {
  T[] array = (T[]) new Object[1]; // unchecked warning
  array[0] = v1;
  return array;
}
{% endhighlight %}
Calling this method results in `ClassCastException`:
{% highlight java %}
String[] s = toArray("foo"); // class cast exception
{% endhighlight %}
Because we cannot assign `Object[]` instance to `String[]` variable.
The source of the trouble is type erasure again.
Because value of parameter `T` is not accessible at runtime
we don't know what array we should create - should it be array of
objects or maybe array of strings. We may fix this method by passing
additional parameter that will represent required type of array elements:
{% highlight java %}
public static <T> T[] toArray(T v1, Class<T> type) {
  T[] array = (T[]) Array.newInstance(type, 1);
  array[0] = v1;
  return array;
}

String[] s = toArray("foo", String.class);
{% endhighlight %}
Now method works as expected but is cumbersome to use.

Another problem with arrays and generics is that we cannot
create array with generic elements - type erasure is culprit again:
{% highlight java %}
// error: generic array creation
// List<Integer>[] lists = new List<Integer>[3];

List<Integer>[] lists = (List<Integer>[]) new List[3];
{% endhighlight %}
To create array of generic types we must use raw type and cast.

To sum up: you should avoid mixing arrays and generics.

#### Generics and varargs

Java varargs methods are implemented using arrays, when we try
to use varargs with generics:
{% highlight java %}
public static <T> List<T> concat(List<? extends T>... lists) {
   List<T> concatenated = new ArrayList<T>();

   for (List<? extends T> l: lists) {
	  concatenated.addAll(l);
   }

   return concatenated;
}
{% endhighlight %}
compiler issues a warning:
{% highlight nohighlight %}
warning: unchecked generic array creation for varargs parameter
{% endhighlight %}
Generic varargs suffer from the same problems as generic arrays.
If we are sure that our code is safe,
we may use `@SafeVarargs` annotation to suppress this warning.

#### Additional resources

If you want to know more about generics check resources below:

* [Java Generics and Collections: Speed Up the Java Development Process](http://a.co/5oMY1hY)
* [Java Generics FAQ](http://www.angelikalanger.com/GenericsFAQ/JavaGenericsFAQ.html)



	  ]]></description>
	</item>

	<item>
	  <title>Overview of Spring annotation driven AOP</title>
	  <link>//overview-of-spring-annotation-driven-aop</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2016-12-03T01:00:00+01:00</pubDate>
	  <guid>//overview-of-spring-annotation-driven-aop</guid>
	  <description><![CDATA[
	     In this post I will show you how to use Spring aspects.
In contrast to AspectJ aspects that are implemented by either
compile time or load time bytecode manipulation (process often called waving),
Spring aspects are implemented using proxy classes.
The main advantage of proxy aspect implementation is ease of use,
the main disadvantage is reduced functionality of aspects
(e.g. we cannot intercept calls to static methods).

Diagram below illustrates how proxy classes are used to
add functionality contained in `Aspect I` and `Aspect II` to 
`MyComponentImpl` class:
![Proxy based aspects in Spring](assets/images/2016-12-03/proxy2.svg)
When application asks Spring for `MyComponent`
implementation Spring detects that there are aspects attached to
`MyComponentImpl` class,
so instead of returning `MyComponentImpl` instance
Spring creates and returns a proxy.
Proxy returned to client implements `MyComponent` interface
and by default redirects all method calls to `MyComponentImpl` instance.
In some situations like e.g. calling a `doStuff()` method
proxy may execute code (called advice) from `Aspect I` and/or `Aspect II`,
thus adding functionality to `MyComponentImpl` class.

#### Application setup

Before we create our first aspect we need to setup our application.
Let's start with Maven dependencies. We will need `spring-aspects`
and `aspectjweaver` libraries.
You may be wondering why we need something from AspectJ which we
don't use. Spring Framework supports not only proxy based aspects
but also full blown AspectJ aspects, to avoid code duplication
designers of Spring decided to borrow annotation definitions like `@Aspect` 
from AspectJ project.
Thus `aspectjweaver` is only used as an annotation library and nothing more.
{% highlight xml %}
<dependency>
  <groupId>org.springframework</groupId>
  <artifactId>spring-core</artifactId>
  <version>4.3.3.RELEASE</version>
</dependency>
<dependency>
  <groupId>org.springframework</groupId>
  <artifactId>spring-context</artifactId>
  <version>4.3.3.RELEASE</version>
</dependency>

<dependency>
  <groupId>org.springframework</groupId>
  <artifactId>spring-aspects</artifactId>
  <version>3.2.0.RELEASE</version>
</dependency>

<dependency>
  <groupId>org.aspectj</groupId>
  <artifactId>aspectjweaver</artifactId>
  <version>1.8.9</version>
</dependency>
{% endhighlight %}

Next we need to create Spring configuration class and bootstrap
Spring context:
{% highlight java %}
package io.mc.springaspects;
import org.springframework.context.annotation.ComponentScan;

@Configuration
@ComponentScan("io.mc.springaspects")
@EnableAspectJAutoProxy
public class SpringConfiguration { }
{% endhighlight %}
NOTE: To enable proxy based aspects we need to add `@EnableAspectJAutoProxy`
annotation to our configuration class.

{% highlight java %}
public static void main(String... args) throws Exception {
   AnnotationConfigApplicationContext appContext = 
      new AnnotationConfigApplicationContext(
         SpringConfiguration.class);
  // context ready to use!!!
  appContext.close();
} 
{% endhighlight %}

#### Creating aspects

Before we start let's introduce some terminology. Advice is 
a piece of code that should be executed when certain event
like calling a method takes place. A pointcut is a set of
events, for example all calls to a method `foo()` contained in
class `Bar`. A join point is a single event for example a
particular invocation of method `foo()`
on line 105 in class `Bar`.
Aspect is a pointcut-advice pair, in other words aspect defines
what should be done (advice) and when (pointcut).
Spring borrowed this terminology from AspectJ, it takes a while
to get used to it.

We will start by crating `@Before` and `@After` aspects that
as their names suggest are invoked before and after a method call.
Our aspects will add functionality to the following component:
{% highlight java %}
package io.mc.springaspects;

@Component
public class DummyComponent {
    private final ConsoleLogger consoleLogger;
    
    @Autowired
    public DummyComponent(ConsoleLogger consoleLogger) {
        this.consoleLogger = consoleLogger;
    }

    public void doStuff() {
        consoleLogger.log("DummyComponent::doStuff");
    }
}
{% endhighlight %}

Let's start with `@Before` aspect
(here I use the same name for aspect and advice, but remember that they
are two different things):
{% highlight java %}
@Aspect
@Component
@Order(100)
public class DummyAspect {
    private final ConsoleLogger consoleLogger;
    
    @Autowired
    public DummyAspect(ConsoleLogger consoleLogger) {
        this.consoleLogger = consoleLogger;
    }
    
    @Pointcut("execution(* io.mc.springaspects.DummyComponent.doStuff())")
    protected void doStuff() { }
    
    @Before("doStuff()")
    public void beforeDoStuff(JoinPoint joinPoint) {
      // ...
    }
}
{% endhighlight %}
A few things to notice:

* `DummyAspect` class will contain definitions of our aspects, we may define
 many aspects inside a single class
* `DummyAspect` must be registered as a Spring component 
 (here I used `@Component` annotation).
 This also means that dependency injection works inside aspects
* Class must be marked with `@Aspect` annotation otherwise Spring will ignore
 our aspects
* Optionally we may provide `@Order` annotation that specifies order of aspects
 (e.g. when there is more than one aspect attached to a given method call).
 The higher the order value the more close the aspect is to the original method
 call, see the diagram below:

![Aspects order](assets/images/2016-12-03/order.svg)

Now let's see how `@Before` aspects works.
A pointcut defines a set of events (like calling a method) to which we want to
attach advices.
For example to create a pointcut that will "point" to every invocation of 
`DummyComponent::doStuff` method, we may write:
{% highlight java %}
@Pointcut("execution(* io.mc.springaspects.DummyComponent.doStuff())")
protected void doStuff() { }
{% endhighlight %}
This code creates named pointcut with `doStuff` name.
Strange expressions passed to `@Pointcut` annotation is
borrowed from AspectJ, it tells Spring that we want to
select method calls `execution`, of methods that may return any
type `*`, and are members of `io.mc.springaspects.DummyComponent` class,
and are named `doStuff`, and doesn't take any parameters `()`.

Now let's move to the advice:
{% highlight java %}
@Before("doStuff()")
public void beforeDoStuff(JoinPoint joinPoint) {
     consoleLogger.log("BEFORE CALL TO doStuff()");
     
     consoleLogger.log("ARGUMENTS:");
     Arrays.stream(joinPoint.getArgs())
         .map(Object::toString)
         .forEach(arg -> consoleLogger.log("\t%s", arg));
     
     consoleLogger.log("");
}
{% endhighlight %}
Advice is implemented as an instance method, first we
declare that this is a `@Before` advice - so it will be called
before target method. We also define where we want to use
advice by passing pointcut name to `@Before` annotation.
Advice method may optionally have a `JoinPoint` argument that
represents particular invocation of `doStuff()` method.
`JoinPoint` contains many useful informations
like `doStuff()` method arguments, or value of `this` reference.

Let's check if our aspect works:
{% highlight java %}
DummyComponent dummyComponent = 
  appContext.getBean(DummyComponent.class);
dummyComponent.doStuff();
// Output:
// BEFORE CALL TO doStuff()
// ARGUMENTS:
// 
// TestComponent::doStuff
{% endhighlight %}
Yay! It is but since `doStuff` doesn't have any parameters we
can't test arguments logging. We will fix that now, by adding 
a single parameter of type `String` to `doStuff` method:
{% highlight java %}
// DummyComponent:
public void doStuff(String x) {
   consoleLogger.log("TestComponent::doStuff(x), x = %s", x);
}
{% endhighlight %}
Since we changed method signature we must also change our pointcut definition:
{% highlight java %}
@Pointcut("execution(* io.mc.springaspects.DummyComponent.doStuff(..))")
protected void doStuff() { }
{% endhighlight %}
We are using `..` to tell Spring that method may have any number of arguments.
We may also specify exact number and types of arguments for example:
{% highlight java %}
@Pointcut("execution(* io.mc.springaspects.DummyComponent.doStuff(String))")
protected void doStuff() { }
{% endhighlight %}
With changed pointcut we now get:
{% highlight java %}
DummyComponent dummyComponent = 
  appContext.getBean(DummyComponent.class);
dummyComponent.doStuff("foo");
// Output
// BEFORE CALL TO doStuff()
// ARGUMENTS:
//  foo
//
// TestComponent::doStuff(x), x = foo
{% endhighlight %}

##### Extracting arguments

Sometimes we want to extract method argument value, instead
of manually extracting argument from `JoinPoint` we may ask Spring
to do this for us.
Let's add another parameter to `doStuff`:
{% highlight java %}
public void doStuff(String x, String y) {
  consoleLogger.log("TestComponent::doStuff(x, y), " +
    "x = %s, y = %s", x, y);
}
{% endhighlight %}
Then let's define another aspect:
{% highlight java %}
@Pointcut("execution(void io.mc.springaspects.DummyComponent.doStuff(String,String))" +
  "&& args(arg1,arg2)")
protected void doStuff2(String arg1, String arg2) { }
    
@Before("doStuff2(arg1, arg2)")
public void beforeDoStuff2(String arg1, String arg2) {
  consoleLogger.log("arg1 = %s, arg2 = %s", arg1, arg2);
}
{% endhighlight %}
Here we use `args` expression to bound method arguments to `arg1` and `arg2`
variables. Then we may use `arg1` and `arg2` as a parameters in aspect method.
Don't forget to add parameters to pointcut name in `@Before` annotation otherwise
you will get nasty exception with strange and unhelpful message.

##### Modifying method parameters

Aspects allow us to easily change values of method arguments.
For example given method:
{% highlight java %}
public void greetUser(String userName) {
  consoleLogger.log("Hello, %s", userName);
}
{% endhighlight %}
We may create aspect `toUpperCase` that will uppercase user name
before passing argument to target method.
Unfortunately `@Before` aspect is not powerful enough to do this,
we will need `@Around` aspect:
{% highlight java %}
@Pointcut("execution(* io.mc.springaspects.DummyComponent.greetUser(String))")
protected void greetUser() { }

@Around("greetUser()")
public void toUpperCase(ProceedingJoinPoint joinPoint) throws Throwable {
  Object[] originalArguments = joinPoint.getArgs();
  
  Object[] newArguments = new Object[1];
  newArguments[0] = ((String)originalArguments[0]).toUpperCase();
  
  joinPoint.proceed(newArguments);
}
{% endhighlight %}
`@Around` advice has a single parameter of type `ProceedingJoinPoint` that
represents pending target method invocation. This is very powerful feature since
it allows us to change method parameters and return value, wrap
thrown exceptions or even skip method call altogether.
Here we simply invoke target method with changed arguments using `ProceedingJoinPoint::proceed` call.

##### Modifying return value

Aspects allow us to change return value of a method.
For example let's add method to our `DummyComponent` class:
{% highlight java %}
public Collection<Integer> getNumbers(int  size) {
   if (size == 0)
      return null;

   return IntStream.range(0, size)
      .mapToObj(Integer::valueOf)
      .collect(toList());
}
{% endhighlight %}
Notice that for `size` equal zero `getNumbers` returns `null`.
Returning null instead of empty collection 
isn't good programming practice let's change that
behaviour using aspects.

We will start with already familiar `@Around` advice:
{% highlight java %}
@Pointcut("execution(* io.mc.springaspects.DummyComponent.getNumbers(int))")
protected void getNumbers() { }

@Around("getNumbers()")
public Object aroundGetNumbers(ProceedingJoinPoint joinPoint) throws Throwable {
  Object result = joinPoint.proceed();
  
  return (result == null)
    ? Collections.emptyList()
    : result;
}
{% endhighlight %}
If `@Around` advice method returns value then that 
value will be used as return value
of the target method, this is exactly what we do here.

If we only want to access return value we may also use 
`@AfterReturning` advice:
{% highlight java %}
@Pointcut("execution(* io.mc.springaspects.DummyComponent.getNumbers(int))")
protected void getNumbers() { }

@AfterReturning(pointcut="getNumbers()", returning="result")
public void add111(Collection<Integer> result) {
  if (result != null)
    result.add(111);
}
{% endhighlight %}
Here we cannot change returned value itself but we may call methods on it,
set properties etc.

##### Intercepting exceptions

We may use `@Around` advice to intercept, handle or wrap exceptions thrown
by target method (just add ordinary `try..catch` statement around
`proceed` call). Here we will concentrate on `@AfterThrowing` advice
that allows us to inspect exceptions thrown by target method.

In `DummyComponent` we must add method:
{% highlight java %}
public void doThrow() {
  throw new TestException(
    "TestException from TestComponent::doThrow");
}
{% endhighlight %}
We must also declare our exception class:
{% highlight java %}
package io.mc.springaspects;

public class TestException extends RuntimeException {
    private static final long serialVersionUID = 
        -7335805942545920111L;

    public TestException(String message) {
        super(message);
    }
}
{% endhighlight %}
And pointcut-advice pair:
{% highlight java %}
@Pointcut("execution(* io.mc.springaspects.DummyComponent.doThrow())")
protected void doThrow() { }

@AfterThrowing(pointcut="doThrow()", throwing="ex")
public void doThrowThrows(TestException ex) {
   consoleLogger.log("doThrow() THROWS EXCEPTION: %s",
        ex.getClass().getSimpleName());
}
{% endhighlight %}

##### Aspects and interface methods

So far we only attached advices to concrete classes like `DummyComponent`,
in real applications we often want to attach advices to all implementations
of given interface.
Fortunately for us Spring supports this scenario.
We will start by declaring `DummyInterface` interface 
and its two implementations:
{% highlight java %}
package io.mc.springaspects;

public interface DummyInterface {
    void dummyMethod();
}
{% endhighlight %}
{% highlight java %}
@Component("implA")
public class DummyInterfaceImplA implements DummyInterface {
    private final ConsoleLogger logger;
    @Autowired
    public DummyInterfaceImplA(ConsoleLogger logger) {
        this.logger = logger;
    }
    @Override
    public void dummyMethod() {
        logger.log("DummyInterface Implementation A");
    }
}
{% endhighlight %}
{% highlight java %}
@Component("implB")
public class DummyInterfaceImplB implements DummyInterface {
    ...
}
{% endhighlight %}

Now we may attach our advice to `DummyInterface::dummyMethod`:
{% highlight java %}
@Pointcut("execution(void io.mc.springaspects.DummyInterface+.dummyMethod())")
protected void dummyMethod() { }

@Before("dummyMethod()")
public void beforeDummyMethod(JoinPoint joinPoint) {
  String implementation =
          joinPoint.getTarget().getClass().getSimpleName();
  
  logger.log("Interface method called from class: %s", implementation);
}
{% endhighlight %}
In pointcut expression I used `DummyInterface+` to select
all classes that implement `DummyInterface`.
In pointcut expression we are not limited to a single method, we may use
`DummyInterface+.*(..)` expression to attach advice to all interface methods.

Let's check if our advice works:
{% highlight java %}
DummyInterface dummyInterface = 
    (DummyInterface) appContext.getBean("implB");
dummyInterface.dummyMethod();
// Output:
// Interface method called from class: DummyInterfaceImplB
// DummyInterface Implementation B
{% endhighlight %}

##### Aspects and annotations

Another common scenario in real life apps is to attach advices to
methods marked with given annotation.
Let's start by creating custom annotation:
{% highlight java %}
@Target(METHOD)
@Retention(RUNTIME)
public @interface UseAdviceOnThisMethod {
    String value() default "";
}
{% endhighlight %}
Then we must create test method in `DummyComponent` and mark it with
`@UseAdviceOnThisMethod` annotation:
{% highlight java %}
@UseAdviceOnThisMethod
public void someMethod() {
   consoleLogger.log("Hello, world!");
}
{% endhighlight %}
And finally we must create pointcut-advice pair:
{% highlight java %}
@Pointcut("execution(@io.mc.springaspects.UseAdviceOnThisMethod * *.*(..))")
protected void useAdviceOnThisMethodAnnotation() { }    

@Before("useAdviceOnThisMethodAnnotation()")
public void useAdviceBefore(JoinPoint joinPoint) {
  consoleLogger.log("[ASPECT] SOURCE LOCATION: %s",
      joinPoint.getSourceLocation());
}
{% endhighlight %}
In pointcut expression we use `* *.*(..)` to signify that we want
to consider methods with any return type, within any class, with any
name and taking any number and types of arguments.
But we also use `@io.mc.springaspects.UseAdviceOnThisMethod` expression
to point only to these methods that are annotated with `@UseAdviceOnThisMethod`.

Often in advice we want to access annotation to read some values from it.
To access annotation we may modify our `@Before` advice to:
{% highlight java %}
@Pointcut("execution(@io.mc.springaspects.UseAdviceOnThisMethod * *.*(..))")
protected void useAdviceOnThisMethodAnnotation() { }    

@Before("useAdviceOnThisMethodAnnotation() && @annotation(useAdvice)")
public void useAdviceBefore(JoinPoint joinPoint, 
                            UseAdviceOnThisMethod useAdvice) {
  consoleLogger.log("VALUE: %s", useAdvice.value());
}
{% endhighlight %}

##### Aspects and proxy unwrapping

Since Spring aspects are implemented using proxy classes we may
skip advice invocation by unwrapping Spring bean:
{% highlight java %}
DummyComponent dummyComponent = appContext.getBean(DummyComponent.class);
// advice called
dummyComponent.someMethod();
// unwrap target component - don't do this
// in real apps
dummyComponent = (DummyComponent) 
    ((Advised)dummyComponent).getTargetSource().getTarget();
// advice NOT called
dummyComponent.someMethod();
{% endhighlight %}

##### The End

We only scratched the surface of what Spring aspects can do,
and we only used basic expressions in pointcut definitions.
Aspect oriented programming is a huge topic and requires time
and practice to master. I hope that this blog post helped you to
understand what apects are and how to use them in Spring.
If you have any remarks how I can improve this post please leave a comment.

[DOWNLOAD SOURCE CODE](assets/data/2016-12-03/spring-aspects.zip)



	  ]]></description>
	</item>


</channel>
</rss>
