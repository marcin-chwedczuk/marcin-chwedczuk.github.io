<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>marcin-chwedczuk.github.io/</title>
   
   <link>http://localhost:4000</link>
   <description>A place where I share my thoughts about programming.</description>
   <language>en-uk</language>
   <managingEditor> </managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Cierpienia młodego Wertera czyli algorytm alfa-beta dla gry kółko i krzyżyk</title>
	  <link>//cierpienia-mlodego-wertera</link>
	  <author></author>
	  <pubDate>2020-08-06T02:00:01+02:00</pubDate>
	  <guid>//cierpienia-mlodego-wertera</guid>
	  <description><![CDATA[
	     W tym wpisie przyjrzymy się trudnościom które występują podczas
implementacji algorytmu alfa-beta dla gry kółko i krzyżyk.
Nie będę tutaj omawiał samego algorytmu, gdyż został on już dobrze
opisany w wielu innych miejscach, między innymi na
[Ważniaku](http://wazniak.mimuw.edu.pl/index.php?title=Sztuczna_inteligencja/SI_Modu%C5%82_8_-_Gry_dwuosobowe).
Zamiast tego skoncentrujemy się na technikach debugowania które można
będzie wykorzystać również przy innych grach np. warcabach.

Kod algorytmów alfa-beta i minimax jest powszechnie dostępny
w internecie czy to w postaci 
[pseudokodu](https://en.wikipedia.org/wiki/Alpha–beta_pruning#Pseudocode)
czy jako gotowa implementacja na [GitHubie](https://github.com/search?l=Java&q=alpha+beta+tictactoe&type=Repositories).

W trakcie przygotowań do stworzenia tego artykułu, ja również napisałem 
prostą implementację gry w kółko i krzyżyk. 
Kod mojej wersji algorytmu alfa-beta, podobnie jak cała gra, dostępny jest na 
[GitHubie](https://github.com/marcin-chwedczuk/xox/blob/master/src/main/java/pl/marcinchwedczuk/xox/game/AlphaBetaAlgo.java).

W dalszej części artykułu założymy że posiadana przez nas 
implementacja algorytmu alfa-beta jest poprawna, 
a mimo to program nie wykonuje prawidłowych ruchów podczas gry.

### Heurystyka czyli Serce algorytmu

Najważniejszą częścią algorytmu alfa-beta jest heurystyka czyli
funkcja oceniająca stan gry z punktu widzenia danego gracza.
Ogólna sygnatura heurystyki wygląda następująco:
{% highlight java %}
double score(GameState gameState, Player player)
{% endhighlight %}
Większe wartości zwracane przez funkcję odpowiadają lepszej
sytuacji gracza na planszy i na odwrót im mniejsza wartość
zwrócona tym położenie gracza jest gorsze.

Czasami przekazujemy do heurystyki również
inne pomocnicze informacje,
na przykład ostatni wykonany przez gracza ruch - jeżeli może to
przyspieszyć wykonywanie obliczeń.
Sama funkcja również może zwracać więcej danych, niż tylko samą ocenę sytuacji na polu gry.
Przykładowo heurystyka może także zwracać informację o zakończeniu gry i jej ewentualnym zwycięscy.
Wiele zależy tutaj od konkretnej gry, w przypadku gry w kółko i krzyżyk
obie te optymalizacje są możliwe.

W przypadku planszy 3x3 prosta heurystyka która zwraca `1` gdy gracz
wygrał i `0` w przeciwnym wypadku, w połączeniu z algorytmem alfa-beta
tworzy program z którym nie sposób wygrać.

Na koniec uwaga techniczna. Nakreślona powyżej funkcja heurystyki
traktuje w taki sam sposób zarówno gracza MAX
jak i gracza MIN. Dla poprawności działania algorytmu alfa-beta
konieczne jest zanegowanie wyniku zwróconego przez heurystykę dla
gracza MIN:
{% highlight java %}
var score = score(gameState, currentPlayer);
score = maximizingPlayer ? score : -score;
{% endhighlight %}

### Plansza 4x4, 3 pod rząd wygrywają

Uruchomienie powyższego algorytmu na planszy 4x4, gdy pierwszy ruch
należy do użytkownika przynosi jednak opłakane efekty.
Program zajmuje po prostu kolejne pola na planszy, a my nie mamy
najmniejszego problemu z wygraną.

![Dziwne zachowanie algorytmu](assets/images/2020-08-05/game1.png)
X - Użytkownik, O - Komputer

Dlaczego tak się dzieje? Okazuje się że przy grze 4x4, 3 pod rząd
istnieje strategia wygrywająca która pozwala pierwszemu graczowi
wygrać w dokładnie 3 ruchach.
![Strategia wygrywająca](assets/images/2020-08-05/str1.svg)

Z punktu widzenia algorytmu minimax każdy ruch skutkuje przegraną,
dlatego algorytm wybierze pierwszy lub ostatni ruch 
(w zależności od implementacji).
Pozwolę sobie nazwać to zjawisko depresją,
chociaż nie jest to powszechnie przyjęta terminologia.

Istnieje bardzo prosty sposób na wykrycie zjawiska depresji -
wystarczy zamienić kolejność graczy tj. pozwolić komputerowi wykonać
pierwszy ruch. Jeżeli spowoduje to nagłą poprawę sposobu działania algorytmu
należy sprawdzić czy przypadkiem gra nie faworyzuje gracza wykonującego
ruch jako pierwszy.

Istnieje jeszcze jedno proste ulepszenie które możemy wykonać.
Mianowicie jeżeli pozwolimy algorytmowi grać samemu ze sobą to
okaże się że "nie spieszy mu się do wygranej".
![Ilustracja problemu](assets/images/2020-08-05/str2.svg)
Ludzie zachowują się inaczej, chcemy wygrać jak najszybciej,
w jak najmniejszej ilości ruchów.
Możemy dodać to zachowanie do naszego algorytmu, modyfikując
funkcję heurystyki tak żeby "karała" gracza za każdy wykonany ruch.
Alternatywnie heurystyka może nagradzać gracza za każde 
pozostawione wolne pole na planszy:
{% highlight java %}
double impatientPlayerHeuristics(GameState gameState, Player player) {
    var score = score(gameState, currentPlayer);
    var freePlaces = gameState.board.countFreePlaces();
    return score + freePlaces*Q;
}
{% endhighlight %}
Stałą `Q` musimy dobrać w taki sposób żeby wyrażenie `freePlaces*Q` nigdy
nie przekraczało wartości zwracanej w przypadku wygranej przez 
funkcję `score`.
Na przykład jeżeli dla wygranej heurystyka zwraca `1000.0` to użycie
`Q = 1` jest rozsądnym wyborem.

Na koniec zauważmy że plansza 5x5, 3 pod rząd zawiera w sobie
planszę 4x4, 3 pod rząd, dlatego wszystko co powiedzieliśmy tutaj
o zjawisku depresji odnosi się również do niej.

### Plansza 4x4, 4 pod rząd wygrywaj

W przypadku plansz 4x4 i większych kluczowym problemem staje się wydajność.
Prostym sposobem na poradzenie sobie z tym problemem jest rezygnacja z
analizy całego drzewa gry i skupienie się na pierwszych N ruchach 
wykonywanych przez graczy.
W tym wypadku dobór odpowiedniej heurystyki staje się jeszcze bardziej ważny
ponieważ
oceniać musimy nie tylko gry zakończone, ale również takie
które wciąż trwają.
Z drugiej strony nadmierne skomplikowanie heurystyki negatywnie wpływa 
na złożoność obliczeniową i co za tym idzie na czas oczekiwania na wybór ruchu.

Jako kompromis możemy przyjąć na przykład analizę jedynie siedmiu
posunięć graczy w przyszłość, przy jednoczesnym rozbudowaniu heurystyki
o punktowanie "prawie zwycięstw". Prawie zwycięstwo to sytuacja na
planszy która w wyniku jednego ruchu czy posunięcia gracza zmienia się
w wygraną. W przypadku planszy 4x4, 4 pod rząd możemy przyjąć
że rząd, kolumna lub przekątna złożona z trzech znaków gracza i wolnego
miejsca jest prawie zwycięstwem np. `X _ X X` jest prawie zwycięstwem
dla gracza X.

W przypadku optymalizacji bardziej skomplikowanych gier nie obejdziemy się
bez dodatkowych narzędzi takich jak np. profiler.
Jednym z najlepszych, darmowych profilerów dostępnych na rynku dla platformy JVM
jest [async-profiler](https://github.com/jvm-profiling-tools/async-profiler).

Możemy również dużo zyskać unikając nadmiernych alokacji pamięci.
Na przykład zamiast tworzyć nową niemutowalną planszę za każdym razem gdy 
symulujemy ruch gracza, możemy wykorzystać mutowalną strukturę danych
wraz z wycofywaniem ruchów (ang. backtracking):
{% highlight java %}
for (Move playerMove: movesToCheck) {
    board.put(playerMove.position, playerMove.mark);

    // Do recursive minimax call and other stuff

    // Restore board state
    board.removeMark(playerMove.position)
}
{% endhighlight %}

### Plansza 5x5, 4 lub 5 pod rząd wygrywają

Na tym poziomie wydajność staje się elementem kluczowym.
Duża wielkość drzewa gry sprawia że strategie
bazujące na prawdopodobieństwie zaczynają wyglądać 
coraz bardziej interesująco.
Na przykład możemy użyć następującego algorytmu bazującego
na [metodzie Monte Carlo](https://pl.wikipedia.org/wiki/Metoda_Monte_Carlo),
do wygenerowania listy ruchów które będziemy oceniać:
{% highlight java %}
Set<Moves> getMovesToCheck(Board board, int depth) {
    // Cutoff - use heuristics to evaluate the board
    if (depth > 8) {
        return Set.of();
    }

    // For first 3 player moves we analyze every possibility
    var allPossibleMoves = board.getMovesForAllFreeFields()
    if (depth < 3) {
        return allPossibleMoves;
    }

    // Take K random moves to analyze
    return allPossibleMove.shuffle().take(K);

}
{% endhighlight %}

W przypadku gdy algorytm zwróci pustą listę ruchów do sprawdzenia,
po prostu oceniamy planszę za pomocą heurystyki i zwracamy to jako
wynik (pamiętając o negacji dla gracza MIN) z wywołania funkcji minimax.

### Jak to zdebugować? Generalne strategie debugowania

* Testy jednostkowe dla wykorzystywanych przez nas heurystyk to podstawa.
 Pisząc heurystyki dla gry kółko i krzyżyk bardzo łatwo o pomyłkę
 lub błąd w stylu "off by one". Dodanie testów i upewnienie się
 że pokrycie kodu testami jest odpowiednio wysokie powinno być
 pierwszym działaniem jakie podejmujemy podczas debugowania.
* Nasza aplikacja powinna posiadać funkcję umożliwiającą cofnięcie
 ostatnich ruchów gracza. Znacznie ułatwi to debugowanie za pomocą
 debuggera. W przypadku bardziej skomplikowanych gier typu warcaby
 warto dodać opcję zapisy i odczytu stanu gry do pliku.
* Warto dodać opcję gry komputer vs komputer, jak również wyboru
 kto stawia pierwszy ruch. Pozwala to lepiej ocenić działanie algorytmu.
* Zwracając optymalny ruch algorytm minimax zwraca tak naprawdę
 ścieżkę od korzenia do liścia w drzewie gry (korzeń reprezentuje
 obecną sytuację na planszy, liść przyszłą wygraną lub remis).
 Warto zalogować taką informację wypisując ją na konsole, bądź 
 zapisując do pliku. Pamiętajmy żeby zalogować tylko i wyłącznie
 ścieżkę dla wybranego ruchu. W przeciwnym wypadku możemy utonąć w
 powodzi informacji.

Na koniec zdradzę wam sekret debugowania, który pomoże wam rozwiązać
nie jeden problem: "Co dwie głowy to nie jedna!".
Jeżeli masz problem którego nie potrafisz sam rozwiązać poproś
drugą osobę o pomoc. I niech to nie będzie prośba na forum 
czy StackOverflow ale debugowanie ramie w ramie z drugim człowiekiem.
To naprawdę działa i mówię to mając na karku kilka lat solidnej
praktyki jako programista.

### Przykładowa aplikacja

Kod przykładowej aplikacji można znaleźć na 
[GitHubie](https://github.com/marcin-chwedczuk/xox/).

Aplikację najlepiej otworzyć w IntelliJ, importując ją 
jako projekt Gradle. Do edycji GUI niezbędny jest
[SceneBuilder](https://gluonhq.com/products/scene-builder/).

Jeżeli odkryjecie w aplikacji błąd proszę piszcie na 0xmarcin małpa gmail.com.

Sam kod aplikacji jest czytelny ale nie perfekcyjny. Jest jeszcze wiele
rzeczy które chciałbym poprawić. Jeżeli widzicie miejsce które
można poprawić nie bójcie się stworzyć pull request'a na GitHubie.
Gwiazdki są również mile widziane ;)

	  ]]></description>
	</item>

	<item>
	  <title>Nesting monads in Scala</title>
	  <link>//scala-nesting-monads</link>
	  <author></author>
	  <pubDate>2020-08-01T02:00:01+02:00</pubDate>
	  <guid>//scala-nesting-monads</guid>
	  <description><![CDATA[
	     Recently I write a lot of async code. Most of my repository
methods return types like `Future[Set[T]]` or `Future[Option[T]]`.
But as we will see, working with such types in pure Scala
can be very cumbersome.

For example in pure Scala we cannot write:
{% highlight scala %}
val namesFuture = Future.successful(List("bob", "alice"));

val capitalizedNames = for {
  names <- namesFuture
  name <- names
} yield name.capitalize
{% endhighlight %}
Nop. Nada. Will not work. When we try to compile this code,
the compiler will point out that `names` have type of `List[String]`
instead of expected `Future[X]`.

To understand the problem better lets remind ourselves
how Scala compiler translates for-comprehensions into
method calls:
{% highlight scala %}
val ks = for {
  i <- 1 to 10
  j <- 1 to i
  k <- 1 to j
  sum = i + j + k
  if (sum > 10 && sum < 20)
} yield 3*sum
// Is translated (with some simplifications) into:
val ks2 = (1 to 10).flatMap { i =>
  (1 to i).flatMap { j =>
    (1 to j)
      .map { k => i + j + k }
      .withFilter { sum => sum > 10 && sum < 20 }
      .map { sum => 3*sum }
  }
}
{% endhighlight %}
In short every but the last "assignment" of the form `var <- something` is
translated into `something.flatMap { var => ...`.
The last "assignment" is translated into a simple `map` call.
`if` filters are translated into `withFilter` or `filter` calls.

Returning to our first example we see that it is translated
into:
{% highlight scala %}
val capitalizedNames = for {
  names <- namesFuture
  name <- names
} yield name.capitalize
// into this:
val capitalizedNames = namesFuture.flatMap { names =>
  names.map(_.capitalize)
}
{% endhighlight %}
And indeed it does not type check as `namesFuture.flatMap` expects
that the passed lambda will return a `Future[X]` not
a `List[X]`.

We can quickly fix this problem by introducing a nested `for`
or by replacing `flatMap` by `map`:
{% highlight scala %}
val capitalizedNames = for { names <- namesFuture } yield
                       for { name <- names } yield name.capitalize;
// or:
val capitalizedNames = namesFuture.map { names =>
  names.map(_.capitalize)
}
// of if you are processing only a single collection:
val capitalizedNames = for { names <- namesFuture }
                       yield names.map(_.capitalize)
{% endhighlight %}
And even in this simple example, the method chain 
becomes quite unreadable when you try to
squash it into a single line: `namesFuture.map(_.map(_.capitalize))`.

Exactly the same problems appears when we try to work with `Future[Option[T]]`.
But here we can at least use libraries to reduce the pain.
For example using `OptionT` type from [Cats](https://typelevel.org/cats/),
we can write:
{% highlight scala %}
import cats.data.OptionT
import cats.implicits._

val nameFuture = Future.successful(Option("foo"))

val f = OptionT(nameFuture)
  .map(name => name + "!")
  .map(name => println(s"name is $name"))
Await.result(f.value, Duration.Inf)
{% endhighlight %}
...and call it a day. 

In pure Scala this code would look like this:
{% highlight scala %}
val f = nameFuture
  .map(_.map(name => name + "!"))
  .map(_.foreach(n => println(s"name is $n")))
Await.result(f, Duration.Inf)
{% endhighlight %}

In short I don't understand why language designers decided to not support
nested monads in for-comprehensions. It's a pity that we have to use
external libraries to get such a basic functionality.
	  ]]></description>
	</item>

	<item>
	  <title>Useful JDK tools (part 1)</title>
	  <link>//useful-jdk-tools-part-1</link>
	  <author></author>
	  <pubDate>2020-07-10T02:00:01+02:00</pubDate>
	  <guid>//useful-jdk-tools-part-1</guid>
	  <description><![CDATA[
	     JDK comes with a bunch of handy tools. It's good to
know about them. In this post we will take a look at
`jps`, `jstack`, `jmap` and `jhat`.

### jps

`jps` is a JVM counterpart to unix `ps` command.
By default `jps` prints process PID and 
the name of the main class
or the name of a jar file if the 
application was started using `java -jar` option.
{% highlight nohighlight %}
$ jps
54177 Jps
54173 App
54452 app.jar
{% endhighlight %}

But it can be more talkative. 
`-l` option adds a package name to the
main class name and a full/relative path to the jar filename.
`-m` option will print command line arguments passed to the program.
{% highlight nohighlight %}
$ jps -lm
54355 pl.marcinchwedczuk.app.App arg1 arg2 arg3
54452 build/libs/app.jar arg1 arg2 arg3
54458 jdk.jcmd/sun.tools.jps.Jps -lm
{% endhighlight %}

To print JVM switches we use `-v` option:
{% highlight nohighlight %}
$ jps -v
54654 app.jar -Xmx32m -Xms32m
54657 Jps -Dapplication.home=... -Xms8m ...
{% endhighlight %}

### jstack

`jstack PID` can be used to print current stack traces of
all threads running in java process.
You can also print stack traces from a core dump file.
The output of `jstack` command is often referred to
as a _thread dump_.

Thread dumps are invaluable resources when it comes to debugging
nasty deadlocks that show up only on the production servers.
On the other hand the number of threads in a serious java application
can be overwhelming. To make the most of thread dumps, you
need to give threads meaningful names. You should give names 
(via `Thread::setName`) at least to the threads that you create 
yourself and 
you should also supply a "thread naming" `ThreadFactory` when creating
new thread pools (e.g. `newFixedThreadPool(int nThreads, ThreadFactory threadFactory)`).

Let's create a simple app that deadlocks and see what `jstack`
will print:
{% highlight java %}
public static void main(String[] args) throws InterruptedException {
	Lock l1 = new ReentrantLock();
	Lock l2 = new ReentrantLock();

	var t1 = new Thread(() -> {
		Thread.currentThread().setName("AppThread#1");
		l1.lock();
		try {
			Thread.sleep(1000);
		} catch (InterruptedException e) {
			Thread.currentThread().interrupt();
		}
		l2.lock();
	});

	var t2 = new Thread(() -> {
		Thread.currentThread().setName("AppThread#2");
		l2.lock();
		try {
			Thread.sleep(1000);
		} catch (InterruptedException e) {
			Thread.currentThread().interrupt();
		}
		l1.lock();
	});

	t1.start(); t2.start();
	t1.join(); t2.join();
}
{% endhighlight %}
EDIT: I was tired when I wrote this code. It will deadlock
both threads
say 99% of time but not always. Instead of `sleep` I should use
`CountDownLatch`. I leave the code as it is as I don't want to regenerate
thread dumps but I wanted to point out this problem.

For readability I had to shorten `jstack` output.
{% highlight nohighlight %}
$ jstack `jps | grep App | cut -d ' ' -f 1`

"main" #1 prio=5 os_prio=31 cpu=46.25ms elapsed=85.17s tid=0x00007fb623810800 nid=0x1803 in Object.wait()  [0x000070000027a000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(java.base@14.0.1/Native Method)
	...
	at java.lang.Thread.join(java.base@14.0.1/Thread.java:1371)
	at pl.marcinchwedczuk.bzzz.App.main(App.java:37)

"AppThread#1" #13 prio=5 os_prio=31 cpu=1.30ms elapsed=85.12s tid=0x00007fb622031000 nid=0x9b03 waiting on condition  [0x00007000014b3000]
   java.lang.Thread.State: WAITING (parking)
	at jdk.internal.misc.Unsafe.park(java.base@14.0.1/Native Method)
	...
	at java.util.concurrent.locks.ReentrantLock.lock(java.base@14.0.1/ReentrantLock.java:322)
	at pl.marcinchwedczuk.bzzz.App.lambda$main$0(App.java:22)
	at pl.marcinchwedczuk.bzzz.App$$Lambda$1/0x0000000800b65840.run(Unknown Source)
	at java.lang.Thread.run(java.base@14.0.1/Thread.java:832)
...
Found one Java-level deadlock:
=============================
"AppThread#1":
  waiting for ownable synchronizer 0x00000007ffd92998, (a java.util.concurrent.locks.ReentrantLock$NonfairSync),
  which is held by "AppThread#2"

"AppThread#2":
  waiting for ownable synchronizer 0x00000007ffd92968, (a java.util.concurrent.locks.ReentrantLock$NonfairSync),
  which is held by "AppThread#1"
...
{% endhighlight %}
Notice that JVM was able to detect the deadlock, saving us a hours
of debugging. If you have a heisenbug you may consider running
`jstack` periodically and searching its output for `Found * deadlock` lines.

Now let's see how we can extract thread dumps for a core dump.
And for that we need a core dump.

Here I will describe how to make a core dump on macOS 10.15
(this is based on [this article](https://developer.apple.com/library/archive/technotes/tn2124/_index.html#//apple_ref/doc/uid/DTS10003391-CH1-SECCOREDUMPS))
First we need to execute `ulimit -c unlimited` in the shell
to remove the file size limit on created core-dump files.
A simple crashing hello world C program can create about 2GB core dump,
Java cores can have sizes of 10GB or more.
Then we need to set appropriate
permissions for `/cores` directory:
{% highlight nohighlight %}
$ sudo chmod 1777 /cores
# Test if we have enough permissions
$ echo 1 > /cores/test
{% endhighlight %}
TIP: `1` in `1777` is for [sticky bit](https://en.wikipedia.org/wiki/Sticky_bit).
If a directory has this bit set then 
only the owner of a file contained in that directory
can remove or rename that file.
If we additionally create a file with `700` permissions 
then nobody beyond us will be able to change or
remove the file.

Then _in the same_ shell in which we executed `ulimit -c unlimited`
we have to run a java application and in a new
terminal window we need to send `SIGSEGV` to that app:
{% highlight nohighlight %}
$ kill -SIGSEGV PID
{% endhighlight %}
After being hit by `SIGSEGV` Java should crash with a message:
{% highlight nohighlight %}
$ java -jar build/libs/bzzz.jar
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00007fff6f4cfdfa, pid=55303, tid=775
...
# Core dump will be written. Default location: /cores/core.56128
...
{% endhighlight %}
It may take a while to write 10GB+ file on disk so be patient.

Now for some reason I was not able to take a core dump from
official Oracle distribution of JDK. When I used OpenJDK
build everything worked perfectly. Now when I switched to OpenJDK
I have to use OpenJDKs `jstack` to analyze the core dump.
{% highlight nohighlight %}
$ export PATH=/usr/local/Cellar/openjdk/14.0.1/bin:$PATH
$ jhsdb jstack --core /cores/core.56128 \
	 --exe /usr/local/Cellar/openjdk/14.0.1/bin/java

"main" #1 prio=5 tid=0x00007fb4c300c000 nid=0x1d03 in Object.wait() [0x00007000027db000]
   java.lang.Thread.State: WAITING (on object monitor)
   JavaThread state: _thread_blocked
 - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
	- waiting on <0x000000061fe55d88> (a java.lang.Thread)
 - java.lang.Thread.join(long) @bci=72, line=1303 (Interpreted frame)
	- locked <0x000000061fe55d88> (a java.lang.Thread)
 - java.lang.Thread.join() @bci=2, line=1371 (Interpreted frame)
 - pl.marcinchwedczuk.bzzz.App.main(java.lang.String[]) @bci=57, line=37 (Interpreted frame)
...
{% endhighlight %}
For some reason in OpenJDK 14 the command `jstack /path/to/java coredump`
did not work. Instead I have to use a new tool introduced in JDK9
called `jhsdb`. Anyway the result is the same, we managed to
get thread dumps from the core dump. Again the tool was smart enough
to point out the deadlock (not visible on attached listing).

OK lets cleanup our system and revert the settings:
`ulimit -c 0`, `rm /cores/*` and `sudo chmod 1775 /cores`.

### jmap

`jmap` can be used to display various info about
Java process heap. For example we may take a heap 
histogram, which tells us number of instances and
total memory size taken per class.
{% highlight nohighlight %}
$ jmap -histo $PID | head
No dump file specified
 num     #instances         #bytes  class name (module)
-------------------------------------------------------
   1:           965        2775128  [I (java.base@14.0.1)
   2:          7555         399568  [B (java.base@14.0.1)
   3:          7324         175776  java.lang.String (java.base@14.0.1)
   4:          1295         160512  java.lang.Class (java.base@14.0.1)
   5:           964          88712  [Ljava.lang.Object; (java.base@14.0.1)
   6:          1872          59904  java.util.HashMap$Node (java.base@14.0.1)
{% endhighlight %}

But the real power of `jmap` lies in its ability
to take heap dumps:
{% highlight nohighlight %}
$ jmap -dump:live,format=b,file=heapdump $PID
Dumping heap to /path/to/heapdump ...
Heap dump file created [4264220 bytes in 0.018 secs]
{% endhighlight %}
Heapdumps can then be comfortably opened and analyzed in tools like
[Eclipse Memory Analyzer](https://www.eclipse.org/mat/).

![Eclipse Memory Analyzer](assets/images/2020-07-10/ema.png)

Heapdumps can be quite huge, if you want to move them between
servers remember to first compress them to speed things up.
They also contain sensitive data like AWS access
keys and user passwords, so please keep them secure.

TIP: You can also generate heapdumps on
out of memory errors using `-XX:+HeapDumpOnOutOfMemoryError` JVM switch.

EDIT: Since JDK9 the recommended way of generating heapdumps
changed. You may want to see [this article on InfoQ](https://www.infoq.com/news/2015/12/OpenJDK-9-removal-of-HPROF-jhat/).

### jhat

Now what if you don't want/have permissions to install fancy heapdump analyzers?
Not all is lost, we may still use primitive but working `jhat`.
Run `jhat heapdump` to start `jhat` HTTP server with basic
heapdump browser.

EDIT: Unfortunately `jhat` was removed in JDK9.
	  ]]></description>
	</item>

	<item>
	  <title>iTerm2 cheat sheet</title>
	  <link>//iterm2-cheat-sheet</link>
	  <author></author>
	  <pubDate>2020-07-08T02:00:01+02:00</pubDate>
	  <guid>//iterm2-cheat-sheet</guid>
	  <description><![CDATA[
	     iTerm2 is one of the best terminal emulators out there.
But to appreciate its full power you should know how to
use it effectively.
Here are shortcuts that I find indispensible while working with iTerm2.

#### Working with panes

* `Command + D` - Split vertically
* `Command + Shift + D` - Split horizontally
* `Command + W` - Close pane

* `Command + Option + Arrows` - Navigate between panes
* `Control + Command + Arrow` - Resize current pane
* `Command + Shift + Enter` - Maximize current pane / Restore its original size

* `Command + K` - Clear current pane

#### Text editing

* `Control + A` - Move to the line beginning
* `Control + E` - Move to the line end

Consider enabling "Natural Text Editing" (instructions [here](https://apple.stackexchange.com/a/293988))
if you want to use `Option + Left/Right Arrow` for
one word forward/backward navigation instead of
awkward `Control+] F` / `Esc F` (Escape followed by F for forward or
B for backward).

* `Option + Delete` - Delete one world
* `Command + Delete` - Delete entire line

#### Scrolling

* `Fn + Shift + Up Arrow` - Page Up
* `Fn + Shift + Down Arrow` - Page Down

#### Tabs

* `Command + T` - Create new tab
* `Command + <num>` - Move to `num`th tab e.g. `Command + 3`
* `Command + Left/Right arrow` - Move to left/right tab
* `Command + Option + W` - Close tab

Add the following function to your `~/.profile`:
{% highlight bash %}
title() {
	echo -ne "\e]1;$@\a"
}
{% endhighlight %}
Then you can use `title foo` to set iTerm2 tab title.

#### iTerm2 Window

* `Command + Enter` - Enter / Leave full screen mode
* `Command + ,` - Show preferences

#### History search

* `Control + R` - Start history search (fuzzy search)
* `Control + R` - Move to the next suggestion

#### Other

* `Command + ;` - Open graphical autocomplete menu in iTerm2
* Use `open URL` command to open given file in MacOS e.g. `open 'https://google.com'` or `open .` to open current directory in Finder
	  ]]></description>
	</item>

	<item>
	  <title>Connecting to Raspberry PI from Linux via UART</title>
	  <link>//connecting-to-raspberry-pi-via-uart</link>
	  <author></author>
	  <pubDate>2020-07-07T02:00:01+02:00</pubDate>
	  <guid>//connecting-to-raspberry-pi-via-uart</guid>
	  <description><![CDATA[
	     In this blog post we will learn how to connect to a Raspberry PI via UART
(think serial terminal).
Before we begin we need to get a cheap `USB <-> UART` converter.
Make sure that the converter supports 3.3V voltage.
Most of the converters support other voltages e.g. 5V and you
can select which voltage you want by moving a jumper.
If your converter has such a jumper make sure that it is in 3.3V position.
![Converter](assets/images/2020-07-07/converter1.jpeg)

Although converters can have from four up to six pins, we will only need three:
GND, RXD and TXD. We should connect RXD pin on the converter to TXD pin on
the Raspberry PI and similarly TXD pin to the Raspberry's RXD pin (crossover).
We also need to connect the converter GND pin to Raspberry's Ground pin.
Do NOT connect VCC (or VCCIO) pin, we only need three wires.
You can find the Raspberry PI pinout in the official docs: 
[https://www.raspberrypi.org/documentation/usage/gpio/](https://www.raspberrypi.org/documentation/usage/gpio/) - look at the five top left pins, the first two
are +5V, then we have Ground, TXD and RXD pins.
![Connection](assets/images/2020-07-07/connection.jpeg)

Next thing that we need to do is to enable UART support in Raspbian, which for
security reasons is disabled by default.
We need to change `config.txt` file on the `/boot` partition
on the Raspberry PI SD card. We need to add `enable_uart=1` line
before `[pi4]` section (or at the end of the file if the section is not present).
{% highlight no-highlight %}
(some lines skipped)

# Enable audio (loads snd_bcm2835)
dtparam=audio=on

# ADD THIS LINE HERE
enable_uart=1

[pi4]
# Enable DRM VC4 V3D driver on top of the dispmanx display stack
dtoverlay=vc4-fkms-v3d
max_framebuffers=2
{% endhighlight %}

When we connect the converter to both Raspberry PI and the computer it should
be recognized by the system and a new device named `ttyUSBn` (where n is a number e.g. `ttyUSB0`)
should appear under `/dev` directory.
As always with all things hardware `dmesg` is your friend, so you can either `dmesg | tail -n 100` or
`dmesg | grep tty` to find out what exactly device was created and if there where any problems.
On my system I saw the following messages:
{% highlight nohighlight %}
$ dmesg | grep tty
[22562.037811] usb 3-10: cp210x converter now attached to ttyUSB0
{% endhighlight %}

There are a lot of different programs on Linux that you can use to open a session.
We will concentrate on only two of them, `putty` which is a GUI tool and
`screen` which is a pure command line utility.

Let's start with `putty`, first we need to configure it to read from `/dev/ttyUSB0` device.
![Putty Config](assets/images/2020-07-07/puttyconf.png)

To avoid putting this info every time, when you want to connect we should save it as an profile
(put a name and click Save button).
![Putty Profile](assets/images/2020-07-07/profile.png)

It is also worth checking other settings like the font, keyboard or the default terminal size:
![Putty Other Settings 1](assets/images/2020-07-07/puttyk.png)
![Putty Other Settings 2](assets/images/2020-07-07/puttyf.png)

OK its time to test our configuration. Open putty and load
previously saved profile, click Open and restart Raspberry PI.
You should be able to see boot messages. Try pressing Enter if the console appears to hang.
![Boot messages](assets/images/2020-07-07/boot.png)

After we login it is easy to notice that there is no color support out of the box
(at least on Raspbian Lite).
This can be easily changed by selecting a different terminal type in the terminal session:
{% highlight bash %}
export TERM=xterm-256color
{% endhighlight %}
![Color support](assets/images/2020-07-07/colors.png)

Another problem is that we are stuck with a fixed terminal size.
If your Raspberry PI has xterm package installed (not available on Lite version)
you can use `resize` command after you resize putty's window.
Otherwise you may use this script created by @pkh 
[https://unix.stackexchange.com/a/283206](https://unix.stackexchange.com/a/283206):
{% highlight bash %}
resize() {
  old=$(stty -g)
  stty raw -echo min 0 time 5

  printf '\0337\033[r\033[999;999H\033[6n\0338' > /dev/tty
  IFS='[;R' read -r _ rows cols _ < /dev/tty

  stty "$old"
  stty cols "$cols" rows "$rows"
}
{% endhighlight %}
Just copy and paste this code into the session and then enter `resize` (use Ctrl+Shift+Insert to paste in `putty`).
After the `resize`, commands like `top` or `htop` should occupy the entire terminal window.
![Before resize](assets/images/2020-07-07/beforeR.png)
After resize becomes:
![After resize](assets/images/2020-07-07/afterR.png)

You may want to add both the `resize` function and `TERM` environment variable to `~/.profile`
to avoid copy-pasting them every time.

If you don't use GUI at all you may use `screen`. `screen` was designed to work with SSH sessions,
it helps you keep your programs running even after you end your SSH connection.
Most people these day use `tmux` as a modern alternative, unfortunately `tmux` does not
support serial communications so we are stuck with `screen` (which TBH I am not very familiar with).

We start `screen` using the following command:
{% highlight bash %}
screen /dev/ttyUSB0 115200
{% endhighlight %}
To exit screen (which is on the same level of difficultly as exiting Vim) 
press Ctrl+A followed by \ (yup backslash).
A question will appear at the left bottom of the screen, answer y.

If `screen`s window appears blank, press enter to reprint the prompt.
For some reason programs like `htop` tend to look worse under `screen`
(assuming that you set `TERM` variable and did `resize`). Probably I am missing some extra setup,
nevertheless they are usable.
![screen](assets/images/2020-07-07/screen.png)

Last but not least, for fans of ancient `minicom` 
if you want to connect via `minicom`
remember to disable "Hardware Control Flow" option 
(they use RTS and CTS lines present on some converters that we do not use).


	  ]]></description>
	</item>

	<item>
	  <title>Scala WTF 1</title>
	  <link>//scala-wtf-1</link>
	  <author></author>
	  <pubDate>2020-07-06T02:00:01+02:00</pubDate>
	  <guid>//scala-wtf-1</guid>
	  <description><![CDATA[
	     So here is a puzzle. What will be written by
this program:

{% highlight scala %}
object Wtf1 {
  def main(args: Array[String]): Unit = {
    val points: List[Point] = List(
      Point(1, 2),
      Point(3, 4),
      Point(5, 6)
    )

    val result = points.contains(Point(3, _))
    println(s"result: $result")
  }
}

case class Point(x: Int, y: Int)

// ANSWER BELOW
// ..............................................
//
{% endhighlight %}

The answer is `false`.
Why? Because the line with `points.contains(Point(3, _))`
instead of performing pattern matching, checks whether `points` 
contain a function:
{% highlight scala %}
val result = points.contains(Point(3, _))
// in reality is:
val result = names.contains((n: Int) => Point(3, n))
{% endhighlight %}

The strangest thing for me is that the compilation of 
this code does not generate any warnings.
From Scala compiler point of view the above code is
perfectly valid and this in turn is the result of
`List` type being covariant.
Or in the other words because we can assign `List[Point]` to
`List[Any]`, `contains` must accept
arguments of any type:
{% highlight scala %}
val points: List[Point] = List(
    Point(1, 2),
    Point(3, 4),
    Point(5, 6)
)

val anys: List[Any] = points

anys.contains(new Object())
{% endhighlight %}

The declaration of `contains` method in `List[A]` looks like this:
{% highlight scala %}
def contains[A1 >: A](elem: A1): Boolean
{% endhighlight %}
We may snoop the actual types assigned to the generic parameters
using a helper method:
{% highlight scala %}
def detectType[A, A1 >: A](l: List[A], obj: A1)
                          (implicit tagA: ClassTag[A], tagA1: ClassTag[A1]): Unit = {
    println(s"type of A : ${tagA.runtimeClass.getName}")
    println(s"type of A1: ${tagA1.runtimeClass.getName}")
}

detectType(names, Point(3, _))

// This prints:
// type of A : Point
// type of A1: java.lang.Object
//
{% endhighlight %}
So during the compilation `A1` becomes `Object` and everything
type-checks.

Let's finish by writing a code that actually does what
the programmer intended:
{% highlight scala %}
val result = names
    .collectFirst { case Point(3, _) => true }
    .getOrElse(false)
{% endhighlight %}




	  ]]></description>
	</item>

	<item>
	  <title>Matching regexes using backtracking</title>
	  <link>//matching-regexes-using-backtracking</link>
	  <author></author>
	  <pubDate>2020-06-28T02:00:01+02:00</pubDate>
	  <guid>//matching-regexes-using-backtracking</guid>
	  <description><![CDATA[
	     In this post we will write a simple regex library.
The table below presents regex operators that we are going to support:

<table>
    <colgroup>
        <col width="25%" />
        <col width="75%" />
    </colgroup>
    <thead>
        <tr class="header">
            <th>Operator</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td markdown="span">A single character e.g. `a`, `\n`, `\(`</td>
            <td markdown="span">
                A single character matches itself.<br/>
                Special characters need to be escaped e.g. `\n`.
            </td>
        </tr>
        <tr>
            <td markdown="span">Character groups e.g. `[a-z]`, `[^xyz]`</td>
            <td markdown="span">Character group matches any character
                that is part of the group.<br/><br/>
                Negated character group (`[^xyz]`)
                matches any character that is _not_ part of the group.<br/><br/>
                Character ranges like `a-z` can be used inside groups.
                A character c belongs to `a-z` range when its
                numerical value falls between `(int)'a' <= (int)c <= (int)'z'`.
            </td>
        </tr>
        <tr>
            <td markdown="span">`.` wildcard</td>
            <td markdown="span">
                `.` wildcard will match any single character. 
                <br /><br />
                For example
                `...` will match any string consisting of three characters.
            </td>
        </tr>
        <tr>
            <td markdown="span">Concatenation e.g. `abc`,<br/>`[0-9]-[0-9]`</td>
            <td markdown="span">Just as we can concatenate strings, 
                we may also concatenate regexes. 
                The resulting expression will match an input, only when the input can be split into two parts, so that
                the first part of the input matches the first concatenated regex and
                the second part of the input matches the second concatenated regex.
                <br /><br />
                For example input `9X` matches the regex `[0-9][XYZ]` because `9` matches `[0-9]` and `X` matches `[XYZ]`.
            </td>
        </tr>
        <tr>
            <td markdown="span">Alternative e.g. `Z|X|[0-9]`</td>
            <td markdown="span">Input matches the alternative when it matches
                any branch of the alternative. <br /><br/>
                For example inputs `Z`, `X`
                and `3` will all match `Z|X|[0-9]` alternative because they match
                respectively `Z`, `X` and `[0-9]` branches. 
                <br /><br/>
                Alternative has lower priority than concatenation so
                `foo|bar` means `(foo)|(bar)`, not `fo(o|b)ar`.
            </td>
        </tr>
        <tr>
            <td markdown="span">Repetition (quantification) 
                e.g. `a*`, `[0-9]?`, `X{1,5}`</td>
            <td>
                Preceding regex must match input specified number of times.<br/>
                Supported operators are: <br/><br/>
                <ul>
                    <li><code>*</code> - matches zero or more times</li>
                    <li><code>+</code> - matches one or more times</li>
                    <li><code>?</code> - matches zero or one time</li>
                    <li><code>{n}</code> - matches exactly n times</li>
                    <li><code>{n,m}</code> - matches between n and m
                     times (inclusive) 
                    </li>
                </ul>
                <div markdown="span">
                    For example `[0-9]*` will match any string consisting of digits, including empty string.<br />
                    On the other hand `[0-9]{2,3}` will match strings consisting of two or three decimal digits.<br/><br/>
                    In our limited implementation we do not support spaces
                    (or any other whitespace characters) inside `{n,m}` expressions.<br/><br/>
                    Repetition has higher priority than concatenation and 
                    alternative so `foo{5}` means `fo(o{5})`, not `(foo){5}`.<br/><br/>
                    Repetition operators are greedy, this means they will try
                    to match as much input as possible.<br />
                    For example `(a*)(a*)` will match the `aaaaa` input in
                    the following way `(aaaaa)()` - the first `a*` will match
                    all the characters, leaving empty string for the second `a*` to match.
                </div>
            </td>
        </tr>
        <tr>
            <td markdown="span">`^` and `$` anchors</td>
            <td markdown="span">
                `^` matches the beginning of the input.<br/>
                `$` matches the end of the input.<br/><br/>
                For example `^foo` will match strings that start with
                `foo` and `bar$` will match strings that end with `bar`.
            </td>
        </tr>
        <tr>
            <td markdown="span">Grouping (parentheses)</td>
            <td markdown="span">
                Parentheses are used to alter the precedence of the operators.<br/><br/>
                For example compare `foo|bar` with `fo(o|b)ar`,
                the first one will match `foo`, the second one `fooar`.
            </td>
        </tr>
    </tbody>
</table>

The library itself is quite small, it consists of two parts:
a parser and a matcher. 
The parser is a very simple [recursive descent parser](https://en.wikipedia.org/wiki/Recursive_descent_parser)
and as most of manually written parsers
it probably contains some undiscovered bugs.
The parser itself is not the main focus of this article,
so we will tread it as a black box that consumes regular 
expressions in text form and produces equivalent ASTs or Abstract Syntax Trees.

ASTs are tree like data structures, 
that make order of operator evaluation and the internal structure of a regular
expression explicit.
Let's see this on an example. The AST representation of 
 `^a(foo|bar|egg)*b$` regex is:
![AST tree](assets/images/2020-06-28/ast1.svg)

The anchors `^` and `$` are represented by their own
AST nodes `AT_BEGINNING` and `AT_END`.
To represent both character groups and single characters, we use
`GROUP` nodes. `GROUP` nodes are very simple, they contain a list
of characters that they match. A `GROUP` node for `[0-9]` regex
contains characters `0123456789` in the list.
For negated groups like `[^0-9]` we use `NEGATED_GROUP` node,
the representation is the same as for `GROUP` (we keep `0123456789` characters
in the list).
Next is the tricky one, we use `NEGATED_GROUP` without any characters
to represent wildcard (`.`). This makes sense because an empty group `[]` 
does not match anything, so its negation will match all characters.

To represent quantification operators like `?`, `+`, `*` and `{n,m}`
we use `REPEAT` nodes. `REPEAT` nodes contain two additional attributes:
minimum and maximum number of allowed repetitions.
We use `Long.MAX_VALUE` to signify that maximum number of repetitions is unbound.
Finally we use `CONCAT` node to represent concatenation of two or more
regular expressions.

In the code all AST nodes are represented by a single class
called `RAst`:
{% highlight java %}
public class RAst {
    public final RAstType type;
    public final Set<Character> chars;
    public final List<RAst> exprs;

    // Repeat from to, both inclusive
    public final long repeatMin;
    public final long repeatMax;

    // ...
{% endhighlight %}
`type` field describes what kind of AST node this instance
represents e.g. `CONCAT`.
`GROUP` and `NEGATED_GROUP` nodes keep the set of matched/not-matched
characters in `chars` field.
`CONCAT` and `ALTERNATIVE` nodes keep their children in `exprs` field 
(the order of children is important, hence a `List`).
`REPEAT` node keeps its only child as a single element list in `exprs` field.

The matcher is represented in the code by `BacktrackingMatcher` class.
The interface of the matcher is very simple:
{% highlight java %}
public class BacktrackingMatcher {
    public static Match match(String s, RAst regex);
}

public class Match {
    public final boolean hasMatch;
    public final String input;
    public final int start;
    public final int end;

    public String matched()  {
        if (!hasMatch) return null;
        return input.substring(start, end);
    }
}
{% endhighlight %}
Our matcher will only find the first substring of the input that
matches the regex. Yet it would not be too difficult to extend 
the algorithm to find all matches (start matching again 
after the end of the previous match).

To implement our matcher we will use an algorithm design technique 
called backtracking. The general idea of backtracking is
very simple: we enumerate all the possible solution candidates
in a smart way and then we return the first candidate that is a valid solution.
The part "in a smart way" is very important, usually
enumerating all solution candidates will result in a very
slow algorithm (think `O(2^n)` or even `O(n!)`).
The key here is to quickly and early reject some subsets of
the solutions candidates. 

Let's see this on a very simple example,
say we want to solve a puzzle that is about placing various shapes in 3x3 grid. Some places in the grid are already taken. There is also a rule that describes a valid solution: in every row and column we cannot have two shapes of the same kind.
![Puzzle board](assets/images/2020-06-28/puzzle.svg)
Simple enumeration of all possible assignments of the shapes to the free places
will generate `3^5` solution candidates, most of them wrong.
A smarter candidate generation strategy
would be to check immediately after we fill a free place,
if the solution conditions still holds for this place row and column.
This would save us a lot of work, because we could discard a lot of
solution candidates much more early in the process.
For example we could discard all the solution candidates that have
Cloud shape at 1B position in the first step of the algorithm.

The name of the technique itself comes from the specific way
in which the algorithm generates all the solution candidates.
The naive backtracking algorithm that solves our simple puzzle looks like this:
{% highlight java %}
// Board positions:
// [0 | 1 | 2]
// [3 | 4 | 5]
// [6 | 7 | 8]
// Notice that rowIndex = currentPosition / 3
// and         colIndex = currentPosition % 3
private boolean solve(char[][] board, int currentPosition) {
    if (currentPosition == 9) {
        // All places are filled, check if this
        // candidate is a valid solution.
        return isValidSolution(board);
    }

    if (isPlaceTaken(board, currentPosition)) {
        // Move to checking the next place.
        return solve(board, currentPosition+1);
    }

    // Try putting all shapes in the free place
    for (char shape: new char[] { 'C', 'H', 'R' }) {
        putShape(board, currentPosition, shape);

        if (solve(board, currentPosition + 1)) {
            return true;
        }

        // Clear position or BACKTRACK.
        putShape(board, currentPosition, '?');
    }

    return false;
}
{% endhighlight %}
The key part of the algorithm is the `for` loop,
where we put a shape on the free place and then remove it 
when don't find a solution. This removal
or taking a move back is what gave the algorithm its name.
Alternatively we may say that when `solve` returns `false`,
then the `board` is exactly in the same state as it was
before we called `solve`.

Matching regular expression is somehow similar to solving our previous puzzle.
At each step we have several possibilities, like should we match `foo`
or `fo` from the alternative `(foo|fo)`. How much characters should
`f+` expression match? Should `(bar)?` match `bar` or nothing?
On the other hand the most complexity in matching regular expressions
comes from the fact that we are matching a recurrent structure (tree).
It's like matching our puzzle, but where each empty place can contain
another smaller version of the same puzzle that also must be solved.

The main entry point to our regex matching algorithm is
{% highlight java %}
@FunctionalInterface
public interface Cont {
    boolean run();
}

boolean match(Input input, RAst ast, Cont cont)
{% endhighlight %}
method. It takes three parameters, `input` which is just
the input `String` plus a pointer called `pos` that tracks next, not yet
matched character. `Input` also provides helpful methods that can
be used to save and restore `pos` value (we will need that
for backtracking). Next parameter, `ast`, is an AST subtree that the algorithm
should match. The last parameter `cont` is the most interesting one.
In my previous blog post I wrote about 
[continuations](/continuations-in-java), please read that post before
going further. `cont` is lambda expression (but we may thread it also as
a kind of continuation), that when called will
try to match remaining part of the regex AST (e.g. it will match parents
and the remaining siblings nodes of `ast` node).

The contract of `match` method is as follows.
If the method is not able to match `ast` subtree it will
return `false`, `cont` will not be called and the `input`
will not be modified (or it may be restored to the original state).
On the other hand if `ast` subtree could be matched then
`cont` will be called with the modified `input` and
`match` will return whatever `cont` returns.
Before returning value to the client `input` will be restored
to the original state (this is not strictly necessary if we
are looking for the first match but somehow makes algorithm more elegant).

At the top level we will call `match` somehow like this:
{% highlight java %}
int startIndex = input.currentPos();
AtomicInteger endIndex = new AtomicInteger(0);

boolean hasMatch = match(input, regex, () -> {
    endIndex.set(input.currentPos());
    return true;
});
{% endhighlight %}
This call means that we are looking for the matches
starting at index `startIndex` and if we find one
we save the
end of the match in the `endIndex` variable and return `true`
to signify that matching process should stop.
This is the only place in the algorithm where we use
`return true`. Matched substring could be easily
retrieved as `input.substring(startIndex, endIndex)`.

The body of `match` method is a giant switch statement that
delegates matching of different AST types to different methods (not counting simple
operators):
{% highlight java %}
public static boolean match(Input input, RAst ast, Cont cont) {
    RAstType type = ast.type;
    InputPositionMarker m = null;

    switch (type) {
        /* some cases skipped */

        case GROUP:
            if (input.atEnd()) return false;
            if (ast.chars.contains(input.current())) {
                m = input.markPosition();
                input.advance(1);
                try {
                    return cont.run();
                } finally {
                    input.restorePosition(m);
                }
            }
            return false;

        case CONCAT:
            return concatRec(input, ast.exprs, 0, cont);

        case ALTERNATIVE:
            return alternativeRec(input, ast.exprs, 0, cont);

        case REPEAT:
            return repeatRec(input, ast, 0, cont);

        default: throw new AssertionError("Unknown AST type: " + type);
    }
}
{% endhighlight %}
Let's take a look how matching a `GROUP` is performed.
If the group matches next input character, we save the current
input pointer in `m` variable, then we advance the input pointer 
and finally we call `cont` to match the
rest of the regex. After `cont` returns we restore the input position
using `finally` block. This is a bit hacky but it works.

Matching `CONCAT` node is also simple. We use recursion to match
subsequent children expressions:
{% highlight java %}
private static boolean concatRec(Input input,
                                 List<RAst> exprs,
                                 int currExpr,
                                 Cont cont) {
    if (currExpr == exprs.size()) {
        // We matched all the children
        return cont.run();
    }

    // Match exprs.get(currExpr) child
    return match(input, exprs.get(currExpr), () ->
        // If it succeeded then match next child expression 
        concatRec(input, exprs, currExpr + 1, cont)
    );
}
{% endhighlight %}
Notice that because we are not consuming any input here we have
nothing to restore.

Similarly `ALTERNATIVE` is easy to match:
{% highlight java %}
private static boolean alternativeRec(Input input,
                                      List<RAst> expr,
                                      int currExpr,
                                      Cont cont) {
    if (currExpr == expr.size()) {
        // We tried all branches but found no match.
        return false;
    }

    // Try matching expr.get(currExpr) branch of the alternative
    boolean matched = match(input, expr.get(currExpr), cont);
    // We found a match
    if (matched) return true;

    // No match found - Let's try next alternative "branch"
    return alternativeRec(input, expr, currExpr+1, cont);
}
{% endhighlight %}
Here `currExpr` points to the current alternative branch that we are matching.
Instead of using recursion we may implement `alternativeRec` 
using a simple `for` loop, which I left as an exercise for the reader.

Matching `REPEAT` node causes the most troubles, because all
quantification operators are greedy by default. This means that
e.g. `a+` will try to match as much characters as possible.
To implement this behavior we first attempt to match `REPEAT`s child subtree 
as many times as possible, then we move "backwards" calling `cont`
each time to check if we have a match.
The diagram below illustrates this process:
{% highlight nohighlight %}
We match a+ expression:
a
a a
a a a         // We matched a three times.
a a a noMatch // Forth time we have noMatch.
a a a cont()  // We move backwards, calling cont()
a a cont()    // each time until it returns true.
a cont() match // cont() returned true.
               // We stop moving backwards and return true from a+.
{% endhighlight %}
The code of `repeatRec` is:
{% highlight java %}
private static boolean repeatRec(Input input,
                                 RAst repeatAst,
                                 long matchCount,
                                 Cont cont) {
    // For expressions like R{n,m} do we have
    // more matches than necessary?
    if (matchCount > repeatAst.repeatMax)
        return false;

    // Greedy matching as much as possible.
    boolean matched = match(input, repeatAst.headExpr(), () ->
        repeatRec(input, repeatAst, matchCount+1, cont)
    );

    // We are moving backwards, calling `cont` each time.
    // We also make sure that we have min number of matches
    // for expressions like R{n,m}.
    if (!matched && (matchCount >= repeatAst.repeatMin)) {
        return cont.run();
    }

    return matched;
}
{% endhighlight %}

And generally that's it. Our simple regex engine.
There are some details left (like handling `^` or `$` or
moving `startIndex`) but the idea behind the backtracking
matcher should now be familiar to us.

You can find source code for the engine (including tests)
on GitHub: [https://github.com/marcin-chwedczuk/reng](https://github.com/marcin-chwedczuk/reng). But before you jump to see the
code I really recommend you to write a similar engine (in your
favorite language) yourself. This will give you a much more
deeper understanding of the algorithm.

Last but not least, our algorithm has a decent performance,
given that we use reasonable regexes and inputs.
A regex like `(a+)*c` matched on the input `aaaaaaaaaaaaaaaaaaaaaaaaaaaab`
will have a very bad performance. This is a common problem
not only in our matcher but in most regex libraries
that use backtracking algorithms. You can 
read more about this problem on [Wikipedia](https://en.wikipedia.org/wiki/ReDoS).

	  ]]></description>
	</item>

	<item>
	  <title>Continuations in Java</title>
	  <link>//continuations-in-java</link>
	  <author></author>
	  <pubDate>2020-06-27T02:00:01+02:00</pubDate>
	  <guid>//continuations-in-java</guid>
	  <description><![CDATA[
	     CSP or Continuation-Passing Style is a style of programming in which
functions return results via callbacks.
For example `+` operator is a function that takes two numbers and
returns their sum. In CSP `+` operator becomes a function that takes
three arguments, two terms and a callback, usually called a continuation in
the context of CSP.
In Java we can express this as:

{% highlight java %}
void add(int a, int b, Cont<Integer> cont) {
    cont.apply(a + b);
}

@FunctionalInterface
private interface Cont<R> {
  void apply(R result);
}
{% endhighlight %}

Because functions' results are always returned via callback calls,
CSP is forcing us to name the returned values by naming callback parameters.
In addition CSP makes the order of evaluation of an expression explicit.
For example, a simple Java program in imperative style:
{% highlight java %}
System.out.println(1 + 2 + 3);
System.exit(0);
{% endhighlight %}
Can be expressed in CSP as follows:
{% highlight java %}
add(1, 2, partialSum ->
  add(partialSum, 3, sum ->
    print(sum, unit ->
      System.exit(0))));

static void print(int n, Cont<Void> cont) {
  System.out.println(n);
  cont.apply(null);
}
{% endhighlight %}
While transforming imperative programs into CSP form we may encounter
problems with handling procedures (methods returning `void` in Java).
A lot of functional programming languages do not support procedures,
instead they define a special type called `Unit`, that has only
a single value and use that type to signify that function does
not return any meaningful data.
So defined `Unit` type is often identified with the empty tuple `()`.
In Java we do not have `Unit`, but we may use `Void` type with its only
allowed value `null` to simulate it.

While looking at our last example we may notice that in CSP form,
function arguments can be in one of three forms:
a constant, a variable or a lambda expression.
There is no rule preventing us from passing two or more
callbacks to a single function. 
Indeed this is necessary to translate `if` statement to CSP counterpart:
{% highlight java %}
void iff(boolean expr,
         Cont<Boolean> trueBranch,
         Cont<Boolean> falseBranch) {
    if (expr) trueBranch.apply(true);
    else falseBranch.apply(false);
}
{% endhighlight %}
Instead of `Cont<Boolean>` we could use here `Cont<Void>` as well.

To get a better feel for CSP we will look at three more examples.
We will start with a simple (naive) program for computing sum
of all numbers between given two numbers:
{% highlight java %}
static long sum(int from, int to) {
  long sum = 0;
  for (int i = from; i <= to; i++) {
    sum += i;
  }
  return sum;
}
{% endhighlight %}
The transformation to CSP will become easier
if we first replace `for` loop with recursion:
{% highlight java %}
static long sum_rec(int from, int to) {
  return (from > to)
    ? 0
    : from + sum_rec(from+1, to);
}
{% endhighlight %}
This version can be easily translated into CSP:
{% highlight java %}
static void sumCC(int from, int to, Cont<Long> cont) {
  gt(from, to, fromGreaterThanTo ->
    iff(fromGreaterThanTo,
      x -> cont.apply(0L),
      x -> add(from, 1, from1 ->
        sumCC(from1, to, sumCC1 ->
          addLong(from, sumCC1, cont)))));
}
{% endhighlight %}
Where `gt` is the CSP counterpart of `>` operator.

Next we will transform factorial computing function.
This time we will start with a recursive definition that is 
easier to translate:
{% highlight java %}
static int factorial(int n) {
  if (n == 0) return 1;
  return factorial(n-1)*n;
}
{% endhighlight %}
CSP version of factorial looks like this:
{% highlight java %}
private static void factorial(int n, Cont<Integer> cont) {
  eq(n, 0, isNZero ->
    iff(isNZero,
      x -> cont.apply(1),
      x -> add(n, -1, nm1 ->
        factorial(nm1, fnm1 ->
          multiply(n, fnm1, cont)))));
}
{% endhighlight %}

As the last example we will transform a function
that computes Fibonacci sequence:
{% highlight java %}
static int fib1(int n) {
    if (n < 2) return 1;
    return fib1(n-1) + fib1(n-2);
}
{% endhighlight %}
In CSP it looks like this:
{% highlight java %}
static void fib(int n, Cont<Integer> cont) {
  lt(n, 2, nlt2 ->
    iff(nlt2,
      x -> cont.apply(1),
      x -> add(n, -1, nm1 ->
        fib(nm1, fnm1 ->
          add(n, -2, nm2 ->
            fib(nm2, fnm2 ->
              add(fnm1, fnm2, cont)))))));
}
{% endhighlight %}

Now we should have, at least intuitive feel, how the
transformation to CSP works. In fact any program can be
transformed to CSP. The last point is quite interesting,
especially if we pass `() -> exit(0)` or some other not-returning function
as the last continuation. Why? Because in that case we will
never return from any of the called functions.
Let's see how this works on a simple example:
{% highlight java %}
static void main(String[] args) {
    factorial(6, fac6 ->
      print(fac6, x ->
        System.exit(0)));

    System.out.println("Will never be printed");
}
{% endhighlight %}

The entire idea of having a call stack is about providing a way for
the called functions to return the control to the callers.
But if we are never returning, then we don't need a call stack, right?
Not so fast, some of you may say - what about passing arguments to 
the called functions,
call stack is used for that too. Yes, the arguments are also stored on
the call stack but with CSP we capture 
the values of arguments using closures.
Of course JVM does not know that our programs are in CSP form or that they 
would do fine without having a call stack at all.
Instead we get a new call stack frame every time we call something,
this results in `StackOverflowError` quickly when we call
e.g. `factorial(3000, r -> ...)`.

Too avoid `StackOverflowError`s we may use a technique called trampolining. 
Trampolining in connection with CSP
could reduce the required call stack space to a constant number
of slots.
The idea of trampolining is very simple, we split computation into
parts and then we compute only the first part and _return_ a 
continuation (called thunk) that is responsible for computing the rest. 
The returned continuation captures the result of the first computation in
its closure so we don't have to recompute it.
Let's see how a trampolined `+` operator would looks like:
{% highlight java %}
static Thunk add(int a, int b, Cont<Integer> cont) {
    int sum = a + b;
    return () -> cont.apply(sum);
}

static Thunk add3(int a, int b, int c, Cont<Integer> cont) {
    return add(a, b, sum ->
            add(sum, c, cont));
}

@FunctionalInterface
private interface Cont<R> {
    Thunk apply(R result);
}

@FunctionalInterface
private interface Thunk {
    Thunk run();
}
{% endhighlight %}
Notice that trampolined `+` operator splits its computation
into two parts: computing the sum and calling the continuation.
The called continuation will again split it's work and so on and on.

`add3` function illustrates two key points. 
One is that the logical flow of the program stays the same, we just
call the passed continuations like in a pure CSP program.
The other is, that to introduce trampolining we only need to modify
primitives provided by our programming language (operators and statements).
The program code stays the same.
Of course because Java is a statically-typed language we need to change 
functions return type from `void` into `Thunk`, but this is
a simple mechanical change that would not be necessary in 
a dynamically-typed language.

Next example illustrates how trampolined `if` statement and
`factorial` looks like. Notice that factorial code did not change,
not counting the return type:
{% highlight java %}
static Thunk iff(boolean expr,
                 Cont<Boolean> trueBranch,
                 Cont<Boolean> falseBranch) {
  return (expr)
    ? () -> trueBranch.apply(true)
    : () -> falseBranch.apply(false);
}

static Thunk factorial(int n, Cont<Integer> cont) {
  return eq(n, 0, isNZero ->
    iff(isNZero,
      x -> cont.apply(1),
      x -> add(n, -1, nm1 ->
        factorial(nm1, fnm1 ->
          multiply(n, fnm1, cont)))));
}
{% endhighlight %}

Because we are now performing computation "in parts", we need 
a procedure that will be continually invoking returned thunks,
thus ensuring that out computation is making progress.
A procedure like this is called a trampoline:
{% highlight java %}
static void trampoline(Thunk thunk) {
  while (thunk != null) {
      thunk = thunk.run();
  }
}

static <T> Cont<T> endCall(Consumer<T> call) {
  return r -> {
      call.accept(r);
      return null;
  };
}
{% endhighlight %}
We are also providing a new primitive operator `endCall` that
can be used to mark the last part of the computation.
Using `trampoline` we may now compute `factorial(3000)`
without any troubles:
{% highlight java %}
AtomicInteger res = new AtomicInteger(-1);
trampoline(factorial(400000, endCall(res::set)));
System.out.println(res.get())
{% endhighlight %}
As a side effect, we may now use trampoline to mix
CSP and imperative code in the same program.

CSP and trampolining are not mere theoretical concepts,
there where and are still used to implement e.g. LISP interpreters.
Continuations can also be used to simplify backtracking algorithms.
Source code for this blog post can be found
[here](https://github.com/marcin-chwedczuk/reng/tree/master/test/pl/marcinchwedczuk/continuations).



	  ]]></description>
	</item>

	<item>
	  <title>Jak zacząć przygodę z elektroniką</title>
	  <link>//jak-zaczac-przygode-z-elektronika</link>
	  <author></author>
	  <pubDate>2019-12-30T01:00:01+01:00</pubDate>
	  <guid>//jak-zaczac-przygode-z-elektronika</guid>
	  <description><![CDATA[
	     Parę miesięcy temu postanowiłem powrócić do mojego
hobby z czasów dzieciństwa: elektroniki.
Powrót, po ponad dziesięciu latach przerwy, okazał
się być trudniejszy niż przypuszczałem,
a droga do pierwszego działającego układu 
pełna frustracji i porażek.

Pomimo tego radość z wykonania najprostszego generatora,
który naprzemiennie migał diodami LED dostarczyła
mi tak dużo radości i frajdy, że przez kilka następnych
wieczorów oddałem się w całości budowie kolejnych układów.

Niestety elektronika jako hobby, nie jest
już w Polsce tak popularna jak 
miało to miejsce w końcówce lat dziewięćdziesiątych.
A szkoda, bo na zachodzie mamy obecnie do czynienia
z prawdziwym boomem na elektronikę.
Dobrze ilustrują to platformy takie jak
[Arduino](https://www.arduino.cc/) czy
[Raspberry PI](https://www.raspberrypi.org/).
Nie wspominając już o modzie na retro-computing
(a więc na budowę prostych, często 8-bitowych komputerów wprost
z układów scalonych) uosabianej przez takie postaci
jak [Ben Eater](https://www.youtube.com/channel/UCS0N5baNlQWJCUrhCEo8WlA)
i projekty jak [The MOnSter 6502](https://monster6502.com/) i
[Gigatron](https://gigatron.io/)

Niestety nauka nowej umiejętności czy jest nią jazda samochodem,
czy język obcy czy też elektronika, nie jest prosta.
Na początkujących czyha wiele pułapek, które zniechęcają ich 
do dalszej nauki. Dlatego, aby ułatwić początkującym wejście w
świat elektronik, postawiłem podzielić się moimi doświadczeniami
(czytaj wpadkami)
i opisać problemy na jakie się natknąłem.
To jest pierwszy wpis z tej serii, w którym opisuję
pułapki które czekają nas przy zakupie pierwszych płytek
stykowych, przewodów i elementów elektronicznych. Zapraszam!

#### Płytka stykowa

Według mnie najlepszym sposobem montażu układów, na początku
przygody z elektroniką są płytki stykowe.
Na rysunku poniżej przedstawiam przykład dwóch takich płytek:
![Przykładowe płytki stykowe](assets/images/2019-12-30/plytki-stykowe-1.jpg)

Płytka oznaczona numerem 1, to przykład płytki droższej
która mimo to posiada kilka poważnych mankamentów.
Po pierwsze brakuje oznaczenia polaryzacji szyn zasilania,
co rodzi pole do przykrych w konsekwencjach pomyłek
(np. nieprawidłowe doprowadzenie zasilania do układu scalonego).
Po drugie szyny zasilania są "przecięte" w połowie płytki
(patrz strzałki). Tego typu "przecięcie" przydaje 
się gdy budujemy układy w których występują dwa poziomy
zasilania np. 3.3V i 5V. Większość początkujących
elektroników korzysta jednak z pojedynczego napięcia zasilania.
W praktyce okazywało się to tak denerwujące że musiałem dodać specjalne
oznaczenia markerem, żeby już więcej się nie zastanawiać dlaczego
połowa układu nie ma napięcia zasilania.

Płytka oznaczona numerem 2 to tania płytka (7 PLN za sztukę),
produkcji chińskiej. Mimo to producent
nie oszczędzał na pomocnych oznaczeniach. 
Każda z czterech linii zasilania
ma swój kolor, każde gniazdo jest adresowane 
za pomocą kombinacji litery (a-j) i liczby (1-65).
Może, na pierwszy rzut oka nie wydaje się to
przydatne, ale w internecie można znaleźć mnóstwo
projektów pomyślanych specjalnie do wykonania
na płytkach stykowych, które zawierają instrukcje
typu: "umieść rezystor 1k w gniazdach 5f i 5c".

Niestety niska cena płytki nr. 2 znalazła negatywne
odbicie w jakości styków. Korzystanie z tej płytki
rodziło sporo kłopotów: często miałem problemy żeby
włożyć końcówkę przewodu lub nóżkę elementu do danego
gniazda. Czasami pomagało wetknięcie szpilki, czasami
włożenie przewodów najpierw do sąsiadujących gniazd
a dopiero potem przeniesienie ich do tego właściwego.
Czasami pomagało "wiercenie" w gnieździe nóżką diody LED.
Innymi słowy, spora część radości wynikającej z budowania układu 
ustępowała miejsca frustracji związanej z niskiej jakości płytką.

Przed zakupem płytek polecam przeczytać
recenzje, zarówno na polski forach jak i na zagranicznych (oraz
na Amazonie). Osobiście, nie znalazłem jak do tej pory
płytki stykowej godnej polecenia, jeżeli taką znacie to
proszę dodajcie komentarz z linkiem.

Wróćmy jeszcze na chwilę do zdjęcia płytek. 
Część oznaczona numerem cztery to pojedyncza szyna zasilania,
odseparowana od płytki stykowej typu dwa. 
Jak się okazuje od każdej płytki możemy oderwać jedną lub
obie szyny zasilania. Przy wykonywaniu tej operacji
przydaje się nożyk do kartonu, który pozwoli nam
rozciąć izolacyjny materiał znajdujący się na spodzie płytki.

Każda płytka stykowa posiada wypustki, które pozwalają
zbudować "megapłytkę" z dwóch lub większej liczby 
pojedynczych płytek (z obecnymi lub oderwanymi szynami zasilania).
Niestety płytki wyprodukowane przez różne firmy rzadko
są ze sobą kompatybilne. 
Poniżej zamiejszczam zdjęcie takiej "megapłytki":
![Megapłytka](assets/images/2019-12-30/megaplytka.jpg)

Oprócz pełonowymiarowych płytek, na ryku dostępne są też
mniejsze modele:
![Mini płytki](assets/images/2019-12-30/mini.jpg)
Osobiście nie polecam ich początkującym, gdyż są
po prostu za małe.

Wydawało by się że orientacja płytki nie ma żadnego znaczenia.
Warto jednak przy budowie układów podążać za sprawdzoną regułą,
która mówi że prądy powinny płynąć z góry na dół, a sygnały
od lewej do prawej. W praktyce oznacza to że górna wewnętrzna
szyna zasilająca powinna być podłączona do plusa zasilania,
a dolna wewnętrzna do minusa. Przestrzeganie tej
zasady znacznie ułatwi nam doprowadzanie zasilania do układów scalonych.

A skoro już jesteśmy przy układach scalonych, większość
z nich nie posiada prostopadłych nóżek. Zamiast tego
nóżki rozchodzą się nieco na boki, co uniemożliwia umieszczenie
takiego układu w płytce stykowej. Rozwiązaniem tego
problemu jest przygięcie nóżek scalaka przed włożeniem go
do płytki:
![Ach te nóżki](assets/images/2019-12-30/nogi.jpg)

Zanim opuścimy temat płytek warto jeszcze dodać, że
na opakowaniu płytki znajduje się jeden z najważniejszych
jej parametrów, mianowicie zakres grubości drutów/końcówek/wyprowadzeń
z jakimi płytka współpracuje. Ten parametr okaże się istotny
gdy będziemy planować zakup przewodów kompatybilnych
z płytką (czytaj nie każdy przewód pasuje do danej płytki).

#### Przewody / połączenia / zworki

Oprócz płytki stykowej, przy budowie układów będziemy
też potrzebowali całej masy przewodów.
Osobiście polecam zakup zestawu przewodów
takich jak [Adafruit Hook-up Wire](https://www.adafruit.com/product/3174),
wraz ze szczypcami do ściągania izolacji takimi
jak [Adafruit Wire Stripper](https://www.adafruit.com/product/147):
![Przewody](assets/images/2019-12-30/druty.jpg)
Przy zakupie warto zwracać uwagę czy na pewno kupujemy
_jednożyłowy_, _cynowany_ przewód miedziany, a nie na przykład
wielożyłowy (czysta miedź pokrywa się
nieprzewodzącą warstwą tlenków, cynowany drut zapewni
nam znacznie lepszą jakość połączeń).

Przedstawiony powyżej zestaw przewodów ma grubość
drutu AWG 22 (miara amerykańska), co przelicza się
na polskie 0.6438 milimetra średnicy.
Płytki stykowe z pierwszej sekcji, pracują poprawnie z przewodami
o grubościach 0.3-0.8 milimetra, a więc są kompatybilne z tym
zestawem przewodów.

Ze względu na rosnące ceny miedzi zakup zestawów takich
jak te przedstawione powyżej, może wiązać się ze sporym wydatkiem.
Należy jednak pamiętać że
jeden zestaw przewodów powinien zaspokoić nasze potrzeby na mniej więcej rok,
a szczypce to wydatek jednorazowy.
Obecna cena powyższego zestawu przewodów w sklepie [Mouser](https://pl.mouser.com/)
wynosi około 120PLN. Oczywiście zawsze warto sprawdzić czy
nie znajdziemy lepszej oferty w polskich sklepach, na ceneo czy
w końcu na AliExpressie.

Oprócz zestawu przewodów, w sklepach można znaleźć również zestawy zworek
(numer jeden na zdjęciu):
![Przewody ciąg dalszy](assets/images/2019-12-30/zwory.jpg)
Zestawy takie są, w stosunku do ich ceny, kompletnie bezużyteczne.
Zwory prawie nigdy nie miały potrzebnej długości gdy chciałem
ich użyć. Krótkie zworki kończyły się bardzo szybko, podczas
gdy długich zostawał nadmiar. Jednym słowem: nie polecam.

Polecam za to zakup elastycznych przewodów połączeniowych
(numer dwa i trzy na zdjęciu).
Przewody typu trzy dostępne są w zestawach o dość przystępnej
cenie. Przewody typu dwa występują we wstęgach, które można
rozrywać (nawet na pojedyncze przewody) wedle upodobań.

Do zabawy z płytkami stykowymi i Arduino potrzebne nam będą przede
wszystkim przewody z wtykami męskimi (patrz numer trzy).
Do zabawy z Rasbperry PI,
a także z modułami do Arduino (np. czujniki ruchu) przydadzą się
przewody męsko-żeńskie (patrz numer dwa).

Czasami zdarza się, że przewody będące częścią zestawów mają
końcówki wtyków pokryte ochronną warstwą plastiku którą łatwo
przeoczyć. Jeżeli przewód "źle łączy" należy sprawdzić czy
końcówki nie posiadają takiej ochronnej izolacji i ewentualnie
ją usunąć.

Warto zarezerwować sobie dwa kolory (np. czarny i czerwony)
na oznaczenie przewodów które mają potencjał masy i plusa zasilania.
Warto też pomyśleć o konwencji użycia kolorów, na przykład: przewód biały to
zawsze sygnał zegara.
Poza tym im więcej kolorów mamy do dyspozycji tym lepiej.

#### Pozostałe narzędzia

Pozostałe przydatne narzędzia to:

1. Mały płaski śrubokręt
2. _Szczypce tnące boczne_
 do ucinania zbyt długich wyprowadzeń elementów
 ([model ze zdjęcia](https://botland.com.pl/pl/szczypce/5851-szczypce-tnace-boczne-yato-yt-2081-115mm-5906083920813.html))
3. Oraz najbardziej przydatna z całej tej
 trójki, bo pozwalająca wygodnie wyjmować i wkładać przewody
 połączeniowe - pęseta
 ([model ze zdjęcia](https://sklep.avt.pl/peseta-antystatyczna-122mm-prosta-ostra-esd-10.html))

![Przydatne narzędzia](assets/images/2019-12-30/szczypce.jpg)

Przycinanie wyprowadzeń elementów za pomocą
szczypiec może być odrobinę niebezpieczne.
Nóżki, na przykład dużych diod LED, podczas przycinania mają tendencje to
"wystrzeliwania" w znanym tylko sobie kierunku, dlatego
warto też pomyśleć o zakupie 
[okularów ochronnych](https://botland.com.pl/en/goggles/5626-okulary-yt-7367-5906083973611.html).

Ostatnim, naprawdę niezbędnym narzędziem, w jaki
powinniśmy się zaopatrzyć jest multimetr.
Ja używam następującego modelu, mało znanej chińskiej
marki i jestem z niego całkowicie zadowolony:
![Multimetr](assets/images/2019-12-30/multi.jpg)

#### Elementy elektroniczne

Można by pomyśleć, że po całym tym zamieszaniu z płytkami,
narzędziami i multimetrem zakup elementów elektronicznych 
będzie czystą przyjemnością.
Nic bardziej mylnego!
Pierwszym zaskoczeniem jakie mnie spotkało, była niewielka
średnica wyprowadzeń resystorów zakupionych w zestawie
"dla początkujących". Średnica była tak mała, że czasami
trudno było uzyskać dobre połączenie z płytką stykową.
Ostatecznie skończyłem z [tym zestawem rezystorów](https://botland.com.pl/pl/rezystory-przewlekane/13895-zestaw-rezystorow-cf-tht-14w-velleman-kres-e3-480szt-5410329241803.html)

![Zestaw velleman-kit](assets/images/2019-12-30/vkit.jpg)

Dobrze ilustruje to powyższe zdjęcie, rezystor oznaczony
numerem jeden pochodzi z taniego zestawu "dla początkujących".
Posiada długie i cienkie wyprowadzenia słabo współpracujące z
płytkami stykowymi. Rezystor oznaczony numerem dwa pochodzi
z zestawu velleman'a - wyraźnie widać krótsze, ale za to
grubsze i bardziej masywne wyprowadzenia.

Osobiście odradzam również zakup rezystorów o mocy większej
niż 0,25W. Rezystory 1W w porównaniu do 0,25W to prawdziwe olbrzymy.

W przeciwieństwie do rezystorów, zakup diod LED
(polecam "duże" 5mm) czy kondensatorów nie sprawiał
większych problemów, elementy po prostu działały.

Z kolei zakup przycisków ("switchy") i potencjometrów
sprawił mi trochę kłopotów. Okazuje się że wiele elementów
występuje w dwóch wersjach: do wlutowania i do płytek stykowych.
Popatrzmy na zdjęcie:
![Elementy do wlutowania i do płytek stykowych](assets/images/2019-12-30/proste.jpg)
Elementy z grupy pierwszej są przeznaczone do wlutowania.
Elementy z grupy drugiej, charakteryzującej się prostymi
wyprowadzeniami, są przewidziane do umieszczenia na płytkach
stykowych. Zawsze należy dokładnie sprawdzić czy na pewno
kupujemy takie elementy, jakich naprawdę potrzebujemy.

Na koniec, żeby nie tracić czasu na mozolne odnajdywanie potrzebnych
elementów, warto zaopatrzyć się w dobry organizer:
![Organizer](assets/images/2019-12-30/organizer.jpg)

#### Zasilanie

Początkowo zasilałem moje układy z baterii 9V.
Wykorzystywałem do tego celu kijankę (numer jeden),
gniazdo które można włożyć w szynę zasilania płytki stykowej (numer trzy) oraz
konwerter (numer dwa):
![Zasilanie z bateri 9V](assets/images/2019-12-30/zas1.jpg)
Konwerter okazał się konieczny, ponieważ zakupu
gniazda dokonałem "na oko", nie będąc świadom że
istnieje wiele różnych rozmiarów wtyków zasilania.

Osobiście nie polecam tego sposobu zasilania.
Po pierwsze jesteśmy zdani na napięcie baterii, a wiele
układów wymaga niestandardowych napięć 3,3V lub 5V.
Po drugie zaśmiecamy środowisko zużytymi bateriami,
przy jednoczesnym zubożaniu naszego portfela.

Najlepszym rozwiązaniem, dla osób dysponujących zapasem
gotówki jest kupno zasilacza laboratoryjnego,
nazywanego również zasilaczem warsztatowym.
Dla wszystkich pozostałych, przynajmniej na początku,
dobrym kompromisem jest zakup 
[zasilacza płytek stykowych](https://sklep.avt.pl/avt3072.html):
![Zasilacz do płytek stykowych](assets/images/2019-12-30/zas2.jpg)
Należy pamiętać że sam zasilacz to tylko prosta płytka PCB
(ang. printed circuit board, pl. płytka drukowana), do
pracy potrzebny jej jest [zasilacz impulsowy](https://sklep.avt.pl/zasilacz-impulsowy-12v-1-5a-18w-dc2-5-5-5.html) - oznaczony na zdjęciu numerem dwa.

Przedstawiony powyżej zasilacz, który służy mi już kilka miesięcy,
niestety nie jest pozbawiony wad.
Najpoważniejsza z nich jest taka, że nie jesteśmy ostrzegani
o zwarciu przewodów zasilania.
Istnieją na rynku zasilacze które np. piszczą
gdy dojdzie do zwarcia.
W powyższym zasilaczu, zwarcie można rozpoznać jedynie po
silnie rozgrzanym radiatorze.
Dlatego, pomimo że podałem linki do sklepu, zachęcam was do
poszukania lepszego modelu lub jeżeli już taki
posiadacie do pozostawienia komentarza z linkiem.

#### Sklepy

Na koniec lista sklepów z których jestem
względnie zadowolony:

* [Sklep AVT](https://sklep.avt.pl/) związany od wielu lat
 z czasopismem "Elektronika dla wszystkich"

* [Botland](https://botland.com.pl/pl/)

Z zagranicznych warto wspomnieć:

* [Mouser](https://pl.mouser.com/) - ten sklep
 śmiało można nazwać profesjonalnym.
 Można łatwo i szybko (czas dostawy nie przekracza tygodnia)
 dostać układy praktycznie niedostępne na polskim rynku.
 Ale uwaga, ceny produktów podane są na modłę amerykańską, 
 a więc nie zawierają
 23% podatku VAT. Najeży o tym pamiętać porównując oferty.

Oczywiście zawsze warto korzystać z porównywarek cen
i sprawdzać opinie sklepów na forach internetowych.
Bardziej odważni i cierpliwi mogą spróbować szczęścia na AliExpressie.

Na zakończenie, "starożytne" i niestety niedziałające, układy
scalone polskiej produkcji (sic!), które otrzymałem od jednego
z polskich sklepów:
![Polskie scalaki](assets/images/2019-12-30/cemi.jpg)



	  ]]></description>
	</item>

	<item>
	  <title>Pitfalls of using Mockito with Scala</title>
	  <link>//pitfalls-of-using-Mockito-with-Scala</link>
	  <author></author>
	  <pubDate>2019-12-22T01:00:01+01:00</pubDate>
	  <guid>//pitfalls-of-using-Mockito-with-Scala</guid>
	  <description><![CDATA[
	     I need to test my new, shiny Scala code.
Usually I write tests in [ScalaTest](http://www.scalatest.org/),
but for generating stubs I still use good, old
[Mockito](https://site.mockito.org/).
What can possibly go wrong?
I open a new tab in my editor and start hacking test code.

For the first surprise I don't have to wait too long.
In my code I use [value classes](https://docs.scala-lang.org/overviews/core/value-classes.html) 
to represent entity IDs.
For example I use `CustomerId`:
{% highlight scala %}
case class CustomerId(id: Long) extends AnyVal
{% endhighlight %}

When I tried to mock `customerId` method (property?):
{% highlight scala %}
trait RequestContext {
  val customerId: CustomerId
  // ...
}
{% endhighlight %}
in my test, Mockito started complaining about wrong return types
and refused to cooperate:
{% highlight scala %}
// inside test
val requestContext = mock(classOf[RequestContext])

/* Fails with WrongTypeOfReturnValue exception:
*
* CustomerId cannot be returned by customerId()
* customerId() should return long
*/
when(requestContext.customerId).thenReturn(CustomerId(123L))
{% endhighlight %}

Of course my `CustomerId` [value class](https://docs.scala-lang.org/overviews/core/value-classes.html) is here to blame...

In Scala, value classes offer type safety of normal classes with
performance of the primitives.
Scala compiler achieves this, simply by replacing the value
class type by the primitive type, wherever possible.
So I grabbed `javap` and took a look at the generated bytecode,
and indeed there is a `long` there:
{% highlight no-highlight %}
target/scala-2.13/classes$ javap RequestContext.class 
Compiled from "RequestContext.scala"
public interface RequestContext {
  public abstract long customerId();
  // ...
}
{% endhighlight %}
Mockito uses reflection to figure out which type
a given method returns.
This gives us little hope for a nice solution.
We can only try to hack around the problem, for example
this monstrosity works:
{% highlight scala %}
val requestContext = mock(classOf[RequestContext])

when(requestContext.customerId.asInstanceOf[Object])
  .thenReturn(Long.box(123L))

assert(requestContext.customerId == CustomerId(123L))
{% endhighlight %}
We use `asInstanceOf[Object]` to fool Scala's type system
and then return a `java.lang.Long` instance.

Yeah it works but it is not nice... But hey, first get the job done, then
get it done well. Let's move on to the next test...

I have to verify that a given method was called.
This time I should have more luck, right?
So I wrote another test and I ran it:
{% highlight scala %}
val requestContext = mock(classOf[RequestContext])

requestContext.setRequestId(RequestId(123L))

// works perfectly 
verify(requestContext).setRequestId(RequestId(123L))

// does NOT WORK 
verify(requestContext).setRequestId(any())
{% endhighlight %}
But I saw the results I was completly perplexed.
Verification with `RequestId(123L)` worked but the one with
`any()` did not. But what is worse the second verification
thrown `NullPointerException`. NPE? Really?

My brain was racing, and after a few seconds a thought strike me:
it's these pesky value classes again!

And I was right! Value classes in Scala cannot be `null`!
For example, in Scala REPL:
{% highlight scala %}
scala> case class FooId(id: Long) extends AnyVal
defined class FooId

scala> val f: FooId = null.asInstanceOf[FooId]
f: FooId = FooId(0)

scala> f.id
res0: Long = 0

// And more...
scala> var o: Object = null
o: Object = null

scala> o.asInstanceOf[FooId]
java.lang.NullPointerException
  ... 33 elided
{% endhighlight %}

`any()` matcher that comes with Mockito has a very simple
implementation:
{% highlight java %}
public static <T> T any() {
  return anyObject();
}

@Deprecated
public static <T> T anyObject() {
  reportMatcher(Any.ANY);
  return null;
}
{% endhighlight %}
that always returns `null`.

The method that I tried to check, has a signature:
{% highlight scala %}
trait RequestContext {
  def setRequestId(requestId: RequestId)
  // ...
}
{% endhighlight %}
and since `RequestId` is a value class, the "real" JVM signature is:
{% highlight no-highlight %}
public abstract void setRequestId(long);
{% endhighlight %}
When I write `verify(...).setRequestId(any())` 
Scala compiler adds instructions that convert the *object* returned
by `any()` (remember generics does not exist on JVM level, so all
these `T`s and `V`s are just `Object`s at runtime) to `long`.
And this is the reason why I got `NullPointerException` earlier.

In bytecode it looks like this:
{% highlight no-highlight %}
19: invokestatic  #33 // Method org/mockito/Mockito.verify:(Ljava/lang/Object;)Ljava/lang/Object;
22: checkcast     #17 // class RequestContext
25: invokestatic  #39 // Method org/mockito/ArgumentMatchers.any:()Ljava/lang/Object;
28: checkcast     #41 // class RequestId
31: invokevirtual #45 // Method RequestId.id:()J
34: invokeinterface #29, 3 // InterfaceMethod RequestContext.setRequestId:(J)V
{% endhighlight %}
and the NPE is thrown by the instruction at the offset `31`.

Now I understand the problem, but I still want to use `any()` matcher.
There must be a trick to make it return a valid `RequestId`.
But then I realized that even if I found such a way, I would be
bitten again by `WrongTypeOfReturnValue` exception or
something similar, since
the method takes `long` not `RequestId`. What I really need is
a way to use `anyLong()` with `setRequestId`. It was a good
enough challenge to
start my evil alter-ego working on some frankensteinian solution.
And I found it, I FOUND IT!, I FOUND IT!!! Ehmm... and here it is:
{% highlight scala %}
val requestContext = mock(classOf[RequestContext])

requestContext.setRequestId(RequestId(123L))

// works again
verify(requestContext).setRequestId(RequestId(anyLong()))
verify(requestContext).setRequestId(
  RequestId(ArgumentMatchers.eq(123L)))
{% endhighlight %}
A perfect combination of beauty and evil...

The trick that I used here is that Mockito does not care,
where the matcher is located, it only cares about the time when it
is called. As long as I call `anyLong()` after the call to
`verify(...)` and before the call to `.setRequestId(...)`,
Mockito will work. Actually we may wrap _any_ matcher in
as many dummy calls as we want, as in `a(b(c(d(any()))))`,
only the fact that it was called counts.

It can't be worse right? Two tests, two hacks...

But only I wrote my third test, I was slapped by the next problem,
this time caused by default parameters:
{% highlight scala %}
trait SomeTrait {
 def method(a: Int, b: Int = 100): Int
}

test("...") {
 val someTrait = mock(classOf[SomeTrait])

 someTrait.method(3)

 /* This call fails with:
 * Argument(s) are different! Wanted:
 *  someTrait.method(3, 100);
 * Actual invocations have different arguments:
 *  someTrait.method(3, 0);
 */
 // verify(someTrait).method(3, 100)

 // works
 verify(someTrait).method(3, 0)
}
{% endhighlight %}
WTF? Not again... Another strange problem that forces me
to look under the bonnet.

Let's look at the bytecode using `javap -c`:
{% highlight no-highlight %}
// bytecode of `someTrait.method(3)`
// (some code skipped here)
// 3 - load first arg onto the stack
10: iconst_3

// Scala Magic(TM), call a method to get the second
// argument's default value and push it onto the stack:
// someTrait.method$default$2()
11: aload_0
12: invokeinterface #27,  1

// finally call the `method` method
17: invokeinterface #31,  3
// (some code skipped here)
{% endhighlight %}

So the Scala compiler calls a hidden method, with a name
`methodName$default$parameterIndex` on the trait,
to figure out what value should be used as a value
of the default parameter. Wow! I didn't expect something
like that!

If only I could stub this `method$default$2` or something :thinking:
:thinking: :thinking:
...oh wait I could:
{% highlight scala %}
val someTrait = mock(classOf[SomeTrait])
when(someTrait.method$default$2).thenReturn(100)

someTrait.method(3)

// it works!
verify(someTrait).method(3, 100)
{% endhighlight %}
Excellent. It is working perfectly but now I have three tests
and three hacks. Surely I am doing something wrong here.

And so I harnessed the power of Google (after spending
some time looking at the pictures of stoats;
hey they are really cute) and found this gem:

[Mockito-Scala](https://github.com/mockito/mockito-scala)

I plug it into my project (it even has a special version
for ScalaTest) and suddenly everything started to working
as it should be.

Stubbing works:
{% highlight scala %}
import org.mockito.ArgumentMatchersSugar._ // from Mockito-Scala
import org.mockito.MockitoSugar._
// Don't import Mockito or ArgumentMatchers

val requestContext = mock[RequestContext]
when(requestContext.customerId).thenReturn(CustomerId(123L))
assert(requestContext.customerId == CustomerId(123L))
{% endhighlight %}
...and verification works:
{% highlight scala %}
val requestContext = mock[RequestContext]

requestContext.setRequestId(RequestId(123L))

verify(requestContext).setRequestId(eqTo(RequestId(123L)))
verify(requestContext).setRequestId(any[RequestId])
// but this will not work: verify(requestContext).setRequestId(any)
{% endhighlight %}
even default parameters work:
{% highlight scala %}
val someTrait = mock[SomeTrait]
someTrait.method(3)
verify(someTrait).method(3)
verify(someTrait).method(3, 100)
{% endhighlight %}
Yay! 

Wanna see some real code? [Click here.](https://github.com/marcin-chwedczuk/blog-problems-when-using-mockito-from-scala/)

References:
* [Intro to Mockito-Scala (Medium)](https://medium.com/@bruno.bonanno/introduction-to-mockito-scala-ede30769cbda?)

	  ]]></description>
	</item>


</channel>
</rss>
