<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>marcin-chwedczuk.github.io/</title>
   
   <link>http://localhost:4000</link>
   <description>A place where I share my thoughts about programming.</description>
   <language>en-uk</language>
   <managingEditor>mc</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>SSH like a Pro</title>
	  <link>//ssh-like-a-pro</link>
	  <author>mc</author>
	  <pubDate>2020-10-01T02:00:01+02:00</pubDate>
	  <guid>//ssh-like-a-pro</guid>
	  <description><![CDATA[
	     In this post I have gathered various tips and tricks 
that can make you a more productive SSH user.

### Copying SSH keys to the server

A lot of beginners when faced with the problem of uploading their
public keys to the server, follows a manual process.
I will demonstrate this, by trying to upload my public key to a Raspberry PI manually:
{% highlight bash %}
mac$ ssh pi@raspberry_pi
pi@raspberry_pi's password:

pi$ mkdir .ssh
pi$ vi .ssh/authorized_keys
pi$ # Append contents of key_rsa.pub to authorized_keys
pi$ ^D # Ctrl-D to end our ssh session
{% endhighlight %}
Now I can connect to Raspberry PI using my private key:
{% highlight bash %}
mac$ # Let's load the private key so that we can use it
mac$ ssh-add ~/.ssh/pi_rsa

mac$ ssh pi@raspberry_pi
pi$ # Yay!
{% endhighlight %}
I was lucky - in my case everything worked, but often it doesn't.
The main culprit is usually a wrong access permission set either on `.ssh` directory
or on `authorized_keys` file.
Here is how the right permissions should look like:
{% highlight bash %}
pi@raspberrypi:~ $ ls -la .ssh
total 12
drwx------  2 pi pi 4096 Oct  1 10:09 .
drwxr-xr-x 17 pi pi 4096 Oct  1 10:09 ..
-rw-------  1 pi pi  574 Oct  1 10:09 authorized_keys
{% endhighlight %}

PROs do not think about permissions, nor they manually edit `authorized_keys` file.
Instead they use `ssh-copy-id` util (a part of the official SSH distribution).
{% highlight bash %}
mac$ ssh pi@raspberry_pi 'rm -rf ~/.ssh' # Let's reset everything
mac$ ssh-copy-id -i ~/.ssh/pi_rsa pi@raspberry_pi

mac$ ssh-add ~/.ssh/pi_rsa # Do not forget to load the key
mac$ ssh pi@raspberry_pi
pi$ # Yay!
{% endhighlight %}
One nice thing about `ssh-copy-id` is that it always uploads the public key,
even if you (like I in the above example) specify private key file on the command line.

### Keys management

`ssh-add` is a nice utility that manages currently active (loaded) private keys.
Loaded keys can be automatically used for authentication.

To load a key type:
{% highlight bash %}
# ssh-add path-to-key-file
mac$ ssh-add ~/.ssh/pi_rsa
{% endhighlight %}
Or just `ssh-add` to load `id_rsa`.

To list currently loaded keys:
{% highlight bash %}
$ ssh-add -l
{% endhighlight %}

To remove all keys:
{% highlight bash %}
$ ssh-add -D
{% endhighlight %}

When you connect to a remote machine you have an option to pass your currently
loaded keys along. This is called ssh agent forwarding and 
allows you to ssh into further machines using your private keys:

![Nested SSH connections](assets/images/2020-10-01/ssh1.svg)

For example without key forwarding I cannot log from my Raspberry PI into my PC:
{% highlight bash %}
mac$ ssh pi@raspberry_pi
pi$ ssh mc@old-pc 
Password:
{% endhighlight %}
With key forwarding enabled (`-A`) I can:
{% highlight bash %}
mac$ ssh -A pi@raspberry_pi
pi$ ssh mc@old-pc
old-pc$ # yay!
{% endhighlight %}
WARNING: You should only use forwarding when logging into servers that
you fully trust (see `man ssh` for details).

TIP: With the power of `ssh-add` there is no reason to have a key without password protection.
Remember to password protect all your keys. Always!

### Using ~/.ssh/config

Sometimes your user name is too long or hard to remember or maybe the server name is
or maybe your server uses a non-standard SSH port. Any of these can make typing the right ssh command
in the terminal very hard. But there is a nice solution to this, 
we just need to add an entry for our server to `~/.ssh/config` file.

For example for my Raspberry PI computer I added the following entry:
{% highlight no-highlight %}
# this is comment
Host pi
        Hostname raspberry_pi
        Port 22
        User pi
        IdentityFile ~/.ssh/pi_rsa
        ForwardAgent yes
        # or ForwardAgent no
{% endhighlight %}
Now I can ssh into it by simply typing:
{% highlight bash %}
mac$ ssh pi
pi$ # yay!
{% endhighlight %}

### Copying files

`scp` command may be used to copy files, both from a server to the local machine:
{% highlight bash %}
# Assumes that we use pi alias
mac$ scp pi:./myfile.txt . 
# Without pi alias 
mac$ scp -P22 pi@raspberry_pi:./myfile.txt ./myfile.txt
{% endhighlight %}
Or from the local machine to the server:
{% highlight bash %}
# Assumes that we use pi alias
mac$ scp map.txt pi:./map2.txt
# Without pi alias
mac$ scp -P22 map.txt pi@raspberry_pi:./
# You may skip -P parameter if server is using default (22) port
{% endhighlight %}
TIP: If are going to transfer a big file remember to `gzip` it first.

For more complex scenarios we can use either `sftp` command:
{% highlight bash %}
mac$ sftp pi
Connected to pi.
sftp> ls # list files on the *server*
Bookshelf   Desktop     Documents   Downloads   Music       Pictures    Public
Templates   Videos      server_file.txt
sftp> get server_file.txt ./save_as_downloaded.txt
Fetching /home/pi/server_file.txt to ./save_as_downloaded.txt

sftp> put ./local_file.txt ./uploaded.txt
Uploading ./local_file.txt to /home/pi/./uploaded.txt

sftp> exit
{% endhighlight %}
or use command line file manager like `mc` (Midnight Commander):

1. Press `F9` to select menu bar and `R` to expand `Right` menu.
2. Select `SFTP link...`
3. Enter the connection URL:

![MC without alias](assets/images/2020-10-01/mc2.png)

And then you may use standard `mc` commands to copy/move/modify files
on the server and the local machine.

To exit SFTP mode just enter `..` in the top directory to which you `sftp`ed.

### Port forwarding

Let's say that there there is a service running on my Raspberry PI that is accessible only
via `localhost`. For example it can be a simple web server:
{% highlight bash %}
pi$ python3 -m http.server 7777 --bind 127.0.0.1 --directory .
{% endhighlight %}
Because server is listening only on `127.0.0.1` instead of `0.0.0.0`, 
we cannot access it from outside of my Raspberry PI:
{% highlight bash %}
mac$ curl raspberry_pi:7777
curl: (7) Failed to connect to raspberry_pi port 7777: Connection refused
{% endhighlight %}

To access the server we may e.g. forward connections to port 5432 on my laptop
to port 7777 on pi (this is called tunneling or port forwarding).
We can do this using SSH:
![SSH Tunnel](assets/images/2020-10-01/tunnel.png)
{% highlight bash %}
mac$ ssh -L localhost:5432:localhost:7777 pi
# In another terminal
mac$ curl localhost:5432
<html>
	<head></head>
	<body>
		Welcome on Raspberry PI!!!
	</body>
</html>
{% endhighlight %}
The general syntax is `-L local-machine:local-port:remote-machine:remote-port`.
Notice that for the `remote-machine` we have chosen `localhost`, but we could e.g.
chose other computer to which `pi` can connect. 
`local-machine` part can be omitted (`localhost` is the default). 

If you don't need the SSH session only the tunnel, you can run `ssh` as a background task
(this will not be a shell background task, so it will not show up in `bg` command):
{% highlight bash %}
mac$ ssh -fN -L localhost:5432:localhost:7777 pi
mac$ ps | grep ssh
84851 ttys001    0:00.01 grep ssh
84290 ttys002    0:00.15 ssh pi
{% endhighlight %}

Port forwarding can also work in the opposite direction. We may make a service running on
my laptop accessible on Raspberry PI:
{% highlight bash %}
mac$ python3 -m http.server 9999 --bind 127.0.0.1 --directory .

# On PI
pi$ $ curl localhost:5432
curl: (7) Failed to connect to localhost port 5432: Connection refused

# On Mac
mac$ ssh -R localhost:5432:localhost:9999 pi
pi$ curl localhost:5432
<html>
	<head></head>
	<body>
		Hello from MacOS!!!
	</body>
</html>
{% endhighlight %}
Here syntax is `-R remote-machine:remote-port:local-machine:local-port`.
Connections to `remote-machine:remote-port` are forwarded to `local-machine:local-port`.

By default the open ports are available on `localhost` only (think security!).
If you want to accept connections from outside, you need to change 
`GatewayPorts` settings of sshd daemon to `yes` on the server (the machine to which you connect to):
{% highlight bash %}
pi$ sudo vi /etc/ssh/sshd_config
# Set GatewayPorts yes
pi$ sudo service sshd restart
{% endhighlight %}
Now we can make `pi` accept connection from the entire local network and
forward them to my laptop:
{% highlight bash %}
# Establish tunnel
mac$ ssh -R '*:5432:localhost:9999' pi
# From my PC
old-pc$ curl raspberry_pi:5432
<html>
	<head></head>
	<body>
		Hello from MacOS!!!
	</body>
</html>
{% endhighlight %}
TIP: The single quotes are needed to prevent shell expansion of `*`.

### Providing internet connection via SSH

Say on your local machine you cannot access e.g. `facebook.com` for some strange reason.
But you noticed that on a certain server there is no such restriction,
and you can e.g. use `links` to browse `facebook.com`:
![Facebook in Links](assets/images/2020-10-01/fcrap.png)
Since FB does not looks good in `links` you really need a better solution...

Behold, SSH comes to the rescue. By using a dynamic port forwarding we may establish
SOCKS tunnel to the server:
{% highlight bash %}
mac$ ssh -C -D 1080 pi 
{% endhighlight %}
`-C` is for compression, `1080` is the standard SOCKS port.

Now we need to configure a browser. Firefox is well known for excellent SOCKS support:
![SOCKS proxy configuration in Firefox](assets/images/2020-10-01/ff.png)
And voilà `facebook.com` is working again!

A trick like this was very popular when I was living in a dormitory.
Our dorm internet connection was very slow, but as CS students we had SSH access
to a few servers, some of them with very fast internet connections...

### X Forwarding

Here I will explain how to do this on MacOS.
First we need to install [XQuartz](https://www.xquartz.org/), which is X11
port for MacOS:
{% highlight bash %}
mac$ brew install xquartz
{% endhighlight %}
Next we need to start XQuartz.app (it will only show in the dock).

Now we must enable X11 forwarding support on Raspberry PI:
{% highlight bash %}
pi$ sudo vi /etc/ssh/sshd_config
# Set: 
# X11Forwarding yes
# X11DisplayOffset 10
pi$ sudo service sshd restart
pi$ which xauth # Make sure xauth is installed
{% endhighlight %}

And finally we can start our X session:
{% highlight bash %}
mac$ DISPLAY=:0 ssh -X pi
pi$ vlc
{% endhighlight %}
Now when I typed `vlc` a VLC window popped up on my laptop. 
The resolution isn't great (it would look native if I used X11 port forwarding on Linux), 
this is due to poor retina display support in XQuartz. But still it works:
![XForwarding in MacOS](assets/images/2020-10-01/vlc.png)

### Tmux session manager

Sometimes you want to leave some program running on the server even if you close
you SSH connection. Or maybe you are doing something important, e.g. devops stuff and
you want to make sure that the command you are executing will not be interrupted.
For cases like this (...and for hacker movie lovers) terminal multiplexers where invented.
The two most popular ones are `screen` and `tmux`.

Here I will shortly explain what `tmux` is. 
Generally `tmux` deserves its own blog post,
fortunately for me [this post is already written](https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/).
Here I will only show you one single use-case, just to give you the taste what `tmux` is all about.

Let's connect to Raspberry PI and start `vi` inside `tmux` session:
{% highlight bash %}
pi$ tmux
pi [tmux]$ vi
# Some serious editing
{% endhighlight %}
Next I will perform some manual intervention (the physical connection got busted):
![Simulating connection link failure](assets/images/2020-10-01/pi.jpeg)
My SSH session on my laptop hanged so I had to kill it with `pkill ssh`.

Now after I fixed the Ethernet connection and reconnected to `pi` 
I can execute `tmux ls` and see my previous
session:
{% highlight bash %}
pi$ tmux ls
0: 1 windows (created Thu Oct  1 15:00:01 2020) [90x43]
{% endhighlight %}
Let's attach tmux to this session:
{% highlight bash %}
pi$ tmux attach -t 0
# Bang! my VI is back with all the unsaved text
{% endhighlight %}
Looks like after attaching I could recover all my previous work!

WARNING: `tmux` session will not survive the server restart. Make sure that the server
will not be restarted while running important computations within `tmux`.

Congrats! Now you are SSH PRO!

### References

* https://www.cyberciti.biz/faq/create-ssh-config-file-on-linux-unix/
* http://www.trembath.co.za/mctutorial.html
* https://phoenixnap.com/kb/ssh-port-forwarding
* https://help.ubuntu.com/community/SSH/OpenSSH/PortForwarding
* https://linuxize.com/post/how-to-setup-ssh-socks-tunnel-for-private-browsing/
* https://unix.stackexchange.com/a/46748
	  ]]></description>
	</item>

	<item>
	  <title>Minikomputer 8085 - Część II</title>
	  <link>//minikomputer-8085-czesc-II</link>
	  <author>mc</author>
	  <pubDate>2020-09-29T02:00:01+02:00</pubDate>
	  <guid>//minikomputer-8085-czesc-II</guid>
	  <description><![CDATA[
	     W [poprzednim](minikomputer-8085-czesc-I) wpisie udało nam się zbudować działający minikomputer oraz uruchomić
na nim napisany przez Davida Huntera monitor. Dla przypomnienia zbudowana przeze mnie
maszyna wyglądała następująco:
![Minikomputer wyłaniający się z chaosu](assets/images/2020-09-29/comp1.jpeg)
Podczas kilku kolejnych godzin pracy z komputerem, szybko okazało się że taka plątanina
przewodów znacznie utrudnia debugowanie i rozwiązywanie problemów.
Co gorsza przewody połączeniowe nie zapewniały dobrej jakości połączeń pomiędzy układami scalonymi.
W efekcie komputer potrafił nie startować lub zawieszał się podczas wykonywania programów.

Kolejną ważną rzeczą którą pominąłem podczas budowy komputera są 
kondensatory odsprzęgające (ang. decoupling capacitors). 
Układy scalone, zwłaszcza te należące do rodziny 74LS 
potrafią emitować sporo zakłóceń podczas zmiany stanu.
Dołączenie kondensatora foliowego lub ceramicznego o pojemności 0.1uF do linii zasilania układu
pozwala zmniejszyć zakłócenia i poprawia stabilność jego działania.

Teraz nadszedł czas żeby naprawić wszystkie powyższe mankamenty. 
Przewody połączeniowe zastąpiłem
ciętymi na wymiar przewodami jednożyłowymi. Oprócz kondensatorów odsprzęgających,
dodałem do szyny zasilania również jeden duży kondensator elektrolityczny o
znacznej pojemności (470uF). Generalnie dokładanie tak dużych kondensatorów nie jest
zalecane bo potrafi mocno obciążyć zasilacz w momencie startu układu.
Ja używam prostego zasilacza do płytek stykowych który przeżył już niejedno zwarcie,
więc na razie postanowiłem zignorować ten problem.
Efekt mojej pracy widać poniżej:
![Minikomputer tym razem z porządnymi połączeniami](assets/images/2020-09-29/comp2.jpeg)

Przy okazji przebudowy komputera postanowiłem wprowadzić kilka modyfikacji.
Po pierwsze zastąpiłem pojedyńczy rejestr wejścia/wyjścia z projektu Huntera,
dwoma rejestrami wyjściowymi i jednym wejściowym. Dzięki temu w prosty sposób
będziemy mogli podłączyć do komputera zarówno 2x16 znakowy wyświetlacz LCD,
jak i parę przycisków. 

Warto tutaj zaznaczyć że oryginalny projekt Huntera również pozwala na integracje z
wyświetlaczem LCD, jeżeli tylko wykorzystamy rejestry przesuwne 74LS595 do zwielokrotnienia liczby
wyjść. Dokładnie tą samą sztuczkę wykorzystał Ben Eater w swoim 
[programatorze EEPROM](https://github.com/beneater/eeprom-programmer).

Ostatecznie po wszystkich modyfikacjach schemat komputera wygląda następująco:
![Schemat minikomputera](assets/images/2020-09-29/mikrus-85.svg)
Powyższy schemat oddaje jeden do jednego układ połączeń oraz typ układów scalonych które znalazły się
na moich płytkach stykowych. Na przykład miałem pod ręką tylko jeden układ 74HCT574.
Przy budowie portów wyjściowych musiałem więc wykorzystać dwa starsze układy 74HCT374,
które robią co prawda to samo co 74HCT574, ale mają znacznie mnie wygodny układ wyprowadzeń.
Podobnie nie posiadałem 74LS373 więc użyłem 74LS574 w połączeniu z inwerterem.
Na koniec przypomnę że układy rodzin 74LS i 74HCT są ze sobą kompatybilne i można je
stosować zamiennie.

Schemat minikomputera został stworzony w darmowym i popularnym wśród hobbystów programie
[KiCad](https://kicad-pcb.org/). Podczas tworzenia schematu nie widziałem co wpisać w pole tytuł,
postanowiłem więc nadać mojemu komputerowi nazwę Mikrus-85. Hurra!

Kolejny celem jaki przed sobą postawiłem była kompilacja i uruchamianie na Mikrusie
programów napisanych w C.
Niestety już samo znalezienie odpowiedniego kompilatora stanowiło duży problem.
[Small Device C Compiler](http://sdcc.sourceforge.net/) mógłby być idealnym wyborem,
gdyby wspierał używany przeze mnie procesor 8085. 
Co prawda prace nad dodaniem takiego wsparcia
rozpoczęły się [ponad rok temu](https://github.com/kenyapcomau/sdcc-8080), 
ale nie zaowocowały jeszcze w pełni działającym kompilatorem.
Warto dodać że procesor 8085 jest wstecznie kompatybilny z procesorem 8080
(dokładnie mówiąc 8085 dodaje tylko dwie nowe instrukcje), więc
kompilator C dla 8080 może być z powodzeniem wykorzystany również do 
generowania kodu dla 8085.

Ostatecznie postanowiłem użyć kompilatora [Small-C](https://github.com/ncb85/SmallC-85),
napisanego ponad 30 lat temu przez Chrisa Lewisa, a przywróconego do życia dzięki wysiłkom
użytkownika [ncb85](https://github.com/ncb85). ncb85 oprócz kodu kompilatora
udostępnił też na swoim koncie [przykład jego użycia](https://github.com/ncb85/utilis-and-examples/tree/master/cpm_hello)
co pozwoliło mi zaoszczędzić niemało czasu.

Wracając do samego kompilatora, jest to dość stary program który powstał jeszcze przed
wprowadzeniem standardu C89 (sic!). Poniżej garść ciekawostek które się z tym wiążą:

* Nie ma typu `void`. Metody domyślnie zwracają typ `int`. :deal-with-it-parrot:
* Brak wsparcia dla inicjalizacji wartości zmiennych globalnych.
* Deklaracja metod musi byc wykonana w przestarzałym stylu [K&R](https://en.wikipedia.org/wiki/C_(programming_language)#K&R_C):

{% highlight c %}
lcd(regSelect, data)
    char regSelect;
    char data;
{
    // code
}
{% endhighlight %}
Współcześnie napisalibyśmy:
{% highlight c %}
void lcd(char regSelect, char data) {
    // code
}
{% endhighlight %}

Ponieważ nasz procesor jest 8-bitowy do dyspozycji mamy jedynie cztery typu liczb całkowitych:
`unsigned char`, `signed char`, `unsigned int` i `signed int`.
Operacje na 16-bitowych typach `int` muszą być symulowane za pomocą dostarczanej razem z kompilatorem
biblioteki [crun8085lib.asm](https://github.com/marcin-chwedczuk/mikrus-85/blob/master/smallC/crun8085lib.asm).

Sam kompilator jest bardzo prosty, nie generuje prawie żadnych ostrzeżeń - łatwo więc sobie strzelić w stopę.
Dla przykładu poniższa pętla jest nieskończona:
{% highlight c %}
char c;
for (c = 0; c < 128; c++) {
    // do nothing
}
{% endhighlight %}
Od czasu do czasu kompilator kończy pracę zgłaszając Segmentation Fault.
Praca z Small-C wymaga więc sporej dozy i cierpliwości, i wyrozumiałości, i wytrwałości.

Stworzenie najprostszego programu w C `main() { }` przy użyciu Small-C wymaga
trochę więcej wysiłku niż tylko uruchomienie kompilator. W wyniku kompilacji
otrzymujemy bowiem nie plik binary, ale plik źródłowy assemblera który
należy jeszcze poddać translacji do kodu maszynowego.
Do tego celu należy wykorzystać `as8085` będący częścią pakietu [ASxxxx](https://shop-pdp.net/ashtml/asxxxx.php).
`ASxxxx` jest wciąż rozwijanym projektem posiadającym naprawdę dobrą [dokumentację](https://shop-pdp.net/ashtml/asxbld.htm).
Dzięki temu zbudowanie assemblera ze źródeł nie powinno sprawić nam żadnych problemów.

Czas na małą dygresję. Po starcie procesor 8085 zaczyna
wykonywanie kodu programu od adresu `0x0000`.
Wartości rejestrów procesora, w szczególności rejestru `SP` odpowiedzialnego
za zarządzaniem stosem nie są na starcie procesora dobrze zdefiniowane.
Zanim wywołamy naszą funkcję `main()` powinniśmy nadać rejestrowi `SP` poprawną wartość.
Zbudowany przeze mnie komputer posiada następującą mapę pamięci:
{% highlight no-highlight %}
Adresy          | Przeznaczenie
---------------------------------
0x0000 - 0x1FFF - ROM
0x2000 - 0x3FFF - RAM
0x8000          - output port 1
0xA000          - output port 2
0xC000          - input port
{% endhighlight %}
Stos na 8085 podobnie jak w innych procesorach Intela rośnie w dół (w kierunku mniejszych adresów).
Dodatkowo warto żeby adres stosu był parzysty, rozsądnym wyborem jest więc ustawienie `SP`
na adres `0x3FFE` a więc przedostatni dostępny adres pamięci RAM.

Ostatecznie stworzyłem plik `cstart.asm` odpowiedzialny za przygotowanie
środowiska dla C:
{% highlight asm %}
;       Run time setup for Small C.
        .module CSTART
        .area   CSTART (REL,CON) ;program area CRTSO is RELOCATABLE
        .list   (err, loc, bin, eqt, cyc, lin, src, lst, md)
        .nlist  (pag)
        .globl  cstartend

        lxi h,#0x3ffe   ; Initialize stack on even address.
                        ; Stack grows downwards.
        sphl            ; Load HL into SP

        call    main    ; call main program

stop:
        hlt             ; stop processor
        jmp stop        ; interrupt can wake CPU from hlt

cstartend:
       .end
{% endhighlight %}
Pozostaje nam już tylko upewnić się że kod z pliku `cstart.asm` wyląduje pod
adresem `0x0000`. Do tego celu musimy 1) nadać mu unikalną nazwę `CSTART` 
2) wykorzystać parametr linkera `-b` żeby wymusić pozycje obszaru `CSTART`
w pamięci EEPROM.

Poniżej przedstawiam parametry linkera (plik `eeprom.lnk`):
{% highlight no-highlight %}
-ioux
eeprom-img
cstart
main
-b CSTART=0
-b SMALLC_GENERATED=0+cstartend
-e
{% endhighlight %}
Zauważmy że kod w pliku `cstart.asm` kończy się deklaracją labelki `cstartend`.
Labelkę to wykorzystujemy żeby zmusić linker to umieszczenia kodu wygenerowanego 
przez Small-C (`SMALLC_GENERATED`) zaraz po kodzie sekcji `CSTART`.

Jeżeli zaczniemy pisać bardziej skomplikowane programy w C to może się okazać
że nasz program wymaga funkcji, znajdujących się we wspomnianej już przeze mnie
bibliotece `crun8085lib.asm`. Na chwilę obecną po prostu kopiuje brakujące funkcje
do pliku `cstart.asm`, postaram się to poprawić w kolejnym wpisie.

Ostatecznie wynikiem kompilacji i linkowania jest plik w formacie Intel HEX
który możemy już wypalić w pamięci EEPROM.

W trakcie zabawy z Mikrusem przygotowałem prosty [program](https://github.com/marcin-chwedczuk/mikrus-85/tree/master/test/single-file-prog)
który wypisuje wiadomość na ekran LCD oraz pozwala na obsługę dwóch przycisków:
![Obsługa LCD](assets/images/2020-09-29/lcd.jpeg)

Na koniec zagadka dla czytelników: W tej chwili Small-C nie pozwala nam wykorzystać zmiennych
globalnych. Odczyt zmiennych jest co prawda możliwy ale zapisy do zmiennych zdają się "znikać"?
Dlaczego tak się dzieje?

W następnym wpisie postaram się to naprawić.
Koniec części drugiej.
	  ]]></description>
	</item>

	<item>
	  <title>Minikomputer 8085 - Część I</title>
	  <link>//minikomputer-8085-czesc-I</link>
	  <author>mc</author>
	  <pubDate>2020-09-20T02:00:01+02:00</pubDate>
	  <guid>//minikomputer-8085-czesc-I</guid>
	  <description><![CDATA[
	     Już od dłuższego czasu myślałem o tym żeby zbudować swój własny minikomputer.
W internecie można znaleźć mnóstwo tego typu projektów, z moich ulubionych
mogę wymienić oparty na procesorze 6502 [komputer autorstwa Bena Eatera](https://eater.net/6502)
oraz oparty na CPU Intela [MiniMax8085 Sergieja Malinova](http://www.malinov.com/Home/sergeys-projects/minimax8085).
Mój minikomputer
postanowiłem jednak oprzeć na artykule opublikowanym na łamach czasopisma [Nuts and Volts](https://www.nutsvolts.com/),
autorstwa Davida Huntera. Dokładniej chodzi o artykuł
[Build a pocket-sized ALTAIR computer](https://www.nutsvolts.com/magazine/article/build-a-pocket-sized-altair-computer)
z początku 2019 roku.

Olbrzymią zaletą opisywanego w artykule komputera jest jego prostota.
Podstawową wersję komputera, możemy zbudować przy pomocy zaledwie pięciu 
układów scalonych (CPU, RAM, ROM, 74LS373 oraz 74LS139).
Dodatkowo do budowy komputera możemy wykorzystać płytki stykowe, 
dzięki czemu możemy się obejść bez lutownicy.

Pierwszą przeszkodą z jaką musimy się zmierzyć jest zakup procesora.
Oryginalny układa 8085 Intela jest już praktycznie niedostępny na rynku.
Na szczęście wciąż jeszcze można kupić kompatybilne z nim zamienniki.
Bardzo pomocna jest tutaj strona [www.cpu-collection.de](http://www.cpu-collection.de/?tn=0&l0=cl&l1=8085)
która podaje ich długą i wyczerpującą listę.
Dla przykładu udało mi się kupić układ oznaczony jako `SAB 8085AH2P`,
który jak się okazało jest nadal dostępny w sklepie [inter-chip.pl](https://inter-chip.pl/8085p-2630.html)
(uprzedzam strona sklepu jest okropna).
Z kolei klon `AMD P8085A` zdaje się być dostępny w sklepie [TVSAT-SHOP.pl](https://shop.tvsat.com.pl/pl/p/1szt-IC-uPC-P8085A-DIP40-AMD/31712)
w nieco niższej cenie.
![Zakupiony przeze mnie procesor 8085](assets/images/2020-09-20/my8085.jpeg)

Na koniec pewna uwaga techniczna: dwójka znajdująca się przy końcu oznaczenia procesora np. `SAB 8085AH2P`
wskazuje na model który może być taktowany z częstotliwością do 5MHz. Układy bez dwójki np. `AMD P8085A` mogą być taktowane
zegarem do 3MHz. Warto dodać że procesor pracuje z połową częstotliwości podłączonego do niego
rezonatora kwarcowego (aka kryształu). Jeżeli więc chcemy taktować procesor z częstotliwością 5MHz, to powinniśmy
użyć kryształu 10MHz'owego. Z drugiej strony minimalna częstotliwość z jaką mogą pracować te procesory wynosi 1MHz,
czyli minimalna częstotliwość rezonatora kwarcowego to 2MHz.

Zakup pozostałych części nie powinien sprawić większych kłopotów.
Pełna lista wymaganych komponentów podana jest w [artykule pana Huntera](https://www.nutsvolts.com/magazine/article/build-a-pocket-sized-altair-computer#Parts%20List),
do tego potrzebować będziemy jeszcze stabilizowanego źródła zasilania 5V, trzech płytek stykowych, 
całej masy przewodów połączeniowych i kilku diod LED.

Do programowania pamięci EEPROM możemy wykorzystać popularny wśród hobbystów TL866II PLUS
(cena około 300PLN). Prosty programator można również zbudować samemu z wykorzystaniem Arduino
(patrz [programator Bena Eatera](https://www.youtube.com/watch?v=K88pgWhEb1M) 
oraz [TommyPROM](https://github.com/TomNisbet/TommyPROM)).

Do komunikacji z PC potrzebować będziemy jeszcze konwertera `USB <-> UART`
(aka FTDI), który możemy [kupić za około 15PLN](https://botland.com.pl/pl/konwertery-usb-uart-rs232-rs485/4501-konwerter-usb-uart-pl2303-wtyk-usb-waveshare-4037.html).
Przed podłączeniem konwertera do budowanego minikomputera, należy upewnić się
że zworka odpowiedzialna za wybór napięcia znajduje się w pozycji 5V:
![Konwerter USB UART](assets/images/2020-09-20/ftdi.jpeg)
Po podłączeniu konwertera do komputera, system operacyjny powinien "wystawić" urządzenie jako nowy port szeregowy
np. `COM3` w systemie Windows lub `/dev/ttyUSB0` w systemie Linux.

Na koniec uwaga praktyczna: Układ 74HCT373 możemy zastąpić nowszym 74HCT573 który zdaje się mieć nieco
bardziej rozsądny układ wyprowadzeń (wszystkie wejścia po jednej stronie układu).
Zamiast 74HCT373 lub 74HCT573 możemy wykorzystać układ 74HCT574 zgodnie ze schematem:
![Alternatywny zatrzask adresu](assets/images/2020-09-20/74.png)
(źródło: [Análisis general de un Microprocesador](https://silo.tips/download/analisis-general-de-un-microprocesador))

Jako inwerter można wykorzystać np. CD40106BE.
Testowałem powyższą konfigurację z kryształem 4MHz i wszystko działało bez problemów.

### Budowa i uruchomienie układu

Moje pierwsze podejście do budowy komputera wyglądało następująco: 
umieściłem wszystkie niezbędne komponenty komputera na płytkach stykowych,
dwukrotnie sprawdziłem poprawności połączeń, podłączyłem konwerter `USB <-> UART`
i na koniec włączyłem zasilanie. I... nic. 
Komputer nie pracował, a ja nie miałem pojęcia dlaczego.
Musiałem więc rozmontować cały układ i zbudować go jeszcze raz, tym razem
krok po kroku.

Rozpocząłem od podłączenie jedynie CPU, pamięci ROM oraz układu 74HCT573.
![Alternatywny zatrzask adresu](assets/images/2020-09-20/ver1.jpg)
W tym układzie:

* Nóżki RD i WR procesora połączyłem przez oporniki 22k z plusem zasilania (+5V)
* Nóżkę WE pamięci ROM podłączyłem do plusa zasilania (zapis wyłączony)
* Nóżkę CE pamięci ROM podłączyłem do masy/GND (ROM włączony na stałe)
* Nóżkę OE pamięci ROM podłączyłem do nóżki RD procesora
* Nóżkę RST7_5 procesora odłączyłem od nóżki SID i zamiast tego połączyłem z masą zasilania przez opornik 1k

Do sprawdzenia czy procesor działa wykorzystałem pomysł pochodzący
z [glitchwrks.com](http://www.glitchwrks.com/2010/09/02/8085-sbc),
to jest wykorzystanie wyjścia SOD procesora do sterowania diodami LED:
![Podłączenie diod LED do SOD](assets/images/2020-09-20/leds.png)
Ponieważ nasz "komputer" nie posiada jeszcze pamięci RAM to nie mogłem
wykorzystać zamieszczonego przez GlitchWorks kodu. Brak pamięci RAM
oznacza bowiem brak stosu wywołań funkcji. Innymi słowy rozkazy `CALL`
i `RET` nie działają w tej konfiguracji. Zamiast wywołań funkcji wykorzystałem
więc, będącą wciąż w powszechnym użyciu metodę Kopiego-Pasty:
{% highlight asm %}
    ORG 0000H

FLASH           MVI     A,0C0h ; LED ON
                SIM       
                
                MVI A,0FFh ; Wait about half a second
DELAY           DCR A
                JZ CLEAR 
BLOOP           MVI B,0FFh
BLOOP2          DCR B
                JNZ BLOOP2
                JMP DELAY

CLEAR           MVI A,040h ; LED OFF
                SIM

                MVI A,0FFh ; Wait about half a second
DELAYx          DCR A
                JZ FLASH
BLOOPx          MVI B,0FFh
BLOOP2x         DCR B
                JNZ BLOOP2x
                JMP DELAYx

                HLT 
HERE            JMP HERE

    END FLASH
{% endhighlight %}
Powyższy kod nie należy do najbardziej czytelnych i pięknych, ale pozwoli nam przetestować działanie komputera.

Kod skompilowałem za pomocą wspomnianego w artykule assemblera [a85](https://github.com/glitchwrks/a85),
który co prawda potrafi zgłaszać enigmatyczne błędy, ale posiada całkiem przyzwoity [manual](https://github.com/glitchwrks/a85/blob/master/A85.DOC).
No cóż przyjaciele, RTFM!
{% highlight bash %}
$ ./a85 test.asm -o test.hex
# Pamiętajcie żeby użyć poprawnego typu pamięci
$ minipro -p AT28C64 -w test.hex 
{% endhighlight %}
Opensource'owe [oprogramowanie do programatora TL866 II PLUS](https://gitlab.com/DavidGriffith/minipro) 
dopiero od kilku miesięcy obsługuje format Intel HEX. 
Jeżeli dostaniecie komunikat o nieznanym formacie pliku spróbujcie uaktualnić `minipro` do
najnowszej wersji.

Tym razem wszystko poszło zgodnie z planem i mogłem przez kika minut delektować się mruganiem diod LED.

W kolejnym kroku dodałem do komputera układ 74HTC139 (nowszy zamiennik 74LS139) zgodnie ze schematem
zamieszczonym w artykule i przekonałem się że dioda LED nadal miga.

Kolejny krok polegał na dodaniu modułu RAM, który pracowicie połączyłem z resztą komputera:
![Komputer w budowie](assets/images/2020-09-20/comp1.jpeg)
Diody nadal migały, ale teraz mogłem spróbować uruchomić na moim komputerku oryginalny kod z GlitchWorks:
{% highlight asm %}
    ORG 0000H

START          LXI     H,02060h  
               SPHL              


FLASH          MVI     A,0C0h    
               SIM               
               CALL    DELAY     
               MVI     A,40h     
               SIM               
               CALL    DELAY     
               JMP     FLASH     

;Delay, return to HL when done.
DELAY          MVI     A, 0FFh   
               MOV     B,A       
PT1            DCR     A         
PT2            DCR     B         
               JNZ     PT2       
               CPI     00h       
               JNZ     PT1       
               RET               

    END FLASH
{% endhighlight %}
Po kompilacji, wgraniu programu i uruchomieniu komputera diody nadal migały - hurra!

OK pora spróbować uruchomić [oprogramowanie](https://www.nutsvolts.com/magazine/article/build-a-pocket-sized-altair-computer#content-extras) 
przygotowane przez Huntera. 

Zanim jednak podłączyłem konwerter `USB <-> UART` do komputera, połączyłem ponownie nóżkę SID procesora z nóżką RST7_5
i jeszcze raz sprawdziłem wszystkie pozostałe połączenia. 

Pin GND konwertera `USB <-> UART` podłączyłem do masy zasilania, pin `SOD` procesora połączyłem z pinem `RDX` konwertera,
a pin `SID` z pinem `TXD`. Pin `VCC` konwertera pozostał niepodłączony.

Po kompilacji pliku `AltaidsROM.asm` i wgraniu programu do EEPROM uruchomiłem [Putty](https://www.putty.org/) żeby móc
odbierać komunikaty wysyłane z komputera. Użyłem następującej konfiguracji (2400 baud, 8N1, Flow control: None):
![Konfiguracja Putty](assets/images/2020-09-20/putty.png)
Niestety jedyne co mogłem odczytać to wydawałoby się losowe znaki. Problemem okazała się częstotliwość z jaką pracował
mój mikrokomputer, ale sam byłem sobie winny - zamiast kryształu 4.9152MHz użyłem kryształu 4MHz. 

Na szczęście, jak sugeruje pan Hunter, jest to proste do naprawienia - wystarczy nadać stałym `HALFBIT` i `FULLBIT`
(patrz `AltaidsROM.asm`) odpowiednio przeskalowane wartości. Ponieważ użyta przeze mnie częstotliwość procesora to 
2MHz (= 4MHz / 2) to musiałem przeskalować i zaokrąglić oryginalne wartości do:
{% highlight nohighlight %}
s = 2 / 2.4576
HALFBIT = s * 38 = 31
FULLBIT = s * 69 = 56
{% endhighlight %}
Obie stałe wykorzystywane są do obliczenia czasu transmisji pojedyńczego bitu (i jego środka) przy szybkości transmisji 2400 baudów.

Po uruchomieniu komputera powitał mnie następujący widok:
![Kolejny problem](assets/images/2020-09-20/gib.png)
Połowa tekstu była czytelna, połowa zawierała śmieci. Sam komputer nie zachowywał się poprawnie.
Po około godzinie debugowania i zbyt dużej ilości CLUB-MATE udało mi się znaleźć problem:
źle podłączoną linię adresową A11. 

Szybko naprawiłem to niedopatrzenie. Tym razem wszystko działało poprawnie a ja mogłem wpisać i uruchomić
prosty program w BASIC'u (przy wpisywaniu musiałem zachować około jednosekundowy odstęp pomiędzy kolejnymi znakami,
wspierane są tylko duże litery):
![BASIC I](assets/images/2020-09-20/basic1.png)
![BASIC II](assets/images/2020-09-20/basic2.png)
![BASIC III](assets/images/2020-09-20/basic3.png)

Koniec części pierwszej. Ciąg dalszy nastąpi...




	  ]]></description>
	</item>

	<item>
	  <title>Future[_] vs Future[Unit] or which return type should I choose?</title>
	  <link>//future-or-future</link>
	  <author>mc</author>
	  <pubDate>2020-09-12T02:00:01+02:00</pubDate>
	  <guid>//future-or-future</guid>
	  <description><![CDATA[
	     Recently I have a heated debate with my colleague about
a proper return type for async procedures 
(procedure is just a function that returns `Unit` in Scala.)
My point of view was that `Future[Unit]` is the right type.
Let me present my way of reasoning here. 

Let's start with lifting.
Lifting in functional programming is defined as an operation that
transforms a function `f: A => B` into a function `f': M[A] -> M[B]`,
where `M[_]` is a functor. A functor `M[A]`, in simple words, is just a wrapper around a value of 
type `A` with addition of extra `map` operation that can be used to transform the wrapped value.
A lot of types that we are using in our daily practice as programmers like `Option[T]`, `Try[T]` or
`Future[T]` are functors. Because Scala does not define `Functor[T]` trait we cannot write a generic
`lift` function that could work with all these types. Instead we must write specific `lift` functions that
work with only single functor type e.g.
{% highlight scala %}
def liftOption[A, B](f: A => B): Option[A] => Option[B] = {
  optA => optA.map(f)
}
{% endhighlight %}
We can use `liftOption` to e.g. make `negate` function work with `Option[Int]` argument:
{% highlight scala %}
def negate(a: Int): Int = -a

val negateOpt = liftOption(negate)

println(negateOpt(Some(1)))
println(negateOpt(None))
// prints:
//  Some(-1)
//  None
{% endhighlight %}
Similarly to `liftOption` we could define `liftFuture`:
{% highlight scala %}
def liftFuture[A,B](f: A => B)
                  (implicit ec: ExecutionContext)
: Future[A] => Future[B] = {
    futA => futA.map(f)
}
{% endhighlight %}
And then we can use it on a function that returns `Unit` to get an async function that,
no surprise here, will return `Future[Unit]`:
{% highlight scala %}
import ExecutionContext.Implicits.global

def printIt(s: String): Unit = println(s)
val printItF = liftFuture(printIt)

val r: Unit = Await.result(
    printItF(Future.successful("ok")),
    duration.Duration.Inf)
{% endhighlight %}

But of course my colleague had his own arguments. 
He pointed out that e.g. `ExecutorService` `submit` method returns `Future<?>`, not `Future<Void>` as my
reasoning would suggest. So there must be a good reason why library designers
chosen `Future<?>`, he continued, but when asked what exactly this reason could be 
he was not able to answer. But he counter my question arguing that the standard 
library establishes good patterns and practices, so if they use `Future<?>`
then we should do the same in our code.
![Future is there](assets/images/2020-09-12/es.png)

My colleague had a point. I needed to research the subject: why `Future<?>` and not `Future<Void>`?
After a bit of googling I noticed that `runAsync` method of
[CompletableFuture](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html)
does not follow the `Future<?>` convention and instead returns `CompletableFuture<Void>`.
So it looks like the library designers changed their mind and now prefer returning `Future<Void>`:
![Void is there](assets/images/2020-09-12/cf.png)

I pointed this out to my colleague, but he countered by saying that `Future[Unit]`
is just uncomfortable to use. Consider this example he said:
{% highlight scala %}
def findIdByName(name: String): Future[Int] = {
  Future.successful(123)
}

def deleteRecord(id: Int): Future[Int] = {
  Future.successful(1)
}

def doStuff(name: String): Future[Unit] = {
  findIdByName(name)
    .flatMap(id => deleteRecord(id))
    .map(_ => ())
}
{% endhighlight %}
Look at this ugly `.map(_ => ())` he said, it's awful, isn't it?
I pointed out that he can use for-comprehensions to get rid
of the last `map`, but may argument was weak - the
fluent interface is often nicer and faster to work with.
{% highlight scala %}
def doStuff(name: String): Future[Unit] = {
  for {
    id <- findIdByName(name)
    _ <- deleteRecord(id)
  } yield ()
}
{% endhighlight %}
Indeed I find it very strange that Scala does not provide a conversion from 
`Future[T]` to `Future[Unit]` out of the box. In sync code we could write:
{% highlight scala %}
def doStuff(name: String): Future[Unit] = {
  val id <- findIdByName(name)
  deleteRecord(id)
}
{% endhighlight %}
and the value returned by `deleteRecord` would be automatically discarded.
Why can't we have something similar in async code?

Yet this last problem pointed me to the following issue.
If we agree to use `Future[_]` everywhere, then we may return by mistake
a value that should never be returned. 
In other words we may inadvertently break object or module
encapsulation. 
There is also a small risk of a memory leak, if we return
say a huge array and the `Future[_]` value will be kept for a while.
This is illustrated by the following example:
{% highlight scala %}
// In some object
private var balance = 1234

private def increaseBalance(amount: Int): Future[Int] = {
  val oldBalance = balance
  balance = oldBalance + amount
  Future.successful(oldBalance)
}

// This should return nothing
def doStuff(): Future[_] = {
  increaseBalance(100)
}

// Calling code
val escapedBalance = Await.result(obj.doStuff(), duration.Duration.Inf)
println(escapedBalance) // 1234
{% endhighlight %}
Seeing all these arguments, in the end, we decided to go with `Future[Unit]` although
it is not a perfect solution.

There is nothing better than a healthy debate BTW ;D
	  ]]></description>
	</item>

	<item>
	  <title>Passing functions as arguments in Scala. What can go wrong?</title>
	  <link>//passing-functions-as-arguments-in-scala-what-can-go-wrong</link>
	  <author>mc</author>
	  <pubDate>2020-09-11T02:00:01+02:00</pubDate>
	  <guid>//passing-functions-as-arguments-in-scala-what-can-go-wrong</guid>
	  <description><![CDATA[
	     In microservices architecture we often designate a single service for managing the configuration of the entire system.
Libraries like [Archaius](https://github.com/Netflix/archaius) make this easy. 
As a side effect, on the code level I often see class declarations like this:

{% highlight scala %}
class MyService(timeoutProperty: () => Long) {
  ...
}
{% endhighlight %}

Basically we inject providers for current configuration properties values into classes.
This has two advantages. First, our classes are independent of any library that we are using
for managing configuration. And second, our classes are easy to test - no mocks needed.

Yet this approach can lead to subtle bugs. Say our original code that creates `MyService`
looks like this:
{% highlight scala %}
new MyService(() => currentTimeoutValue())
{% endhighlight %}
Imagine that a few weeks later a Scala purist is coming by and decides to "improve" this code into:
{% highlight scala %}
new MyService(currentTimeoutValue)
{% endhighlight %}
Shorter code, better code as they say...
A few more weeks pass by and we realise that using `Long`s for storing time intervals is passé.
So now we are slowly migrating our `() => Long` providers into `() => java.time.Duration`.
Of course as Scala fanboys we decided to add an extension method to `Long`, to make the entire
process less painful:
{% highlight scala %}
implicit class MyRichLong(l: Long) {
  def asMillisecondsDuration(): Duration = {
    Duration.ofMillis(l)
  }
}
{% endhighlight %}
In meantime, the code responsible for `MyService` creation morphed into:
{% highlight scala %}
class MyServiceRefactored(timeoutProperty: () => Duration) { ... }

new MyServiceRefactored(currentTimeoutValue().asMillisecondsDuration)
{% endhighlight %}
And... BOOM! It's no longer working!

Why this code is no longer working? Because
{% highlight scala %}
new MyServiceRefactored(currentTimeoutValue().asMillisecondsDuration)
{% endhighlight %}
is transformed by Scala compiler into
{% highlight scala %}
val tmp = currentTimeoutValue()
new MyServiceRefactored(() => tmp.asMillisecondsDuration())
{% endhighlight %}
So `timeout` property value is frozen at the moment of `MyServiceRefactored` object creation,
this is not what we want.

Bugs like this are hard to figure out. At the first glance everything works fine.
The problem demonstrates itself only when we try to adjust the property value at runtime.
And even then a simple service restart will reload the property, so we may incorrectly assign
it to a configuration server/library/networking glitch.

Here I must mention that this bug was possible only because we broken one of Scala's good practices.
Our extension method is declared like so
{% highlight scala %}
def asMillisecondsDuration(): Duration
{% endhighlight %}
but we should be declared like this
{% highlight scala %}
def asMillisecondsDuration: Duration
{% endhighlight %}
as this method is actually a getter - it does not mutate the object on which it is called.
If we use the second declaration our bug would be quickly detected by Scala compiler.

In practice a lot of Scala programmers are confused by the optional parentheses
in parameterless method declarations. I often see methods declared like `def foo: Unit`
that mutate the state or method declared like `def bar(): Int` that are just getters.
For people like me, that constantly switch between Java and Scala, this is especially difficult
and I routinely make mistakes like this (I add parentheses everywhere)...

One solution that people often come up with when confronted with this problem is to
replace functions by by-name parameters.

By-name parameters are nothing new. They where first introduced more than 50 years ago in a language called
Algol60. Early programmers of that language quickly found out that by-name parameters are error prone and difficult to use.
As a result most of the contemporary programming languages do not support them.

Scala as ~~an over-engineered~~ a versatile language supports by-name parameters, as they allow programmers
to create functions that mimic the language build-in constructs. For example:
{% highlight scala %}
def repeat(times: Int)(f: => Unit): Unit = {
  for (_ <- 1 to times) {
    f
  }
}

repeat(3) {
  println("hurray!")
}
{% endhighlight %}

The main problem with by-name parameters is that they do not follow the
usual order of evaluation. An ordinary function call
{% highlight scala %}
egg(foo()), bar())
{% endhighlight %}
will result in functions `foo` and `bar` being called one after another,
followed by `egg` function call.
When we use by-name parameters no order is guaranteed, `foo` may be called
before or after `bar` or may not be called at all, 
or may be called three times, or four...
This makes code difficult to reason about.
That is why I use by-name parameters sparingly, usually only when I need to implement a
new statement like construct.

That being said, we may declare our new version of `MyService` as
{% highlight scala %}
class MyService(timeoutProperty: => Duration) {
  ...
}
{% endhighlight %}
and it will work flawlessly with our converted-on-the-fly property:
{% highlight scala %}
new MyService(currentTimeoutValue().asMillisecondsDuration())
{% endhighlight %}

To make it clear that we are passing not a value but an expression to be evaluated
(called a [thunk](https://en.wikipedia.org/wiki/Thunk)), 
we can surround the expression with curly braces:
{% highlight scala %}
new MyService({ currentTimeoutValue().asMillisecondsDuration() })
{% endhighlight %}
But it must be noted that in Scala we can add curly braces to almost anything, 
e.g. `println({1} + {2})`.
In other words curly braces around thunks are only a convention not enforced by the compiler.

Sometimes the best solution is the object-oriented one. So after being disappointed with by-name
params I decided to create an interface:
{% highlight scala %}
@FunctionalInterface
trait Property[V] {
  // parentheses required for lambda -> SAM conversion
  // in Scala 2.13. Yeah this sucks!
  def value(): V
}
{% endhighlight %}
and inject it into `MyService`:
{% highlight scala %}
class MyService(timeoutProperty: Property[Duration]) { ... }
{% endhighlight %}
Scala since version 2.12 supports converting lambda expressions to SAMs (Single Method Interfaces),
so we can create `MyService` without too much ceremony:
{% highlight scala %}
new MyService(() => currentTimeoutValue().asMillisecondsDuration())
{% endhighlight %}
No simplification is possible this time, and both below examples do not compile:
{% highlight scala %}
new MyService({ currentTimeoutValue().asMillisecondsDuration })
new MyService(currentTimeoutValue().asMillisecondsDuration)
{% endhighlight %}

The protection is, unfortunately, not 100% bullet proof.
For example the following code snipped will compile but does not work as intended:
{% highlight scala %}
new MyService(currentTimeoutValue().asMillisecondsDuration _)
{% endhighlight %}
At least it provides a visual clue (`_`) that will attract reviewer attention during the code review.

Now I fully understand why Java designers decided to introduce a new operator `::` for creating method
references. It makes it clear which part of the expression will be evaluated only once and which part
will become the functional interface implementation:
{% highlight scala %}
public static void main(String[] args){
  print(next()::toString);
  print(next().toString()::toUpperCase);
  print(next().toString().toUpperCase()::trim);
  
  print(() -> next().toString());
}
{% endhighlight %}
Compare this with Scala:
{% highlight scala %}
def main(args: Array[String]): Unit = {
  print(next().toString)
  print(next().toString.toUpperCase)
  print(next().toString.toUpperCase.trim)
}
{% endhighlight %}

Looks likes the third solution is the best one. The only thing left is to provide a fake
implementation for `Property[V]` interface to make testing easy:
{% highlight scala %}
class ManuallySetProperty[V](initialValue: V) extends Property[V] {
  private var v = initialValue

  override def value(): V = v
  def setValue(newValue: V): Unit = {
    v = newValue
  }

  override def toString: String = {
    s"property(value=$v)"
  }
}

val timeout = new ManuallySetProperty(Duration.ZERO)
println(timeout.value())
timeout.setValue(Duration.ofMinutes(3))
println(timeout.value())
{% endhighlight %}
	  ]]></description>
	</item>

	<item>
	  <title>Preparing images for Ben Eater's VGA card using Gimp</title>
	  <link>//preparing-images-for-ben-eater-vga-using-gimp</link>
	  <author>mc</author>
	  <pubDate>2020-09-10T02:00:01+02:00</pubDate>
	  <guid>//preparing-images-for-ben-eater-vga-using-gimp</guid>
	  <description><![CDATA[
	     Recently I have completed my own version of [Ben Eater video card](https://eater.net/vga).
I still need to spend some time on it, since I could not achieve as good
and sharp looking images as Ben did. For example the finch picture generated by my card
does not look as crisp and clear as in Ben videos:
![Finch](assets/images/2020-09-10/finch.jpg)

Anyway, here I want to show how you can create your own images and `.bin` files using Gimp and
a small Java program.
But first we need to find some nice images. After a bit of searching
I have found a Twitter account called @PixelStudioTeam full of retro looking images
that I decided to use. Thank you PixelStudioTeam!

OK let's start by importing a palette file into Gimp.
Choose in the main menu: Windows -> Dockable Dialogs -> Palettes.
Then right click on the list of the palettes and choose Import...
![Import palette](assets/images/2020-09-10/palette1.png)
In the dialog that will appear, select Palette file as a source and
choose `64-color.act` file that Ben [publishes on his home page](https://eater.net/downloads/64-color.act).
![Import palette](assets/images/2020-09-10/palette2.png)
Click Import, after that a new palette with name `64-colors.act` should appear on the list of the palettes.

Now we can prepare the images. First we must resize the images to 100px by 75px size required by Ben Eater video card.
To do this we can use Image -> Scale image... and Image -> Set canvas size... menu options.

IMPORTANT: Before we proceed we must also remove transparency layer that some PNG files have.
To do this please select Layer -> Transparency -> Remove alpha channel... If this option is grayed out then
the image does not have alpha channel and we do not need to remove anything.

Now let's convert our image to indexed mode, choose: Image -> Mode -> Indexed...
![Indexed mode](assets/images/2020-09-10/indexed.png)
Choose Ben's palette. Enabling [dithering](https://en.wikipedia.org/wiki/Dither) can result in a better looking images.
After this step a colorful image should change appearance, if it looks the same try to switch modes again, first to RGB and then
to Indexed.

The last step is to export our image to PNG format 
(File -> Export As... -> Give a file name ending with `.png` and click Export):
![Export](assets/images/2020-09-10/export.png)
You should deselect all options. You can restore them later
by selecting Load Defaults button.

I prepared two small Java programs that you use to convert resulting `.png` images into `.bin` images.
You need to have Java JDK installed to compile and run them:
{% highlight no-highlight %}
javac Converter.java
java Converter pic.png pic.bin
{% endhighlight %}
I also prepared a program that generates a set of patterns like chessboard for debugging purposes:
{% highlight no-highlight %}
$ javac Stripes.java 
$ java Stripes 
use program output_file.bin [pallete|chess|rows|cols]
$ java Stripes chess.bin chess
{% endhighlight %}

You can find the four example images, the four example debugging patterns and the source code of Java programs [here](assets/images/2020-09-10/ben_eater_vga_imgs.zip).

Let's finish with the results that I achieved:
<table>
  <tbody>
    <tr>
      <td>
        <img src="assets/images/2020-09-10/pic1.png" />
      </td>
      <td>
        <img src="assets/images/2020-09-10/pic2.png" />
      </td>
    </tr>
    <tr>
      <td>
        <img src="assets/images/2020-09-10/pic3.png" />
      </td>
      <td>
        <img src="assets/images/2020-09-10/pic4.png" />
      </td>
    </tr>
   </tbody>
</table>
Of course the converted images look perfect, my card on the other hand introduces quite a lot of distortions...

UPDATE: I managed to find the source of distortions in my card. 
I mixed address lines 3 and 4 from VSync to EEPROM module.
After swapping two wires I got a clear and crisp image:
<table>
  <tbody>
    <tr>
      <td>
        <img src="assets/images/2020-09-10/working.png" />
      </td>
      <td>
        <img src="assets/images/2020-09-10/card.png" />
      </td>
    </tr>
   </tbody>
</table>

	  ]]></description>
	</item>

	<item>
	  <title>Cierpienia młodego Wertera czyli algorytm alfa-beta dla gry kółko i krzyżyk</title>
	  <link>//cierpienia-mlodego-wertera</link>
	  <author>mc</author>
	  <pubDate>2020-08-06T02:00:01+02:00</pubDate>
	  <guid>//cierpienia-mlodego-wertera</guid>
	  <description><![CDATA[
	     W tym wpisie przyjrzymy się trudnościom które występują podczas
implementacji algorytmu alfa-beta dla gry kółko i krzyżyk.
Nie będę tutaj omawiał samego algorytmu, gdyż został on już dobrze
opisany w wielu innych miejscach, między innymi na
[Ważniaku](http://wazniak.mimuw.edu.pl/index.php?title=Sztuczna_inteligencja/SI_Modu%C5%82_8_-_Gry_dwuosobowe).
Zamiast tego skoncentrujemy się na technikach debugowania które można
będzie wykorzystać również przy innych grach np. warcabach.

Kod algorytmów alfa-beta i minimax jest powszechnie dostępny
w internecie czy to w postaci 
[pseudokodu](https://en.wikipedia.org/wiki/Alpha–beta_pruning#Pseudocode)
czy jako gotowa implementacja na [GitHubie](https://github.com/search?l=Java&q=alpha+beta+tictactoe&type=Repositories).

W trakcie przygotowań do stworzenia tego artykułu, ja również napisałem 
prostą implementację gry w kółko i krzyżyk. 
Kod mojej wersji algorytmu alfa-beta, podobnie jak cała gra, dostępny jest na 
[GitHubie](https://github.com/marcin-chwedczuk/xox/blob/master/src/main/java/pl/marcinchwedczuk/xox/game/AlphaBetaAlgo.java).

W dalszej części artykułu założymy że posiadana przez nas 
implementacja algorytmu alfa-beta jest poprawna, 
a mimo to program nie wykonuje prawidłowych ruchów podczas gry.

### Heurystyka czyli Serce algorytmu

Najważniejszą częścią algorytmu alfa-beta jest heurystyka czyli
funkcja oceniająca stan gry z punktu widzenia danego gracza.
Ogólna sygnatura heurystyki wygląda następująco:
{% highlight java %}
double score(GameState gameState, Player player)
{% endhighlight %}
Większe wartości zwracane przez funkcję odpowiadają lepszej
sytuacji gracza na planszy i na odwrót im mniejsza wartość
zwrócona tym położenie gracza jest gorsze.

Czasami przekazujemy do heurystyki również
inne pomocnicze informacje,
na przykład ostatni wykonany przez gracza ruch, jeżeli może to
przyspieszyć wykonywanie obliczeń.
Sama funkcja może również zwracać więcej danych niż tylko samą ocenę sytuacji na polu gry.
Przykładowo heurystyka może zwracać informację o zakończeniu gry i jej ewentualnym zwycięscy.
Wiele zależy tutaj od konkretnej gry, w przypadku gry w kółko i krzyżyk
obie te optymalizacje są możliwe.

W przypadku planszy 3x3 prosta heurystyka która zwraca `1` gdy gracz
wygrał i `0` w przeciwnym wypadku, w połączeniu z algorytmem alfa-beta
tworzy program z którym nie sposób wygrać.

Na koniec uwaga techniczna. Nakreślona powyżej funkcja heurystyki
traktuje w taki sam sposób zarówno gracza MAX
jak i gracza MIN. Dla poprawności działania algorytmu alfa-beta
konieczne jest zanegowanie wyniku zwróconego przez heurystykę dla
gracza MIN:
{% highlight java %}
var score = score(gameState, currentPlayer);
score = maximizingPlayer ? score : -score;
{% endhighlight %}

### Plansza 4x4, 3 pod rząd wygrywają

Uruchomienie powyższego algorytmu na planszy 4x4, gdy pierwszy ruch
należy do użytkownika przynosi jednak opłakane rezultaty.
Program zajmuje po prostu kolejne pola na planszy, a my nie mamy
najmniejszego problemu z wygraną.

![Dziwne zachowanie algorytmu](assets/images/2020-08-05/game1.png)
X - Użytkownik, O - Komputer

Dlaczego tak się dzieje? Okazuje się że przy grze 4x4, 3 pod rząd
istnieje strategia wygrywająca która pozwala pierwszemu graczowi
wygrać w dokładnie 3 ruchach:
![Strategia wygrywająca](assets/images/2020-08-05/str1.svg)

Z punktu widzenia algorytmu minimax każdy ruch skutkuje przegraną,
dlatego algorytm wybierze pierwszy lub ostatni ruch 
(w zależności od implementacji).
Pozwolę sobie nazwać to zjawisko depresją,
chociaż nie jest to powszechnie przyjęta terminologia.

Istnieje bardzo prosty sposób na wykrycie zjawiska depresji -
wystarczy zamienić kolejność graczy tj. pozwolić komputerowi wykonać
pierwszy ruch. Jeżeli spowoduje to nagłą poprawę sposobu działania algorytmu
należy sprawdzić czy przypadkiem gra nie faworyzuje gracza wykonującego
ruch jako pierwszy.

Istnieje jeszcze jedno proste ulepszenie które możemy wykonać.
Mianowicie jeżeli pozwolimy algorytmowi grać samemu ze sobą to
okaże się że "nie spieszy mu się do wygranej":
![Ilustracja problemu](assets/images/2020-08-05/str2.svg)
Ludzie zachowują się inaczej, chcemy wygrać jak najszybciej,
w jak najmniejszej ilości ruchów.
Możemy dodać to zachowanie do naszego algorytmu, modyfikując
funkcję heurystyki tak żeby "karała" gracza za każdy wykonany ruch.
Alternatywnie heurystyka może nagradzać gracza za każde 
pozostawione wolne pole na planszy:
{% highlight java %}
double impatientPlayerHeuristics(GameState gameState, Player player) {
    var score = score(gameState, currentPlayer);
    var freePlaces = gameState.board.countFreePlaces();
    return score + freePlaces*Q;
}
{% endhighlight %}
Stałą `Q` musimy dobrać w taki sposób żeby wartość 
wyrażenia `freePlaces*Q` nigdy
nie przekraczała wartości zwracanej w przypadku wygranej przez 
funkcję `score`.
Na przykład jeżeli dla wygranej heurystyka zwraca `1000.0` to użycie
`Q = 1.0` jest rozsądnym wyborem.

Na koniec zauważmy że plansza 5x5, 3 pod rząd zawiera w sobie
planszę 4x4, 3 pod rząd, dlatego wszystko co powiedzieliśmy tutaj
o zjawisku depresji odnosi się również do niej.

### Plansza 4x4, 4 pod rząd wygrywają

W przypadku plansz 4x4 i większych kluczowym problemem staje się wydajność.
Prostym sposobem na poradzenie sobie z tym problemem jest rezygnacja z
analizy całego drzewa gry i skupienie się na pierwszych N ruchach 
wykonywanych przez graczy.
W tym wypadku dobór odpowiedniej heurystyki staje się jeszcze ważniejszy
ponieważ
oceniać musimy nie tylko gry zakończone, ale również takie
które wciąż trwają.
Z drugiej strony nadmierne skomplikowanie heurystyki negatywnie wpływa 
na złożoność obliczeniową i co za tym idzie, na czas oczekiwania na wybór ruchu.

Jako kompromis możemy przyjąć na przykład analizę jedynie siedmiu
posunięć graczy w przyszłość, przy jednoczesnym rozbudowaniu heurystyki
o punktowanie "prawie zwycięstw". Prawie zwycięstwo to sytuacja na
planszy która w wyniku jednego ruchu czy posunięcia gracza zmienia się
w wygraną. W przypadku planszy 4x4, 4 pod rząd możemy przyjąć
że rząd, kolumna lub przekątna złożona z trzech znaków gracza i wolnego
miejsca jest prawie zwycięstwem np. `X _ X X` jest prawie zwycięstwem
dla gracza X.

W przypadku optymalizacji bardziej skomplikowanych gier nie obejdziemy się
bez dodatkowych narzędzi takich jak np. profiler.
Jednym z najlepszych, darmowych profilerów dostępnych na rynku dla platformy JVM
jest [async-profiler](https://github.com/jvm-profiling-tools/async-profiler).

Możemy również dużo zyskać unikając nadmiernych alokacji pamięci.
Na przykład zamiast tworzyć nową niemutowalną planszę za każdym razem gdy 
symulujemy ruch gracza, możemy wykorzystać mutowalną strukturę danych
wraz z wycofywaniem ruchów (ang. backtracking):
{% highlight java %}
for (Move playerMove: movesToCheck) {
    // Modify board in place
    board.put(playerMove.position, playerMove.mark);

    // Do recursive minimax call and other stuff

    // Restore board state
    board.removeMark(playerMove.position)
}
{% endhighlight %}

### Plansza 5x5, 4 lub 5 pod rząd wygrywają

Na tym poziomie wydajność staje się elementem kluczowym.
Duża wielkość drzewa gry sprawia że strategie
bazujące na prawdopodobieństwie zaczynają wyglądać 
coraz bardziej interesująco.
Na przykład możemy użyć następującego algorytmu bazującego
na [metodzie Monte Carlo](https://pl.wikipedia.org/wiki/Metoda_Monte_Carlo),
do wygenerowania listy ruchów które będziemy oceniać:
{% highlight java %}
Set<Moves> getMovesToCheck(Board board, int depth) {
    // Cutoff - use heuristics to evaluate the board
    if (depth > 8) {
        return Set.of();
    }

    // For the first three player moves we analyze every possibility
    var allPossibleMoves = board.getMovesForAllFreeFields()
    if (depth < 3) {
        return allPossibleMoves;
    }

    // Take K random moves to analyze
    return allPossibleMove.shuffle().take(K);

}
{% endhighlight %}

W przypadku gdy algorytm zwróci pustą listę ruchów do sprawdzenia,
po prostu oceniamy planszę za pomocą heurystyki i zwracamy to jako
wynik (pamiętając o negacji dla gracza MIN) z wywołania funkcji minimax.

### Jak to zdebugować? Generalne strategie debugowania

* Testy jednostkowe dla wykorzystywanych przez nas heurystyk to podstawa.
 Pisząc heurystyki dla gry kółko i krzyżyk bardzo łatwo o pomyłkę
 lub błąd w stylu "off by one". Dodanie testów i upewnienie się
 że pokrycie kodu testami jest odpowiednio wysokie powinno być
 pierwszym działaniem jakie podejmujemy podczas debugowania.
* Nasza aplikacja powinna posiadać funkcję umożliwiającą cofnięcie
 ostatnich ruchów gracza. Znacznie ułatwi to debugowanie za pomocą
 debuggera. W przypadku bardziej skomplikowanych gier typu warcaby
 warto dodać opcję zapisu i odczytu stanu gry z pliku.
* Warto dodać opcję gry komputer vs komputer, jak również wyboru
 kto stawia pierwszy ruch. Pozwala to lepiej ocenić działanie algorytmu.
* Zwracając optymalny ruch algorytm minimax zwraca tak naprawdę
 ścieżkę od korzenia do liścia w drzewie gry (korzeń reprezentuje
 obecną sytuację na planszy, liść przyszłą wygraną lub remis).
 Warto zalogować taką informację wypisując ją na konsole, bądź 
 zapisując do pliku. Pamiętajmy żeby zalogować tylko i wyłącznie
 ścieżkę dla wybranego ruchu. W przeciwnym wypadku możemy utonąć w
 powodzi informacji.

Na koniec zdradzę wam sekret debugowania, który pomoże wam rozwiązać
nie jeden problem: "Co dwie głowy to nie jedna!".
Jeżeli masz problem którego nie potrafisz sam rozwiązać poproś
drugą osobę o pomoc. I niech to nie będzie prośba na forum 
czy StackOverflow ale debugowanie ramie w ramie z drugim człowiekiem.
To naprawdę działa i mówię to mając na karku kilka lat solidnej
praktyki jako programista.

### Przykładowa aplikacja

Kod przykładowej aplikacji można znaleźć na 
[GitHubie](https://github.com/marcin-chwedczuk/xox/).

Aplikację najlepiej otworzyć w IntelliJ, importując ją 
jako projekt Gradle. Do edycji GUI niezbędny jest
[SceneBuilder](https://gluonhq.com/products/scene-builder/).

Jeżeli odkryjecie w aplikacji błąd proszę piszcie na 0xmarcin małpa gmail.com.

Sam kod aplikacji jest czytelny ale nie perfekcyjny. Jest jeszcze wiele
rzeczy które chciałbym poprawić. Jeżeli widzicie miejsce które
można poprawić nie bójcie się stworzyć pull request'a na GitHubie.
Gwiazdki są również mile widziane ;)

	  ]]></description>
	</item>

	<item>
	  <title>Nesting monads in Scala</title>
	  <link>//scala-nesting-monads</link>
	  <author>mc</author>
	  <pubDate>2020-08-01T02:00:01+02:00</pubDate>
	  <guid>//scala-nesting-monads</guid>
	  <description><![CDATA[
	     Recently I write a lot of async code. Most of my repository
methods return types like `Future[Set[T]]` or `Future[Option[T]]`.
But as we will see, working with such types in pure Scala
can be very cumbersome.

For example in pure Scala we cannot write:
{% highlight scala %}
val namesFuture = Future.successful(List("bob", "alice"));

val capitalizedNames = for {
  names <- namesFuture
  name <- names
} yield name.capitalize
{% endhighlight %}
Nop. Nada. Will not work. When we try to compile this code,
the compiler will point out that `names` have type of `List[String]`
instead of expected `Future[X]`.

To understand the problem better lets remind ourselves
how Scala compiler translates for-comprehensions into
method calls:
{% highlight scala %}
val ks = for {
  i <- 1 to 10
  j <- 1 to i
  k <- 1 to j
  sum = i + j + k
  if (sum > 10 && sum < 20)
} yield 3*sum
// Is translated (with some simplifications) into:
val ks2 = (1 to 10).flatMap { i =>
  (1 to i).flatMap { j =>
    (1 to j)
      .map { k => i + j + k }
      .withFilter { sum => sum > 10 && sum < 20 }
      .map { sum => 3*sum }
  }
}
{% endhighlight %}
In short every but the last "assignment" of the form `var <- something` is
translated into `something.flatMap { var => ...`.
The last "assignment" is translated into a simple `map` call.
`if` filters are translated into `withFilter` or `filter` calls.

Returning to our first example we see that it is translated
into:
{% highlight scala %}
val capitalizedNames = for {
  names <- namesFuture
  name <- names
} yield name.capitalize
// into this:
val capitalizedNames = namesFuture.flatMap { names =>
  names.map(_.capitalize)
}
{% endhighlight %}
And indeed it does not type check as `namesFuture.flatMap` expects
that the passed lambda will return a `Future[X]` not
a `List[X]`.

We can quickly fix this problem by introducing a nested `for`
or by replacing `flatMap` by `map`:
{% highlight scala %}
val capitalizedNames = for { names <- namesFuture } yield
                       for { name <- names } yield name.capitalize;
// or:
val capitalizedNames = namesFuture.map { names =>
  names.map(_.capitalize)
}
// of if you are processing only a single collection:
val capitalizedNames = for { names <- namesFuture }
                       yield names.map(_.capitalize)
{% endhighlight %}
And even in this simple example, the method chain 
becomes quite unreadable when you try to
squash it into a single line: `namesFuture.map(_.map(_.capitalize))`.

Exactly the same problems appears when we try to work with `Future[Option[T]]`.
But here we can at least use libraries to reduce the pain.
For example using `OptionT` type from [Cats](https://typelevel.org/cats/),
we can write:
{% highlight scala %}
import cats.data.OptionT
import cats.implicits._

val nameFuture = Future.successful(Option("foo"))

val f = OptionT(nameFuture)
  .map(name => name + "!")
  .map(name => println(s"name is $name"))
Await.result(f.value, Duration.Inf)
{% endhighlight %}
...and call it a day. 

In pure Scala this code would look like this:
{% highlight scala %}
val f = nameFuture
  .map(_.map(name => name + "!"))
  .map(_.foreach(n => println(s"name is $n")))
Await.result(f, Duration.Inf)
{% endhighlight %}

In short I don't understand why language designers decided to not support
nested monads in for-comprehensions. It's a pity that we have to use
external libraries to get such a basic functionality.
	  ]]></description>
	</item>

	<item>
	  <title>Useful JDK tools (part 1)</title>
	  <link>//useful-jdk-tools-part-1</link>
	  <author>mc</author>
	  <pubDate>2020-07-10T02:00:01+02:00</pubDate>
	  <guid>//useful-jdk-tools-part-1</guid>
	  <description><![CDATA[
	     JDK comes with a bunch of handy tools. It's good to
know about them. In this post we will take a look at
`jps`, `jstack`, `jmap` and `jhat`.

### jps

`jps` is a JVM counterpart to unix `ps` command.
By default `jps` prints process PID and 
the name of the main class
or the name of a jar file if the 
application was started using `java -jar` option.
{% highlight nohighlight %}
$ jps
54177 Jps
54173 App
54452 app.jar
{% endhighlight %}

But it can be more talkative. 
`-l` option adds a package name to the
main class name and a full/relative path to the jar filename.
`-m` option will print command line arguments passed to the program.
{% highlight nohighlight %}
$ jps -lm
54355 pl.marcinchwedczuk.app.App arg1 arg2 arg3
54452 build/libs/app.jar arg1 arg2 arg3
54458 jdk.jcmd/sun.tools.jps.Jps -lm
{% endhighlight %}

To print JVM switches we use `-v` option:
{% highlight nohighlight %}
$ jps -v
54654 app.jar -Xmx32m -Xms32m
54657 Jps -Dapplication.home=... -Xms8m ...
{% endhighlight %}

### jstack

`jstack PID` can be used to print current stack traces of
all threads running in java process.
You can also print stack traces from a core dump file.
The output of `jstack` command is often referred to
as a _thread dump_.

Thread dumps are invaluable resources when it comes to debugging
nasty deadlocks that show up only on the production servers.
On the other hand the number of threads in a serious java application
can be overwhelming. To make the most of thread dumps, you
need to give threads meaningful names. You should give names 
(via `Thread::setName`) at least to the threads that you create 
yourself and 
you should also supply a "thread naming" `ThreadFactory` when creating
new thread pools (e.g. `newFixedThreadPool(int nThreads, ThreadFactory threadFactory)`).

Let's create a simple app that deadlocks and see what `jstack`
will print:
{% highlight java %}
public static void main(String[] args) throws InterruptedException {
	Lock l1 = new ReentrantLock();
	Lock l2 = new ReentrantLock();

	var t1 = new Thread(() -> {
		Thread.currentThread().setName("AppThread#1");
		l1.lock();
		try {
			Thread.sleep(1000);
		} catch (InterruptedException e) {
			Thread.currentThread().interrupt();
		}
		l2.lock();
	});

	var t2 = new Thread(() -> {
		Thread.currentThread().setName("AppThread#2");
		l2.lock();
		try {
			Thread.sleep(1000);
		} catch (InterruptedException e) {
			Thread.currentThread().interrupt();
		}
		l1.lock();
	});

	t1.start(); t2.start();
	t1.join(); t2.join();
}
{% endhighlight %}
EDIT: I was tired when I wrote this code. It will deadlock
both threads
say 99% of time but not always. Instead of `sleep` I should use
`CountDownLatch`. I leave the code as it is as I don't want to regenerate
thread dumps but I wanted to point out this problem.

For readability I had to shorten `jstack` output.
{% highlight nohighlight %}
$ jstack `jps | grep App | cut -d ' ' -f 1`

"main" #1 prio=5 os_prio=31 cpu=46.25ms elapsed=85.17s tid=0x00007fb623810800 nid=0x1803 in Object.wait()  [0x000070000027a000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(java.base@14.0.1/Native Method)
	...
	at java.lang.Thread.join(java.base@14.0.1/Thread.java:1371)
	at pl.marcinchwedczuk.bzzz.App.main(App.java:37)

"AppThread#1" #13 prio=5 os_prio=31 cpu=1.30ms elapsed=85.12s tid=0x00007fb622031000 nid=0x9b03 waiting on condition  [0x00007000014b3000]
   java.lang.Thread.State: WAITING (parking)
	at jdk.internal.misc.Unsafe.park(java.base@14.0.1/Native Method)
	...
	at java.util.concurrent.locks.ReentrantLock.lock(java.base@14.0.1/ReentrantLock.java:322)
	at pl.marcinchwedczuk.bzzz.App.lambda$main$0(App.java:22)
	at pl.marcinchwedczuk.bzzz.App$$Lambda$1/0x0000000800b65840.run(Unknown Source)
	at java.lang.Thread.run(java.base@14.0.1/Thread.java:832)
...
Found one Java-level deadlock:
=============================
"AppThread#1":
  waiting for ownable synchronizer 0x00000007ffd92998, (a java.util.concurrent.locks.ReentrantLock$NonfairSync),
  which is held by "AppThread#2"

"AppThread#2":
  waiting for ownable synchronizer 0x00000007ffd92968, (a java.util.concurrent.locks.ReentrantLock$NonfairSync),
  which is held by "AppThread#1"
...
{% endhighlight %}
Notice that JVM was able to detect the deadlock, saving us a hours
of debugging. If you have a heisenbug you may consider running
`jstack` periodically and searching its output for `Found * deadlock` lines.

Now let's see how we can extract thread dumps for a core dump.
And for that we need a core dump.

Here I will describe how to make a core dump on macOS 10.15
(this is based on [this article](https://developer.apple.com/library/archive/technotes/tn2124/_index.html#//apple_ref/doc/uid/DTS10003391-CH1-SECCOREDUMPS))
First we need to execute `ulimit -c unlimited` in the shell
to remove the file size limit on created core-dump files.
A simple crashing hello world C program can create about 2GB core dump,
Java cores can have sizes of 10GB or more.
Then we need to set appropriate
permissions for `/cores` directory:
{% highlight nohighlight %}
$ sudo chmod 1777 /cores
# Test if we have enough permissions
$ echo 1 > /cores/test
{% endhighlight %}
TIP: `1` in `1777` is for [sticky bit](https://en.wikipedia.org/wiki/Sticky_bit).
If a directory has this bit set then 
only the owner of a file contained in that directory
can remove or rename that file.
If we additionally create a file with `700` permissions 
then nobody beyond us will be able to change or
remove the file.

Then _in the same_ shell in which we executed `ulimit -c unlimited`
we have to run a java application and in a new
terminal window we need to send `SIGSEGV` to that app:
{% highlight nohighlight %}
$ kill -SIGSEGV PID
{% endhighlight %}
After being hit by `SIGSEGV` Java should crash with a message:
{% highlight nohighlight %}
$ java -jar build/libs/bzzz.jar
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00007fff6f4cfdfa, pid=55303, tid=775
...
# Core dump will be written. Default location: /cores/core.56128
...
{% endhighlight %}
It may take a while to write 10GB+ file on disk so be patient.

Now for some reason I was not able to take a core dump from
official Oracle distribution of JDK. When I used OpenJDK
build everything worked perfectly. Now when I switched to OpenJDK
I have to use OpenJDKs `jstack` to analyze the core dump.
{% highlight nohighlight %}
$ export PATH=/usr/local/Cellar/openjdk/14.0.1/bin:$PATH
$ jhsdb jstack --core /cores/core.56128 \
	 --exe /usr/local/Cellar/openjdk/14.0.1/bin/java

"main" #1 prio=5 tid=0x00007fb4c300c000 nid=0x1d03 in Object.wait() [0x00007000027db000]
   java.lang.Thread.State: WAITING (on object monitor)
   JavaThread state: _thread_blocked
 - java.lang.Object.wait(long) @bci=0 (Interpreted frame)
	- waiting on <0x000000061fe55d88> (a java.lang.Thread)
 - java.lang.Thread.join(long) @bci=72, line=1303 (Interpreted frame)
	- locked <0x000000061fe55d88> (a java.lang.Thread)
 - java.lang.Thread.join() @bci=2, line=1371 (Interpreted frame)
 - pl.marcinchwedczuk.bzzz.App.main(java.lang.String[]) @bci=57, line=37 (Interpreted frame)
...
{% endhighlight %}
For some reason in OpenJDK 14 the command `jstack /path/to/java coredump`
did not work. Instead I have to use a new tool introduced in JDK9
called `jhsdb`. Anyway the result is the same, we managed to
get thread dumps from the core dump. Again the tool was smart enough
to point out the deadlock (not visible on attached listing).

OK lets cleanup our system and revert the settings:
`ulimit -c 0`, `rm /cores/*` and `sudo chmod 1775 /cores`.

### jmap

`jmap` can be used to display various info about
Java process heap. For example we may take a heap 
histogram, which tells us number of instances and
total memory size taken per class.
{% highlight nohighlight %}
$ jmap -histo $PID | head
No dump file specified
 num     #instances         #bytes  class name (module)
-------------------------------------------------------
   1:           965        2775128  [I (java.base@14.0.1)
   2:          7555         399568  [B (java.base@14.0.1)
   3:          7324         175776  java.lang.String (java.base@14.0.1)
   4:          1295         160512  java.lang.Class (java.base@14.0.1)
   5:           964          88712  [Ljava.lang.Object; (java.base@14.0.1)
   6:          1872          59904  java.util.HashMap$Node (java.base@14.0.1)
{% endhighlight %}

But the real power of `jmap` lies in its ability
to take heap dumps:
{% highlight nohighlight %}
$ jmap -dump:live,format=b,file=heapdump $PID
Dumping heap to /path/to/heapdump ...
Heap dump file created [4264220 bytes in 0.018 secs]
{% endhighlight %}
Heapdumps can then be comfortably opened and analyzed in tools like
[Eclipse Memory Analyzer](https://www.eclipse.org/mat/).

![Eclipse Memory Analyzer](assets/images/2020-07-10/ema.png)

Heapdumps can be quite huge, if you want to move them between
servers remember to first compress them to speed things up.
They also contain sensitive data like AWS access
keys and user passwords, so please keep them secure.

TIP: You can also generate heapdumps on
out of memory errors using `-XX:+HeapDumpOnOutOfMemoryError` JVM switch.

EDIT: Since JDK9 the recommended way of generating heapdumps
changed. You may want to see [this article on InfoQ](https://www.infoq.com/news/2015/12/OpenJDK-9-removal-of-HPROF-jhat/).

### jhat

Now what if you don't want/have permissions to install fancy heapdump analyzers?
Not all is lost, we may still use primitive but working `jhat`.
Run `jhat heapdump` to start `jhat` HTTP server with basic
heapdump browser.

EDIT: Unfortunately `jhat` was removed in JDK9.
	  ]]></description>
	</item>

	<item>
	  <title>iTerm2 cheat sheet</title>
	  <link>//iterm2-cheat-sheet</link>
	  <author>mc</author>
	  <pubDate>2020-07-08T02:00:01+02:00</pubDate>
	  <guid>//iterm2-cheat-sheet</guid>
	  <description><![CDATA[
	     iTerm2 is one of the best terminal emulators out there.
But to appreciate its full power you should know how to
use it effectively.
Here are shortcuts that I find indispensible while working with iTerm2.

#### Working with panes

* `Command + D` - Split vertically
* `Command + Shift + D` - Split horizontally
* `Command + W` - Close pane

* `Command + Option + Arrows` - Navigate between panes
* `Control + Command + Arrow` - Resize current pane
* `Command + Shift + Enter` - Maximize current pane / Restore its original size

* `Command + K` - Clear current pane

#### Text editing

* `Control + A` - Move to the line beginning
* `Control + E` - Move to the line end

Consider enabling "Natural Text Editing" (instructions [here](https://apple.stackexchange.com/a/293988))
if you want to use `Option + Left/Right Arrow` for
one word forward/backward navigation instead of
awkward `Control+] F` / `Esc F` (Escape followed by F for forward or
B for backward).

* `Option + Delete` - Delete one world
* `Command + Delete` - Delete entire line

#### Scrolling

* `Fn + Shift + Up Arrow` - Page Up
* `Fn + Shift + Down Arrow` - Page Down

#### Tabs

* `Command + T` - Create new tab
* `Command + <num>` - Move to `num`th tab e.g. `Command + 3`
* `Command + Left/Right arrow` - Move to left/right tab
* `Command + Option + W` - Close tab

Add the following function to your `~/.profile`:
{% highlight bash %}
title() {
	echo -ne "\e]1;$@\a"
}
{% endhighlight %}
Then you can use `title foo` to set iTerm2 tab title.

#### iTerm2 Window

* `Command + Enter` - Enter / Leave full screen mode
* `Command + ,` - Show preferences

#### History search

* `Control + R` - Start history search (fuzzy search)
* `Control + R` - Move to the next suggestion

#### Other

* `Command + ;` - Open graphical autocomplete menu in iTerm2
* Use `open URL` command to open given file in MacOS e.g. `open 'https://google.com'` or `open .` to open current directory in Finder
	  ]]></description>
	</item>


</channel>
</rss>
