<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>marcin-chwedczuk.github.io/</title>
   
   <link>https://marcin-chwedczuk.github.io/</link>
   <description>A place where I can share my thoughts about programming</description>
   <language>en-uk</language>
   <managingEditor> marcin-chwedczuk</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>NSubstitute and the search for perfect error messages</title>
	  <link>//nsubstitute-and-the-search-for-perfect-error-messages</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2018-12-15T01:00:00+01:00</pubDate>
	  <guid>//nsubstitute-and-the-search-for-perfect-error-messages</guid>
	  <description><![CDATA[
	     <p>Those of us that practice TDD daily already know how important good
error messages in tests are. After all writing a failing test that
<em>clearly</em> states what functionality the program 
is missing is the first step in TDD cycle.
The rest of us that either can’t or simply don’t want to practice TDD
must put extra effort to ensure that tests always fail
with meaningful error messages.
Unfortunately, according to what I have learned from my personal experience, 
the most devs either don’t have
enough time or simply don’t bother to check if their tests fail with
something meaningful. For average Joe developer writing tests and
making them green is already a lot of work. 
Things like good test names and proper error messages are often forgotten.</p>

<p>But the developers are not the only one here to blame. 
Too often tools and libraries that supposedly should make unit testing
simpler and easier, generate horrible and often cryptic error messages.</p>

<p>In this post we will take a close look at 
<a href="http://nsubstitute.github.io/">NSubstitute</a>,
a modern and popular mocking libary for .NET and see 
how we can improve messages generated by its argument matchers.</p>

<p>Let’s start by looking at a simple test. 
It demonstrates how NSubstitute is often used to assert that 
a method was called with an argument in a certain state:</p>

<figure class="highlight"><pre><code class="language-csharp" data-lang="csharp"><span class="k">public</span> <span class="k">class</span> <span class="nc">PlainArgument</span> <span class="p">{</span>
    <span class="k">public</span> <span class="kt">int</span> <span class="n">Id</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="p">}</span>
    <span class="k">public</span> <span class="kt">string</span> <span class="n">FirstName</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="p">}</span>
    <span class="k">public</span> <span class="kt">string</span> <span class="n">LastName</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="p">}</span>
    <span class="k">public</span> <span class="kt">string</span> <span class="n">EmailAddress</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="p">}</span>

    <span class="k">public</span> <span class="nf">PlainArgument</span><span class="p">(</span><span class="kt">int</span> <span class="n">id</span><span class="p">,</span> <span class="kt">string</span> <span class="n">firstName</span><span class="p">,</span> <span class="kt">string</span> <span class="n">lastName</span><span class="p">,</span> <span class="kt">string</span> <span class="n">emailAddress</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">Id</span> <span class="p">=</span> <span class="n">id</span><span class="p">;</span>
        <span class="n">FirstName</span> <span class="p">=</span> <span class="n">firstName</span><span class="p">;</span>
        <span class="n">LastName</span> <span class="p">=</span> <span class="n">lastName</span><span class="p">;</span>
        <span class="n">EmailAddress</span> <span class="p">=</span> <span class="n">emailAddress</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">public</span> <span class="k">interface</span> <span class="n">IFooService</span> <span class="p">{</span>
    <span class="k">void</span> <span class="nf">DoStuff</span><span class="p">(</span><span class="kt">object</span> <span class="n">argument</span><span class="p">);</span>
<span class="p">}</span>

<span class="na">[Fact]</span>
<span class="k">public</span> <span class="k">void</span> <span class="nf">Checking_argument_using_Arg_Is</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// Act
</span>    <span class="n">_component</span><span class="p">.</span><span class="nf">DoStuff</span><span class="p">();</span>

    <span class="c1">// Assert
</span>    <span class="n">_fooService</span><span class="p">.</span><span class="nf">Received</span><span class="p">()</span>
        <span class="p">.</span><span class="nf">DoStuff</span><span class="p">(</span><span class="n">Arg</span><span class="p">.</span><span class="n">Is</span><span class="p">&lt;</span><span class="n">PlainArgument</span><span class="p">&gt;(</span>
            <span class="n">e</span> <span class="p">=&gt;</span> <span class="n">e</span><span class="p">.</span><span class="n">Id</span> <span class="p">==</span> <span class="m">9</span> <span class="p">&amp;&amp;</span>
                 <span class="n">e</span><span class="p">.</span><span class="n">FirstName</span> <span class="p">==</span> <span class="s">"jan"</span> <span class="p">&amp;&amp;</span>
                 <span class="n">e</span><span class="p">.</span><span class="n">LastName</span> <span class="p">==</span> <span class="s">"kowalski"</span> <span class="p">&amp;&amp;</span>
                 <span class="n">e</span><span class="p">.</span><span class="n">EmailAddress</span> <span class="p">==</span> <span class="s">"jan.kowalski@gmail.com"</span>
                 <span class="p">));</span>
<span class="p">}</span></code></pre></figure>

<p>When the argument passed to the checked method
was in an unexpected state (e.g. first name was not “jan” but “john”),
we get an error message similar to (formatting added):</p>

<figure class="highlight"><pre><code class="language-nohighlight" data-lang="nohighlight">Expected to receive a call matching:
    DoStuff(e =&gt; ((((e.Id == 9) AndAlso 
        (e.FirstName == "jan")) AndAlso 
        (e.LastName == "kowalski")) AndAlso 
        (e.EmailAddress == "jan.kowalski@gmail.com")))
Actually received no matching calls.
Received 1 non-matching call (non-matching arguments indicated 
with '*' characters):
    DoStuff(*PlainArgument*)</code></pre></figure>

<p>This error message is terrible.
It contains a lot of informations that are easily obtainable by looking at the
test method’s source code. Yet it does not contain
the most important piece of information that we need: which properties 
have unexpected values and what these values are.</p>

<p>We can slightly improve this error message by overloading <code class="highlighter-rouge">ToString</code> method
on <code class="highlighter-rouge">PlainArgument</code> class. 
Let’s call this new class <code class="highlighter-rouge">StringableArgument</code>:</p>

<figure class="highlight"><pre><code class="language-csharp" data-lang="csharp"><span class="k">public</span> <span class="k">class</span> <span class="nc">StringableArgument</span> <span class="p">{</span>
    <span class="c1">// the same code as in PlainArgument
</span>    <span class="k">public</span> <span class="k">override</span> <span class="kt">string</span> <span class="nf">ToString</span><span class="p">()</span>
        <span class="p">=&gt;</span> <span class="err">$</span><span class="s">"{nameof(StringableArgument)}(id: {Id}, firstName: \"{FirstName}\", "</span> <span class="p">+</span>
            <span class="err">$</span><span class="s">"lastName: \"{LastName}\", emailAddres: \"{EmailAddress}\")"</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// in a test method:
</span><span class="n">_fooService</span><span class="p">.</span><span class="nf">Received</span><span class="p">()</span>
    <span class="p">.</span><span class="nf">DoStuff</span><span class="p">(</span><span class="n">Arg</span><span class="p">.</span><span class="n">Is</span><span class="p">&lt;</span><span class="n">StringableArgument</span><span class="p">&gt;(</span>
        <span class="n">e</span> <span class="p">=&gt;</span> <span class="n">e</span><span class="p">.</span><span class="n">Id</span> <span class="p">==</span> <span class="m">9</span> <span class="p">&amp;&amp;</span>
             <span class="n">e</span><span class="p">.</span><span class="n">FirstName</span> <span class="p">==</span> <span class="s">"jan"</span> <span class="p">&amp;&amp;</span>
             <span class="n">e</span><span class="p">.</span><span class="n">LastName</span> <span class="p">==</span> <span class="s">"kowalski"</span> <span class="p">&amp;&amp;</span>
             <span class="n">e</span><span class="p">.</span><span class="n">EmailAddress</span> <span class="p">==</span> <span class="s">"jan.kowalski@gmail.com"</span>
             <span class="p">));</span></code></pre></figure>

<p>Now the error message looks similar to (formatting added):</p>

<figure class="highlight"><pre><code class="language-nohighlight" data-lang="nohighlight">Expected to receive a call matching:
    DoStuff(e =&gt; ((((e.Id == 9) AndAlso 
        (e.FirstName == "jan")) AndAlso 
        (e.LastName == "kowalski")) AndAlso 
        (e.EmailAddress == "jan.kowalski@gmail.com")))
Actually received no matching calls.
Received 1 non-matching call (non-matching arguments indicated 
with '*' characters):
    DoStuff(*StringableArgument(
        id: 7, firstName: "john", 
        lastName: "doe", 
        emailAddres: "john.doe@gmail.com")*)</code></pre></figure>

<p>This is better than before. 
Now we can see both expected and actual values of the 
matched argument’s properties.</p>

<p>One drawback of this approach is that 
the quality of the error message depends on the quality of
<code class="highlighter-rouge">ToString</code> implementation. 
If we are using AOP solution like
<a href="https://github.com/Fody/Fody">Fody</a> to generate <code class="highlighter-rouge">ToString</code> implementations
for most of our classes, then this solution may be good enough. 
On the other hand if we are generating and updating our <code class="highlighter-rouge">ToString</code> methods
manually (even if this means pressing a shortcut in our IDE)
then I would prefer to look for a better solution that is totally automatic.</p>

<p>There is also another problem that we were ignoring so far.
Consider what will happen if we add a new field to our <code class="highlighter-rouge">StringableArgument</code>
class. 
Because we are using property access syntax inside of a lambda expression,
our existing matchers will not only compile without any problems when
we add a new field, they will also pass!
In order to ensure that our matchers and tests remain valid,
we must go through all argument matchers 
for <code class="highlighter-rouge">StringableArgument</code> class and make sure that they use 
the newly added field.</p>

<p>The above problem may be solved by moving equality checking
to the <code class="highlighter-rouge">StringableArgument</code> class itself. 
Let’s call this new class <code class="highlighter-rouge">EquotableArgument</code>:</p>

<figure class="highlight"><pre><code class="language-csharp" data-lang="csharp"><span class="k">public</span> <span class="k">class</span> <span class="nc">EquotableArgument</span> <span class="p">:</span> <span class="n">IEquatable</span><span class="p">&lt;</span><span class="n">EquotableArgument</span><span class="p">&gt;</span> <span class="p">{</span>
    <span class="k">public</span> <span class="kt">int</span> <span class="n">Id</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="p">}</span>
    <span class="k">public</span> <span class="kt">string</span> <span class="n">FirstName</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="p">}</span>
    <span class="k">public</span> <span class="kt">string</span> <span class="n">LastName</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="p">}</span>
    <span class="k">public</span> <span class="kt">string</span> <span class="n">EmailAddress</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="p">}</span>

    <span class="k">public</span> <span class="nf">EquotableArgument</span><span class="p">(</span><span class="kt">int</span> <span class="n">id</span><span class="p">,</span> <span class="kt">string</span> <span class="n">firstName</span><span class="p">,</span> <span class="kt">string</span> <span class="n">lastName</span><span class="p">,</span> <span class="kt">string</span> <span class="n">emailAddress</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">Id</span> <span class="p">=</span> <span class="n">id</span><span class="p">;</span>
        <span class="n">FirstName</span> <span class="p">=</span> <span class="n">firstName</span><span class="p">;</span>
        <span class="n">LastName</span> <span class="p">=</span> <span class="n">lastName</span><span class="p">;</span>
        <span class="n">EmailAddress</span> <span class="p">=</span> <span class="n">emailAddress</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">public</span> <span class="k">override</span> <span class="kt">string</span> <span class="nf">ToString</span><span class="p">()</span>
        <span class="p">=&gt;</span> <span class="err">$</span><span class="s">"{nameof(StringableArgument)}(id: {Id}, firstName: \"{FirstName}\", "</span> <span class="p">+</span>
            <span class="err">$</span><span class="s">"lastName: \"{LastName}\", emailAddres: \"{EmailAddress}\")"</span><span class="p">;</span>

    <span class="k">public</span> <span class="kt">bool</span> <span class="nf">Equals</span><span class="p">(</span><span class="n">EquotableArgument</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">other</span> <span class="k">is</span> <span class="k">null</span><span class="p">)</span> <span class="k">return</span> <span class="k">false</span><span class="p">;</span>

        <span class="k">return</span> <span class="nf">ToTuple</span><span class="p">(</span><span class="k">this</span><span class="p">)</span> <span class="p">==</span> <span class="nf">ToTuple</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">public</span> <span class="k">override</span> <span class="kt">bool</span> <span class="nf">Equals</span><span class="p">(</span><span class="kt">object</span> <span class="n">obj</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">obj</span> <span class="k">is</span> <span class="n">EquotableArgument</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">return</span> <span class="nf">Equals</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="k">false</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">public</span> <span class="k">override</span> <span class="kt">int</span> <span class="nf">GetHashCode</span><span class="p">()</span>
        <span class="p">=&gt;</span> <span class="nf">ToTuple</span><span class="p">(</span><span class="k">this</span><span class="p">).</span><span class="nf">GetHashCode</span><span class="p">();</span>

    <span class="k">private</span> <span class="k">static</span> <span class="p">(</span><span class="kt">int</span><span class="p">,</span> <span class="kt">string</span><span class="p">,</span> <span class="kt">string</span><span class="p">,</span> <span class="kt">string</span><span class="p">)</span> <span class="nf">ToTuple</span><span class="p">(</span><span class="n">EquotableArgument</span> <span class="n">arg</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">arg</span><span class="p">.</span><span class="n">Id</span><span class="p">,</span> <span class="n">arg</span><span class="p">.</span><span class="n">FirstName</span><span class="p">,</span> <span class="n">arg</span><span class="p">.</span><span class="n">LastName</span><span class="p">,</span> <span class="n">arg</span><span class="p">.</span><span class="n">EmailAddress</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1">// in a test method:
</span><span class="n">_fooService</span><span class="p">.</span><span class="nf">Received</span><span class="p">()</span>
    <span class="c1">// NOTICE: We no longer use a lambda expression.
</span>    <span class="p">.</span><span class="nf">DoStuff</span><span class="p">(</span><span class="n">Arg</span><span class="p">.</span><span class="nf">Is</span><span class="p">(</span><span class="k">new</span> <span class="nf">EquotableArgument</span><span class="p">(</span>
        <span class="n">id</span><span class="p">:</span> <span class="m">9</span><span class="p">,</span> 
        <span class="n">firstName</span><span class="p">:</span> <span class="s">"jan"</span><span class="p">,</span> 
        <span class="n">lastName</span><span class="p">:</span> <span class="s">"kowalski"</span><span class="p">,</span>
        <span class="n">emailAddress</span><span class="p">:</span> <span class="s">"jan.kowalski@gmail.com"</span><span class="p">)));</span></code></pre></figure>

<p>With this solution it is impossible to forget to update our matchers
when we add a new field.
We also get a slightly better error message (formatting added):</p>

<figure class="highlight"><pre><code class="language-nohighlight" data-lang="nohighlight">Expected to receive a call matching:
    DoStuff(StringableArgument(
        id: 9, firstName: "jan", 
        lastName: "kowalski", 
        emailAddres: "jan.kowalski@gmail.com"))
Actually received no matching calls.
Received 1 non-matching call (non-matching arguments 
indicated with '*' characters):
    DoStuff(*StringableArgument(
        id: 7, firstName: "john", 
        lastName: "doe", 
        emailAddres: "john.doe@gmail.com")*)</code></pre></figure>

<p>So far so good. But what if our argument has ten or more properties.
With complex arguments looking for a one property with
unexpected value may quickly change into “Where’s Wally?” game.
The only way to further improve error messages is to stop relaying on
NSubstitute/hand-carfted <code class="highlighter-rouge">Equals</code> implementation 
and instead to use specialized assertion library like
<a href="https://fluentassertions.com/">FluentAssertions</a> or
<a href="http://www.n-fluent.net/">NFluent</a>.</p>

<p>Here is how our test would look like if we decide to use FluentAssertions:</p>

<figure class="highlight"><pre><code class="language-csharp" data-lang="csharp"><span class="na">[Fact]</span>
<span class="k">public</span> <span class="k">void</span> <span class="nf">Catching_argument_and_checking_manually_with_fluent_assertions</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// Arrange
</span>    <span class="n">PlainArgument</span> <span class="n">arg</span> <span class="p">=</span> <span class="k">null</span><span class="p">;</span>

    <span class="n">_fooService</span>
        <span class="p">.</span><span class="nf">DoStuff</span><span class="p">(</span><span class="n">Arg</span><span class="p">.</span><span class="n">Do</span><span class="p">&lt;</span><span class="n">PlainArgument</span><span class="p">&gt;(</span><span class="n">x</span> <span class="p">=&gt;</span> <span class="n">arg</span> <span class="p">=</span> <span class="n">x</span><span class="p">));</span>

    <span class="c1">// Act
</span>    <span class="n">_component</span><span class="p">.</span><span class="nf">DoStuff</span><span class="p">();</span>

    <span class="c1">// Assert
</span>    <span class="n">_fooService</span><span class="p">.</span><span class="nf">Received</span><span class="p">()</span>
        <span class="p">.</span><span class="nf">DoStuff</span><span class="p">(</span><span class="n">Arg</span><span class="p">.</span><span class="n">Any</span><span class="p">&lt;</span><span class="n">PlainArgument</span><span class="p">&gt;());</span>

    <span class="n">arg</span><span class="p">.</span><span class="nf">Should</span><span class="p">()</span>
        <span class="p">.</span><span class="nf">BeEquivalentTo</span><span class="p">(</span><span class="k">new</span> <span class="nf">PlainArgument</span><span class="p">(</span>
            <span class="n">id</span><span class="p">:</span> <span class="m">11</span><span class="p">,</span> 
            <span class="n">firstName</span><span class="p">:</span> <span class="s">"jan"</span><span class="p">,</span> 
            <span class="n">lastName</span><span class="p">:</span> <span class="s">"kowlaski"</span><span class="p">,</span> 
            <span class="n">emailAddress</span><span class="p">:</span> <span class="s">"jan.kowalski@gmail.com"</span><span class="p">));</span>        
<span class="p">}</span></code></pre></figure>

<p>The error message is:</p>

<figure class="highlight"><pre><code class="language-nohighlight" data-lang="nohighlight">Expected member Id to be 11, but found 7.
Expected member FirstName to be "jan" with a length of 3, but "john" has a length of 4, differs near "ohn" (index 1).
Expected member LastName to be "kowlaski" with a length of 8, but "doe" has a length of 3, differs near "doe" (index 0).
Expected member EmailAddress to be 
"jan.kowalski@gmail.com" with a length of 22, but 
"john.doe@gmail.com" has a length of 18, differs near "ohn" (index 1).

With configuration:
// (skipped)
// Here FluentAssertions describes configuration
// that it used to compare the two objects.</code></pre></figure>

<p>Not bad, I must say. We get a list of only these properties that have
unexpected values. Certain messages seem a little bit too verbose for me
e.g. <code class="highlighter-rouge">Expected member FirstName to be "jan" with a length of 3</code>,
 <code class="highlighter-rouge">but "john" has a length of 4, differs near "ohn" (index 1).</code>
Maybe <code class="highlighter-rouge">Expected FirstName to be "jan" but was "john".</code> would be
just enough?
Still it is the best solution that we have so far.</p>

<p>The only downside that I see 
is that the test code is now a little more verbose and less readable.
Mainly because 
we are now responsible for manually capturing argument’s value:</p>

<figure class="highlight"><pre><code class="language-csharp" data-lang="csharp"><span class="n">PlainArgument</span> <span class="n">arg</span> <span class="p">=</span> <span class="k">null</span><span class="p">;</span>
<span class="n">_fooService</span>
    <span class="p">.</span><span class="nf">DoStuff</span><span class="p">(</span><span class="n">Arg</span><span class="p">.</span><span class="n">Do</span><span class="p">&lt;</span><span class="n">PlainArgument</span><span class="p">&gt;(</span><span class="n">x</span> <span class="p">=&gt;</span> <span class="n">arg</span> <span class="p">=</span> <span class="n">x</span><span class="p">));</span></code></pre></figure>

<p>With a bit of C# magic we may make argument capturing less painful:</p>

<figure class="highlight"><pre><code class="language-csharp" data-lang="csharp"><span class="n">_fooService</span>
    <span class="p">.</span><span class="nf">DoStuff</span><span class="p">(</span><span class="nf">Capture</span><span class="p">(</span><span class="k">out</span> <span class="n">Arg</span><span class="p">&lt;</span><span class="n">PlainArgument</span><span class="p">&gt;</span> <span class="n">arg</span><span class="p">));</span>

<span class="c1">// Act
</span><span class="n">_component</span><span class="p">.</span><span class="nf">DoStuff</span><span class="p">();</span>

<span class="c1">// Assert
</span><span class="n">_fooService</span><span class="p">.</span><span class="nf">Received</span><span class="p">()</span>
    <span class="p">.</span><span class="nf">DoStuff</span><span class="p">(</span><span class="n">Arg</span><span class="p">.</span><span class="n">Any</span><span class="p">&lt;</span><span class="n">PlainArgument</span><span class="p">&gt;());</span>

<span class="c1">// This time we use NFluent
</span><span class="n">Check</span><span class="p">.</span><span class="nf">That</span><span class="p">(</span><span class="n">arg</span><span class="p">.</span><span class="n">Value</span><span class="p">).</span><span class="nf">HasFieldsWithSameValues</span><span class="p">(</span>
    <span class="k">new</span> <span class="nf">PlainArgument</span><span class="p">(</span>
        <span class="n">id</span><span class="p">:</span> <span class="m">7</span><span class="p">,</span> 
        <span class="n">firstName</span><span class="p">:</span> <span class="s">"john"</span><span class="p">,</span> 
        <span class="n">lastName</span><span class="p">:</span> <span class="s">"doe"</span><span class="p">,</span> 
        <span class="n">emailAddress</span><span class="p">:</span> <span class="s">"john.doe@gmail.com"</span><span class="p">));</span> </code></pre></figure>

<p>To see how it works please check <a href="https://github.com/marcin-chwedczuk/blog-nsubstitute-error-messages/blob/master/Library.Test/ArgCapture.cs">ArgCapture.cs</a> file.</p>

<p>Catching argument’s value manually is cumbersome and 
makes tests less readable. On the other hand using some “magical”
syntactic sugar also does not looks like a good idea. 
After all our code should be simple. If we can avoid using “magic”
we should do it!</p>

<p>Our final solution is to create a custom NSubstitute argument matcher.
The matcher uses undercover FluentAssertions library to perform the check.
Here is how the test code looks like with this approach:</p>

<figure class="highlight"><pre><code class="language-csharp" data-lang="csharp"><span class="na">[Fact]</span>
<span class="k">public</span> <span class="k">void</span> <span class="nf">Checking_argument_using_custom_NSubstitute_matcher</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// Arrange
</span>
    <span class="c1">// Act
</span>    <span class="n">_component</span><span class="p">.</span><span class="nf">DoStuff</span><span class="p">();</span>

    <span class="c1">// Assert
</span>    <span class="n">var</span> <span class="n">expected</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">PlainArgument</span><span class="p">(</span>
        <span class="n">id</span><span class="p">:</span> <span class="m">11</span><span class="p">,</span> 
        <span class="n">firstName</span><span class="p">:</span> <span class="s">"jan"</span><span class="p">,</span> 
        <span class="n">lastName</span><span class="p">:</span> <span class="s">"kowlaski"</span><span class="p">,</span> 
        <span class="n">emailAddress</span><span class="p">:</span> <span class="s">"jan.kowalski@gmail.com"</span><span class="p">);</span>

    <span class="n">_fooService</span><span class="p">.</span><span class="nf">Received</span><span class="p">()</span>
        <span class="p">.</span><span class="nf">DoStuff</span><span class="p">(</span><span class="n">WithArg</span><span class="p">.</span><span class="nf">EquivalentTo</span><span class="p">(</span><span class="n">expected</span><span class="p">));</span>
<span class="p">}</span></code></pre></figure>

<p>The error message generated for an argument that does
not overload <code class="highlighter-rouge">ToString</code> looks like this (formatting added):</p>

<figure class="highlight"><pre><code class="language-nohighlight" data-lang="nohighlight">Expected to receive a call matching:
    DoStuff(PlainArgument)
Actually received no matching calls.
Received 1 non-matching call (non-matching arguments indicated 
with '*' characters):
    DoStuff(*PlainArgument*)
        arg[0]: Expected member Id to be 11, but found 7.
                Expected member FirstName to be "jan" with a length of 3, 
                but "john" has a length of 4, differs near "ohn" (index 1).
                Expected member LastName to be "kowlaski" with a length of 8, 
                but "doe" has a length of 3, differs near "doe" (index 0).
                Expected member EmailAddress to be 
                "jan.kowalski@gmail.com" with a length of 22, but 
                "john.doe@gmail.com" has a length of 18, differs near "ohn" 
                (index 1).</code></pre></figure>

<p>It is clear that the problem occurred at the first argument (<code class="highlighter-rouge">arg[0]</code>). 
Also we can see the actual and expected values of the argument’s 
fields and properties.
And the test code is simple and clean.
If you are interested how it is implemented please see
<a href="https://github.com/marcin-chwedczuk/blog-nsubstitute-error-messages/blob/master/Library.Test/CustomMatcher.cs">CustomMatcher.cs</a>
file.</p>

<p>As we can see there exists no perfect solution. Still with a little effort
we can make our error messages much more readable and pleasurable to work with.
I personally suggest to use either the last solution or 
the solution presented in <code class="highlighter-rouge">Catching_argument_and_checking_manually_with_fluent_assertions</code> test.</p>

<p>Source code and examples: <a href="https://github.com/marcin-chwedczuk/blog-nsubstitute-error-messages">GitHub</a></p>


	  ]]></description>
	</item>

	<item>
	  <title>Inheritance? Just say no!</title>
	  <link>//inheritance-just-say-no</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2018-12-12T01:00:00+01:00</pubDate>
	  <guid>//inheritance-just-say-no</guid>
	  <description><![CDATA[
	     Recently during a code review I have found the following piece
of code:
{% highlight csharp %}
public class TemplateCache 
    : ConcurrentDictionary<TemplateName, Template> { }
{% endhighlight %}
Here the programmer broke one of the most fundamental principles
of modern object oriented programming:

> Prefer composition over inheritance

Why inheritance is bad in most of the cases? Here are the reasons:

###### Watered down component API

What methods would you expect on a cache? Something that gets
values from the cache if they are already there. Let us call 
this operation `TryGetValue(cacheKey, out value)`. 
And of course a method to
add a new or overwrite an existing cache entry, let's call it
`SetValue(cacheKey, value)`. Do we need more methods on a cache
from the client point of view? Maybe in the future we will want to
extend `SetValue` operation to allow client to specify for how
long items added to the cache should be stored? Who knows. 
But still we would end up with only two operations. 

> NOTE A truly generic and reusable cache 
> is usually slightly more complicated - instead of two
> we have three methods! For example please see
> [IMemoryCache](https://github.com/aspnet/Caching/blob/master/src/Microsoft.Extensions.Caching.Abstractions/IMemoryCache.cs) interface.

On the other hand if we use inheritance we end up with something 
like this:
![Cache API when we use inheritance](assets/images/2018-12-12/cache_api.png)
This is much more than we asked for. We actually get operations
that make no sense for a cache like `IsEmpty`. I mean either an item
that we are looking for is in the cache or it is not - who cares
if the cache is empty itself? 

I hope that I managed to persuade you that a good component
API should be small, focused and easy to use. We get none of these 
if we use inheritance.

###### Broken encapsulation

By using inheritance we are making it clear to the clients of
our component that it is implemented using `ConcurrentDictionary` class.
If we wait long enough we will notice that some of them 
will start relaying on that knowledge in their code. 
For example they may use `ContainsKey` method for checking if
the cache contains a given entry. 
What will happen later, when we decide that we want to change 
the cache implementation and use for example 
[IMemoryCache](https://dotnetcoretutorials.com/2017/03/05/using-inmemory-cache-net-core/) instead?
Clients of our component will get angry, because
our new version of the cache  
introduced a breaking change into their code.

Just to sum up: Inheritance both exposes implementation
details of components and makes evolution of their APIs more difficult.

###### Liskov substitution principle is violated 

In short some operations that make sense for a dictionary
may not make sense for a cache. For example it makes no
sense to cache a template that does not exists, yet with
inheritance we may write:

{% highlight csharp %}
var foo = new TemplateName("foo");

ConcurrentDictionary<TemplateName, Template> dict 
   = new TemplateCache();

dict.GetOrAdd(foo, (Template)null);

// Ops we have a null template here...
Console.WriteLine("value is: " + 
   dict.GetOrAdd(foo, (Template)null));
{% endhighlight %}

When we use inheritance we are telling the type system that
`TemplateCache` *is a* `ConcurrentDictionary`. 
From logical point of view this makes no sense. They are two
different components that have two different purposes and also
different usage patterns. 
They should have nothing in common.

> BTW You should avoid putting `null`s into collection classes of any sort.

Let's finish this post by seeing how composition can be used
to improve our `TemplateCache` component:
{% highlight csharp %}
public class TemplateCache {
  private readonly ConcurrentDictionary<TemplateName, Template> _cache 
      = new ConcurrentDictionary<TemplateName, Template>();

  public bool TryGetTemplate(TemplateName name, out Template template)
      => _cache.TryGetValue(name, out template);

  public void AddTemplate(Template template)
      => _cache.AddOrUpdate(
          template.Name, template, (name, existing) => template);
}
{% endhighlight %}
Yep, simple, clean and easy to use!


	  ]]></description>
	</item>

	<item>
	  <title>Abusing local functions to hide design problems</title>
	  <link>//abusing-local-functions-to-hide-design-problems</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2018-10-08T02:00:00+02:00</pubDate>
	  <guid>//abusing-local-functions-to-hide-design-problems</guid>
	  <description><![CDATA[
	     Recently I was browsing through a certain code base
and I saw a code similar to this:
{% highlight csharp %}
public class EnterpriseNotificationSender {
    private readonly IUserManagementService _userManagementService;
    // ctor and stuff...
  
    public void SendNotificationsToUsers(string companyId) {
        var addresses = GetRecipientsAddresses(companyId);
        foreach(var address in addresses) {
            SendNotification(address);
        }
    }
  
    private IEnumerable<EmailAddress> 
                     GetRecipientsAddresses(string companyId) {
        return _userManagementService
             .FindUsersBelongingToCompany(companyId)
             .Where(UserShouldReciveNotification)
             .Select(user => user.EmailAddress)
             .ToList();
  
        bool UserShouldReciveNotification(User user) {
            return user.EmailAddress != null
                && user.IsRegistered
                && !user.IsDisabled;
        }
    }
  
    private void SendNotification(EmailAddress address) {
        // do stuff...
    }
}
{% endhighlight %}
Especially `GetRecipientsAddresses` method draw my attention.
Someone extracted quite complicated lambda expression
to a local function.
At first I thought that this is indeed a very nice usage for local
functions.
LINQ query is much more readable
with expressions like `Where(UserShouldReciveNotification)`
instead of long lambdas.

It took me a while to realize that the local function
in the code above, was used to hide design problems.
Let's take a closer look at the condition encapsulated by
`UserShouldReciveNotification` function:
{% highlight csharp %}
return user.EmailAddress != null
    && user.IsRegistered
    && !user.IsDisabled;
{% endhighlight %}
We should deal with the simplest to fix problems first:

**Bad naming:** We should always format predicates in "a positive way".
For examples we should prefer `IsOpen` and `IsAvailable` to `IsClose`
and `IsUnavailable`. Here `IsDisabled` should be named `IsEnabled`.
As a first step in refactoring we may add `IsEnabled` property
to the `User` class:
{% highlight csharp %}
public bool IsEnabled => !IsDisabled;
{% endhighlight %}

**Unreadable condition:** If a user has optional email then we may expect
that our codebase is littered with little `user.EmailAddres != null` checks.
To increase readability we should encapsulate this check into a separate property:
{% highlight csharp %}
public bool HasEmailAddress => (EmailAddress != null);
{% endhighlight %}

**Missing entity attributes:** When I looked closely at the condition
`user.IsRegistered && !user.IsDisabled` I found out that it occurs
in many places in that codebase. For some reason the system was creating
users before they actually registered. A user that not registered yet was basically
a stub not a real user. Users could also be disabled by admins (registered or not),
this is what the second part of the condition was responsible for.
Clearly `User` entity is missing an attribute that could tell us whatever
a user is active, so let's add one:
{% highlight csharp %}
public bool IsActive
    => IsRegistered && IsEnabled;
{% endhighlight %}

After all these refactorings we may finally rewrite our LINQ query:
{% highlight csharp %}
return _userManagementService
    .FindUsersBelongingToCompany(companyId)
    .Where(user => user.IsActive)
    .Where(user => user.HasEmailAddress)
    .Select(user => user.EmailAddress)
    .ToList();
{% endhighlight %}
This version is as readable as version with the local function,
but does not attempt to hide code smells.

Conclusion: Every time when you have a too long or too complicated
lambda expression, that you what to extract to a local function,
think if you can simplify that lambda by extracting conditions and checks
into new methods and properties on processed objects.


	  ]]></description>
	</item>

	<item>
	  <title>Automatically generate new OAuth 2.0 access tokens when using Postman</title>
	  <link>//automatically-generate-new-oauth2-tokens-when-using-postman</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2018-09-29T02:00:00+02:00</pubDate>
	  <guid>//automatically-generate-new-oauth2-tokens-when-using-postman</guid>
	  <description><![CDATA[
	     Did you ever try to use [Postman](https://www.getpostman.com/)
with OAuth 2.0 protected API? 
It is pretty annoying. 
First you must select the correct authorization type, 
then you must open a popup to request a new access token,
and only then you can send your HTTP request.
And of course when the token expires or when for some reason you need a
new one (e.g. because you want to switching from development to staging environment),
you need to go through the process again.
Fortunately for us this can be automated using Postman pre-request scripts.

To test that my pre-request script works I used publicly available 
[IdentityServer](http://identityserver.io/)
[demo instance](https://demo.identityserver.io/).
We may use it to manually generate a new access token and
to preform a test API call:
![Manually generating token 1](assets/images/2018-09-29/Postman_1.png)
![Manually generating token 2](assets/images/2018-09-29/Postman_2.png)
![Performing test API call](assets/images/2018-09-29/Postman_3.png)

OK, so how will we automate this stuff? Let's start by creating a new
collection that will contain all requests for which we want to automatically
generate OAuth access tokens:
![Create a new collection](assets/images/2018-09-29/Postman_4.png)
On Authorization tab use {% raw %}{{accessToken}}{% endraw %}
 as a value of the Access Token
field, this way Postman will try to load the token value from a variable:
![Set Access Token field](assets/images/2018-09-29/Postman_6.png)
We will populate this variable using the following pre-request script:
{% highlight javascript %}
// Adapted from: https://gist.github.com/harryi3t/dd5c61451206047db70710ff6174c3c1

let tokenUrl = 'https://demo.identityserver.io/connect/token';
let clientId = 'client';
let clientSecret = 'secret';
let scope = 'api'

let getTokenRequest = {
    method: 'POST',
    url: tokenUrl,
    auth: {
        type: "basic",
        basic: [
            { key: "username", value: clientId },
            { key: "password", value: clientSecret }
        ]
    },
    body: {
        mode: 'formdata',
        formdata: [
            { key: 'grant_type', value: 'client_credentials' },
            { key: 'scope', value: scope }
        ]
    }
};

pm.sendRequest(getTokenRequest, (err, response) => {
    let jsonResponse = response.json(),
        newAccessToken = jsonResponse.access_token;

    console.log({ err, jsonResponse, newAccessToken })

    pm.environment.set('accessToken', newAccessToken);
    pm.variables.set('accessToken', newAccessToken);
});
{% endhighlight %}
Which should be set on Pre-request Scripts tab:
![Set pre-request script](assets/images/2018-09-29/Postman_5.png)
Let's save all changes.

Now we must add a new request to our collection:
![Add a new request](assets/images/2018-09-29/Postman_7.png)
**This is very important.** Without this step our
pre-request script will not be called:
![Save the new request](assets/images/2018-09-29/Postman_8.png)
When creating the new request we should select "Inherit auth from parent"
as the authentication type.

Now if we send our test request we should get `200 OK` response:
![It works](assets/images/2018-09-29/Postman_9.png)

## Making our pre-request script work with multiple environments

Often we have to work with multiple environments like
development, staging (UAT) and production.
Each of these environments uses different URLs for services
and for OAuth authorization server. 
Not to mention that each environment will 
have its own set of client secrets (passwords).

Fortunately for us Postman has build in support for multiple environments.
Let's start by creating a new environment with all necessary values
that are needed by our pre-request script:
![Create a new environment](assets/images/2018-09-29/Postman_10.png)

Then we must modify our script to use values from the selected
environment:
{% highlight javascript %}
function getvar(variableName) {
    let value = pm.variables.get(variableName);
    if (!value) throw new Error(
        `Variable '${variableName}' is not defined. Do you forget to select an environment?`);
    return value;
}

let tokenUrl = getvar('tokenUrl');
let clientId = getvar('clientId');
let clientSecret = getvar('clientSecret');
let scope = getvar('scope'); 

// rest of the script is the same as before
{% endhighlight %}

And that is all. Now we must define all environments that
we need and we are ready to go:
![Sending request with environment set](assets/images/2018-09-29/Postman_11.png)

## Troubleshooting

Select `View -> Show Postman Console` to see all log statements
made by our pre-request script: 
![Postman Console](assets/images/2018-09-29/Postman_12.png)

Also using traffic sniffer like [Fiddler](https://www.telerik.com/fiddler)
or [ZAP](https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project)
to compare requests made by auth popup and pre-request script may be helpful:
![ZAP](assets/images/2018-09-29/zap.png)

If you are going to use ZAP do not forget to set ZAP as a proxy in Postman settings.


	  ]]></description>
	</item>

	<item>
	  <title>Avoid hidden coupling to interface implementation</title>
	  <link>//avoid-hidden-coupling-to-interface-implementation</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2018-09-21T02:00:00+02:00</pubDate>
	  <guid>//avoid-hidden-coupling-to-interface-implementation</guid>
	  <description><![CDATA[
	     A few days ago I was reviewing a pull request at work and
one line of code catch my eye:
{% highlight csharp %}
var @event = new CupOfCoffeeReadyEvent(/* ... */);
_logger.LogInformation(
    "Publishing cup of coffee event: {@Event}.", @event); // <== this one
_mediator.Publish(@event);
{% endhighlight %}
At my workplace we are using standard `ILogger` interface from 
`Microsoft.Extensions.Logging.Abstractions`
package. Also logged variable name starts with `@` (`@event`). 
And so I started to suspect that 
the log statement contains an error and instead it should be written as:
{% highlight csharp %}
// {@Event} -> {Event}
_logger.LogInformation(
    "Publishing cup of coffee event: {Event}.", @event);
{% endhighlight %}
Without thinking any further I put a friendly comment, that 
this logging statement should be fixed.
After half an hour, instead of a fix I get the following response:

> In this microservice we are using Serilog as third-party logging provider.
>
> In Serilog `@` is used as destructuring operator,
> please see: 
> https://github.com/serilog/serilog/wiki/Structured-Data#preserving-object-structure
>
> Basically this means that the argument will be logged in JSON form.

So `@` character was put there on purpose. OK, fine.
But there still was something fishy about this code. 
On the one hand we are using `ILogger` from 
`Microsoft.Extensions.Logging.Abstractions` to decouple ourselves 
from any specific logging provider,
on the other hand we are using Serilog specific extensions.
This results in a false sense of security. 
We may think that since we are
using standard `ILogger`, changing logging provider to e.g.
Azure Web App Diagnostics would be as simple as changing `Startup` 
class of our application.
Unfortunately since we coupled ourselves with Serilog 
(by Serilog specific extensions to the log message template),
some of our log statements may not work with the new logging provider.

So what is the solution to this problem? We must choose whatever we
want to use Serilog specific features. If we want to use them, then 
we should not hide the fact that we are using Serilog. Fortunately for
us Serilog provides it's own, ready to use `ILogger` interface.
And we should use that interface instead of standard one accross
the entire application.

On the other hand, if we expect that we may need to change logging
provider in the future, we should stick with 
`Microsoft.Extensions.Logging.Abstractions` `ILogger` and we should
use only the features that are described in 
[the official documentation](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging/?view=aspnetcore-2.1). 
If our needs are not fully covered
by the standard `ILogger` 
e.g. we must log objects as JSON, then we must implement them
ourselves by e.g. creating wrappers around parameters:
{% highlight csharp %}
_logger.LogInformation(
    "Publishing cup of coffee {Event}.", new LogAsJson(@event));
{% endhighlight %}

It is really interesting that a similar coupling happens when using
`IEnumerable<T>` interface as the return type of a method.
How many times have you seen a code similar to:
{% highlight csharp %}
public void SomeMethod() {
    // IEnumerable<User>
    var users = userService.FindAllUsers();
    
    users
        .ToList()
        .ForEach(user => user.IsActive = false);
    
    userService.SaveAll(users.ToArray());
}
class UserSerivce {
    public IEnumerable<User> FindAllUsers() {
        return new List<User> {
            new User { IsActive = true },
            new User { IsActive = false }
        };
    }
    public void SaveAll(params User[] users) {
        foreach (var user in users) {
            Console.WriteLine(user.IsActive);
        }
    }
}
public class User {
    public bool IsActive { get; set; }
}
{% endhighlight %}
Again we have here a bad case of hidden coupling to the interface implementation.
We are using `IEnumerable<T>`
interface but we are assuming that it is backed by
a collection for which multiple enumerations always
return the same elements. 
Our code will break 
when someone will change `FindAllUsers` implementation to
e.g.:
{% highlight csharp %}
public IEnumerable<User> FindAllUsers() {
    yield return new User { IsActive = true };
    yield return new User { IsActive = false };
}
{% endhighlight %}

The solution to this problem is honesty. If you have
a value of type `IEnumerable<T>`, tread it as 
a value of type `IEnumerable<T>`. Nothing more, nothing less.
Do not assume that multiple enumerations
will return the same elements. 
This is not guaranteed by that interface.

If you want to return a sequence of elements from a method with
this additional guarantee, then please use a more specific 
interface like `ICollection<T>` or `IReadOnlyList<T>` or 
maybe even something from `System.Collections.Immutable` package.



	  ]]></description>
	</item>

	<item>
	  <title>Fluent Validation and complex dependencies between properties</title>
	  <link>//fluent-validation-and-complex-dependencies-between-properties</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2018-09-18T02:00:00+02:00</pubDate>
	  <guid>//fluent-validation-and-complex-dependencies-between-properties</guid>
	  <description><![CDATA[
	     [FluentValidation](https://fluentvalidation.net/) is one of the
best validation libraries for .NET. I use it daily both at work
and in my personal pet projects. Still from time to time I
encounter situations where it is not obvious how 
I should use FluentValidation.
In this blog post I describe one such situation that I have to
deal with recently.

In short I had to validate a simple DTO:
{% highlight csharp %}
public class SampleRequestDto {
    public AddressDto Address { get; set; }
    public ContactInfoDto ContactInfo { get; set; }
}

public class AddressDto {
    public string AddressLine1 { get; set; }
    public string AddressLine2 { get; set; }
    public string City { get; set; }
    public string ZipCode { get; set; }
    public string CountryIsoCode { get; set; }
}

public class ContactInfoDto {
    public string EmailAddress { get; set; }
    // Phone number validation depends on CountryIsoCode.
    public string PhoneNumber { get; set; }
}
{% endhighlight %}
With a small twist that `ContactInfo.PhoneNumber` was 
validated using country dependent format and information
about country itself was stored in `Address.CountryIsoCode` field.

This is generally a good use-case for FluentValidation `Custom` rule:
{% highlight csharp %}
RuleFor(x => x)
    .Custom((dto, context) => {
        var countryIsoCode = dto?.Address?.CountryIsoCode;
        if (string.IsNullOrEmpty(countryIsoCode)) 
            return;

        var country = Countries.FindCountryByIsoCode(countryIsoCode);
        // invalid country code - cannot validate phone number
        if (country == null)
            return;

        var phoneNumber = dto?.ContactInfo?.PhoneNumber;
        if (string.IsNullOrWhiteSpace(phoneNumber))
            return;

        if (!country.PhoneNumberFormat.Matches(phoneNumber)) {
            context.AddFailure(new ValidationFailure(
                $"ContactInfo.PhoneNumber", // property name
                $"'{phoneNumber}' is not a valid phone number in {country.Name}."));
        }
    });

{% endhighlight %}
Unfortunately in my case I also had a bunch of other country dependent 
values like VAT numbers scattered across many DTOs. And I needed
a more reusable and programmer friendly solution than `Custom` rule.

Ideally my validator definition should look like this:
{% highlight csharp %}
public class SampleRequestDtoValidator : AbstractValidator<SampleRequestDto> {
    public  SampleRequestDtoValidator() {
        RuleFor(x => x.Address)
            .SetValidator(new AddressDtoValidator());

        RuleFor(x => x.ContactInfo)
            .SetValidator(new ContactInfoDtoValidator());
    }
}

public class AddressDtoValidator : AbstractValidator<AddressDto> {
    public AddressDtoValidator() {
        RuleFor(x => x.CountryIsoCode)
            .NotEmpty()
            .CountryIsoCode(); // custom extension
        // other rules...
    }
}

public class ContactInfoDtoValidator : AbstractValidator<ContactInfoDto> {
    public ContactInfoDtoValidator() {
        RuleFor(x => x.PhoneNumber)
            .NotEmpty()
            .MaximumLength(50)
            .PhoneNumber(); // custom extension
        // other rules...
    }
}
{% endhighlight %}
Creating property validators like `CountryIsoCode` using FluentValidation
is very simple. You just extend `PropertyValidator` class,
provide an error message template to the base class ctor and override
`IsValid` method. 
Additionally you may define an extension method 
to the `IRuleBuilder<T,TProperty>`
interface to make your validator behave like build-in ones.
{% highlight csharp %}
public class CountryIsoCodeValidator : PropertyValidator {
    public CountryIsoCodeValidator() 
        : base("'{PropertyValue}' is not a valid country iso code.") { }

    protected override bool IsValid(PropertyValidatorContext context) {
        var isoCode = (string) context.PropertyValue;

        if (string.IsNullOrEmpty(isoCode)) {
            return true;
        }

        return Countries.IsKnownIsoCode(isoCode);
    }
}

public static class CountryIsoCodeValidatorExtension {
    public static IRuleBuilderOptions<T, string> CountryIsoCode<T>(
        this IRuleBuilder<T, string> rule
    ) {
        return rule.SetValidator(new CountryIsoCodeValidator());
    }
}
{% endhighlight %}

`CountryCode` validator was easy, what about `PhoneNumber` validator?
Here the only challenge that we must solve 
is finding a way to pass country ISO code from `Address` to 
phone number validator.
To solve this problem I decided to use "advanced" FluentValidation
feature called "Root Context Data". Basically this is a 
`IDictionary<string, object>` that can be prefilled with custom data
before validation starts and then is accessible to every validator
in validators tree.

Let's take a look at an example from 
[official documentation](https://fluentvalidation.net/start#root-context-data):
{% highlight csharp %}
var instanceToValidate = new Person();

var context = new ValidationContext<Person>(person);
context.RootContextData["MyCustomData"] = "Test";

var validator = new PersonValidator();
validator.Validate(context);

// usage inside validator:
RuleFor(x => x.Surname).Custom((x, context) => {
  if(context.ParentContext.RootContextData.ContainsKey("MyCustomData")) {
    context.AddFailure("My error message");
  }
});
{% endhighlight %}
Looks very promising, and what's better we can add values to `RootContextData`
straight inside top-level validators by overriding `PreValidate` method:
{% highlight csharp %}
public class SampleRequestDtoValidator : AbstractValidator<SampleRequestDto> {
    public  SampleRequestDtoValidator() {
        RuleFor(x => x.Address)
            .SetValidator(new AddressDtoValidator());

        RuleFor(x => x.ContactInfo)
            .SetValidator(new ContactInfoDtoValidator());
    }

    protected override bool PreValidate(
        ValidationContext<SampleRequestDto> context, ValidationResult result) 
    {
        var contextData = new ValidationContextData(
            context.RootContextData);

        contextData.CountryIsoCode = 
            context.InstanceToValidate?.Address?.CountryIsoCode;

        return true; // continue validation
    }
}
{% endhighlight %}
To avoid dealing with `object`s I have also created a strongly typed
wrapper (`ValidationContextData` class) around `RootContextData`
dictionary.

IMPORTANT: To make validators reusable you should set `RootContextData` only
in top level validators. Validators used with `SetValidator`
method are not considered top level.

Now implementing `PhoneNumberValidator` is easy:
{% highlight csharp %}
public class PhoneNumberValidator : PropertyValidator {
    public PhoneNumberValidator() 
        : base("'{PropertyValue}' is not a valid phone number in {Country}.") { }

    protected override bool IsValid(PropertyValidatorContext context) {
        var phoneNumber = (string) context.PropertyValue;
        if (string.IsNullOrEmpty(phoneNumber)) {
            return true;
        }

        var contextData = new ValidationContextData(
            context.ParentContext.RootContextData);

        var country = TryFindCountry(contextData.CountryIsoCode);
        if (country == null) {
            // without a country we cannot validate a phone number
            return true;
        }

        context.MessageFormatter.AppendArgument("Country", country.Name);

        return country.PhoneNumberFormat.Matches(phoneNumber);
    }

    private Country TryFindCountry(string countryIsoCode) {
        if (string.IsNullOrEmpty(countryIsoCode)) {
            return null;
        }

        return Countries.FindCountryByIsoCode(countryIsoCode);
    }
}

public static class PhoneNumberValidatorExtension {
    public static IRuleBuilderOptions<T, string> PhoneNumber<T>(
        this IRuleBuilder<T, string> rule
    ) {
        return rule.SetValidator(new PhoneNumberValidator());
    }
}
{% endhighlight %}
And we are done!

#### Unit-testing validators

FluentValidation provides several extension methods that
make unit-testing easy, just take a look:
{% highlight csharp %}
using FluentValidation.TestHelper;

public class SampleRequestDtoValidatorTest {
    private readonly SampleRequestDtoValidator _validator;

    public SampleRequestDtoValidatorTest() {
        _validator = new SampleRequestDtoValidator();
    }

    [Fact]
    public void Should_return_error_when_phone_number_is_invalid_and_countryIsoCode_is_set() {
        // Arrange
        var invalidRequest = 
            SampleRequestDtoFixture.CreateValidRequest();
        invalidRequest.Address.CountryIsoCode = "PL";
        invalidRequest.ContactInfo.PhoneNumber = "+48 123";

        // Assert
        _validator
            .ShouldHaveValidationErrorFor(
                x => x.ContactInfo.PhoneNumber, invalidRequest)
            .WithErrorMessage(
                "'+48 123' is not a valid phone number in Poland.");
    }
}
{% endhighlight %}

#### Design considerations

Everything works right now, but there is still place for improvement.
For example what happens when a programmer forgets to
override `PreValidate` method and set all required properties?
Validation of certain properties will be silently skipped.
This is not good.
To minimize this problem I put additional checks inside `ValidationContextData`
class. They will throw an exception with a descriptive message if
validator tries to access a property that was not previously set.

In my application values like phone numbers are always validated against
country specific formats. But I can imaging situations where
sometimes we use country agnostic phone number validator and
sometimes 
we use country specific one. In such cases it would be good
to call the country agnostic validator just a `PhoneNumberValidator` and
the country specific validator a `CountryDependentPhoneNumberValidator`.

I have a mixed feelings about `ValidationContextData` class because
it is used by every country specific validator in my code. Maybe 
instead of introducing this common dependency every validator should
access `RootContextData` and check if the property is set itself?

Sample source code: [GitHub](https://github.com/marcin-chwedczuk/blog-fluent-validation-adventure).


	  ]]></description>
	</item>

	<item>
	  <title>You can live without mocking frameworks</title>
	  <link>//you-can-live-without-your-mocking-framework</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2018-09-08T02:00:00+02:00</pubDate>
	  <guid>//you-can-live-without-your-mocking-framework</guid>
	  <description><![CDATA[
	     For a long time I have been fan of mocking frameworks like 
[Moq](https://github.com/Moq/moq4/wiki/Quickstart)
and [NSubstitute](http://nsubstitute.github.io).
These libraries seems indispensable while unit-testing.
They allow us to easily generate subs and mocks and assert that
certain interaction between components took place.

NOTE: If you do not remember difference between stub and mock
please read [this Martin Fowler article](https://martinfowler.com/articles/mocksArentStubs.html). 
In short mocks are used to test interactions between components 
(a method was called, a property was set) 
while stubs are used as dumb implementations of component dependencies 
(they usually either do nothing or provide some preset data).

But recently, after reading volume 1 of 
[Elegant Objects](https://www.yegor256.com/elegant-objects.html)
which by the way I strongly recommend, I changed my mind.
In one of the chapters author presents the idea that every interface
should have an associated fake object. A fake object is a simple
but *working* implementation of an interface and resides in the same
source code file as the interface itself.
Fake objects serve two purposes. First, they are example implementations
of interfaces that show users how the interfaces should be implemented.
And second they can be used as stubs and mocks in unit-tests.

Of course this idea seemed a bit extreme to me, so I decided to go with
a bit more evolutionary approach.
I **slowly** replaced all mock object that I had in my unit-tests 
with fakes (I put all fakes in my unit test projects - but I am still thinking that maybe they deserve a project of their own). 
During this process all interaction testing assertions 
that are usually performed using mocking frameworks
were replaced by behaviour testing assertions on fake objects.

It will be the best to illustrate this process using an example.
Say we have a simple component `EventPublishingComponent` that
publishes two events (order is not important):
{% highlight csharp %}
public class EventPublishingComponent {
    private readonly EventPublisher _eventPublisher;
    public EventPublishingComponent(EventPublisher eventPublisher)
        => _eventPublisher = eventPublisher;

    public async Task Publish() {
        await _eventPublisher.Publish(new FirstEvent(id: 3));
        await _eventPublisher.Publish(
          new SecondEvent(id: "ZDKA9JOPCKXI7"));
    }
}

public class FirstEvent : Event {
    public int Id { get; }
    public FirstEvent(int id)
        => Id = id;
}

public class SecondEvent : Event {
    public string Id { get; }
    public SecondEvent(string id)
        => Id = id;
}

public interface EventPublisher {
    Task Publish(Event @event);
}

public interface Event { }
{% endhighlight %}
A "classic" unit test for this component using NSubstitute 
could look like this:
{% highlight csharp %}
public class EventPublishingComponentTest {
    private readonly EventPublisher _eventPublisher;
    private readonly EventPublishingComponent _component;

    public EventPublishingComponentTest() {
        _eventPublisher = Substitute.For<EventPublisher>();
        _component = new EventPublishingComponent(_eventPublisher);
    }

    [Fact]
    public async Task Should_publish_FirstEvent() {
        // Arrange
        FirstEvent firstEvent = null;
        await _eventPublisher
            .Publish(Arg.Do<FirstEvent>(e => firstEvent = e));

        // Act
        await _component.Publish();

        // Assert
        await _eventPublisher.Received(1)
            .Publish(Arg.Any<FirstEvent>());

        Check.That(firstEvent)
            .IsNotNull();

        Check.That(firstEvent.Id)
            .IsNotZero();
    }
}
{% endhighlight %}
I am sure you have seen a lot of tests like this. 
The key points are: Your create mocks and stubs using your
favourite mocking library in the test constructor or setup method.
In the arrange (given) part of the test you define mocks and stubs
behaviour using library specific syntax. Here e.g. we are capturing
argument passed to `Publish` method for later use:
{% highlight csharp %}
FirstEvent firstEvent = null;
await _eventPublisher
    .Publish(Arg.Do<FirstEvent>(e => firstEvent = e));
{% endhighlight %}
In the assert (then) part of the test we use again library specific
syntax to check that a method on a mock 
was called with given set of arguments.

This approach is fine but it has some disadvantages:

1. It makes your tests very brittle. For example if I add a new method
 on `EventPublisher` called 
 `PublishAll(events)` that allows me to publish all events at once and
 refactor `EventPublishingComponent` to use it
 then `EventPublishingComponent` tests would stop working.
 The main problem here is that my tests check internal interaction
 between components 
 (was method `Publish` called?) instead of checking external behaviour 
 of the system (was event published?).

2. Mocking library is another tool that you must learn. 
 And please remember that most of the developers are not too eager to
 read documentation. Time presumably saved by using mocking library 
 will be lost on reading StackOverflow answers and on fighting with
 the library itself 
 (ever have a problem that your stub does not return intended value?). 

3. It makes your tests less readable. I must admit that 
 NSubstitute is a huge improvement over Moq in terms
 of readability but it still introduces a lot of visual noise in the test
 code. For example do see all 
 those `<`, `>`, `(` and `)` in the code below:

{% highlight csharp %}
FirstEvent firstEvent = null;
await _eventPublisher
    .Publish(Arg.Do<FirstEvent>(e => firstEvent = e));
{% endhighlight %}

Now let us see how our test can look like if we use fakes instead:
{% highlight csharp %}
public class EventPublishingComponentTest_UsingFakes {
    private readonly InMemoryEventPublisher _eventPublisher;
    private readonly EventPublishingComponent _component;

    public EventPublishingComponentTest_UsingFakes() {
        _eventPublisher = new InMemoryEventPublisher();
        _component = new EventPublishingComponent(_eventPublisher);
    }

    [Fact]
    public async Task Should_publish_FirstEvent() {
        // Act
        await _component.Publish();

        // Assert
        var firstEvent = _eventPublisher.PublishedEvents
            .OfType<FirstEvent>()
            .SingleOrDefault();

        Check.That(firstEvent)
            .IsNotNull();

        Check.That(firstEvent.Id)
            .IsNotZero();
    }
}
{% endhighlight %}
To make this test compile we also need to write a fake for 
`EventPublisher` interface. Please keep in mind that fake is a simple
but **working** implementation of the interface:
{% highlight csharp %}
public class InMemoryEventPublisher : EventPublisher {
    private readonly List<Event> _publishedEvents 
      = new List<Event>();

    public IReadOnlyList<Event> PublishedEvents
        => _publishedEvents;

    public Task Publish(Event @event) {
        if (@event == null)
            throw new ArgumentNullException(nameof(@event));

        _publishedEvents.Add(@event);
        return Task.CompletedTask;
    }
}
{% endhighlight %}

I am sure that after seeing both versions of the test 
you agree with me that both are quite short and readable,
yet the second version does not have the earlier mentioned disadvantages.
Now you may rightly say that with the second approach 
you are forced to create fakes for
almost all interfaces in your application. You are right, but
you actually want to create fakes. Here is why:

1. Fakes are like TDD for your interface **design**. By creating a fake
 you actually check how difficult it is for a client 
 of your API to provide an implementation. A fake too big or 
 too difficult to
 implement is a sign that maybe your interface is doing too much.
 Also fakes can be treated as "reference implementations" of interfaces
 and as such they are part of your API documentation.

2. Writing a fake is a one-time effort. After fake is written it can
 be reused across many tests. Compare this with subs and mocks that you
 need to setup every time you want to use them.

Now it is time for a more real world example. 
As you probably heard *Performance is a feature* but logging can 
also be a feature. Imagine an application where we must log
every failed login attempt. Since this is a business requirement
we want to code it as an acceptance test.
How difficult it can be to check that one method call was
performed:
{% highlight csharp %}
logger.LogDebug("User '{userName}' log into application.", "root");
{% endhighlight %}
In practice it can be more difficult than it seems especially if you use
notoriously hard to test `ILogger` from `Microsoft.Extensions.Logging.Abstractions` package.

Why is `ILogger` hard to test? 

1. `ILogger` interface contains only three methods 
 ([source code here](https://github.com/aspnet/Logging/blob/master/src/Microsoft.Extensions.Logging.Abstractions/ILogger.cs))
 rest of its functionality is provided via extension methods.

2. Extension methods that operate on `ILogger` often 
 create wrappers around original 
 arguments using classes like `FormattedLogValues`.
 Most of these wrapper classes does not 
 overload `Equals` and `GetHashCode` rendering
 argument matchers from mocking frameworks useless.

3. No easy access to the logged message.
 Only method responsible for actual logging on `ILogger` interface
 is `Log`:

{% highlight csharp %}
void Log<TState>(
  LogLevel logLevel, 
  EventId eventId, 
  TState state, 
  Exception exception, 
  Func<TState, Exception, string> formatter);
{% endhighlight %}

To gain access to the logged message we must either dig 
into `state` argument
or call `formatter(state, exception)`.

All this causes that naive testing aproachs like this fail:
{% highlight csharp %}
[Fact]
public async Task Naive_test() {
  var logger = Substitute.For<ILogger<SomeClass>>();
      
  logger
    .LogDebug("User '{userName}' log into application.", "root");

  logger.Received()
    .LogDebug("User '{userName}' log into application.", "root");
}
{% endhighlight %}
And how they fail? With confusing error messages like this one:
{% highlight no-highlight %}
Error Message:
 NSubstitute.Exceptions.ReceivedCallsException : 
  Expected to receive a call matching:
  Log<Object>(Debug, 0, User 'root' log into application., <null>, Func<Object, Exception, String>)
Actually received no matching calls.
Received 1 non-matching call 
 (non-matching arguments indicated with '*' characters):
  Log<Object>(Debug, 0, *User 'root' log into application.*, <null>, Func<Object, Exception, String>)
{% endhighlight %}
Not very helpful, isn't it?

If you really want to test `ILogger` using NSubstitute you must
use the following code:
{% highlight csharp %}
var logger = Substitute.For<ILogger<SomeClass>>();

dynamic state = null;
Exception exception = null; 
Func<object, Exception, string> formatter = null;

logger.Log(LogLevel.Debug, 
  Arg.Any<EventId>(), 
  Arg.Do<object>(s => state = s), 
  Arg.Do<Exception>(ex => exception = ex), 
  Arg.Do<Func<object, Exception, string>>(f => formatter = f));

logger
  .LogDebug("User '{userName}' log into application.", "root");

logger.Received(1)
  .Log(LogLevel.Debug, 
      Arg.Any<EventId>(), 
      Arg.Any<object>(), 
      Arg.Any<Exception>(), 
      Arg.Any<Func<object, Exception, string>>());

Check.That(formatter(state, exception))
    .IsEqualIgnoringCase("User 'root' log into application.");
{% endhighlight %}
Did I say something earlier about unreadable tests and a lot of 
visual noise caused by mocking frameworks? Now you can see it with your
own eyes!

Now it is time for our second approach using fakes. First we create
a fake logger:
{% highlight csharp %}
public class InMemoryListOfEntriesLogger : ILogger {
    private readonly List<LogEntry> _loggedEntries 
      = new List<LogEntry>();

    private readonly Dictionary<string, int> _bookmarks 
      = new Dictionary<string, int>();

    public IReadOnlyList<LogEntry> LoggedEntries 
        => _loggedEntries;

    public IDisposable BeginScope<TState>(TState state) {
        // Notice that we do not have to implement
        // all methods for interfaces that are *not
        // part* of our application.
        throw new NotImplementedException();
    }

    public bool IsEnabled(LogLevel logLevel) {
        return true;
    }

    public void Log<TState>(
        LogLevel logLevel, 
        EventId eventId, 
        TState state, 
        Exception exception, 
        Func<TState, Exception, string> formatter) 
    {
        _loggedEntries.Add(
          new LogEntry(
            logLevel, 
            formatter(state, exception), 
            exception));
    }
}

public class LogEntry {
  public LogLevel LogLevel { get; }
  public string Message { get; }
  public Exception Exception { get; }

  public LogEntry(LogLevel logLevel, string message, 
    Exception ex = null) {
      LogLevel = logLevel;
      Message = message;
      Exception = ex;
  }

  public override string ToString()
      => $"{LogLevel}: {Message}" + 
         (Exception != null 
            ? $" Exception: {Exception.GetType().Name}" 
            : "") +
         ".";
}
{% endhighlight %}
Notice that we did not implement all methods of `ILogger` interface.
For external interfaces that are not under our control we should
implement just enough functionality in our fakes to make them usable.

Now it is time for writing actual test:
{% highlight csharp %}
var logger = new InMemoryListOfEntriesLogger();

logger.LogDebug("User '{userName}' log into application.", "root");

Check.That(logger.LoggedEntries)
    .HasElementThatMatches(x => 
        x.Level == LogLevel.Debug &&
        x.Message == "User 'root' log into application.");
{% endhighlight %}
Wow! Test is short, readable and simple. Exactly what I was looking for.

I hope that this blog post persuaded you to start using fakes in your
unit tests. At least you now know that you have a good alternative to
mocking frameworks.

Sample source code (with a bit more complicated example): 
[GitHub](https://github.com/marcin-chwedczuk/blog-fakes-vs-mocks).


	  ]]></description>
	</item>

	<item>
	  <title>How NOT to use the repository pattern</title>
	  <link>//repository-pattern-my-way</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2018-07-08T02:00:00+02:00</pubDate>
	  <guid>//repository-pattern-my-way</guid>
	  <description><![CDATA[
	     ### Generic repository pattern

First, to avoid misunderstandings, let me explain what I understand
by generic repository. Have your ever seen an interface like this:
{% highlight csharp %}
public interface IGenericRepository<TEntity> 
    where TEntity : class 
{
    IEnumerable<TEntity> Get(
        Expression<Func<TEntity, bool>> filter = null,
        Func<IQueryable<TEntity>, IOrderedQueryable<TEntity>> orderBy = null,
        string includeProperties = "");
    TEntity GetById(object id);

    void Insert(TEntity entity);

    void Update(TEntity entityToUpdate);

    void Delete(object id);
    void Delete(TEntity entityToDelete);
}
{% endhighlight %}
Or maybe you saw it's twin brother that have a slightly 
different variant of `Get` method:
{% highlight csharp %}
IQueryable<TEntity> GetAll();
{% endhighlight %}

Inspiration for the first of these examples comes from 
[official Microsoft documentation for ASP.NET MVC 4](https://docs.microsoft.com/en-us/aspnet/mvc/overview/older-versions/getting-started-with-ef-5-using-mvc-4/implementing-the-repository-and-unit-of-work-patterns-in-an-asp-net-mvc-application#implement-a-generic-repository-and-a-unit-of-work-class).
As for the second example you can find countless number of blogs that
describe this variant of the repository pattern e.g.
[here](http://www.tugberkugurlu.com/archive/generic-repository-pattern-entity-framework-asp-net-mvc-and-unit-testing-triangle),
[and here](https://deviq.com/repository-pattern/),
[and also here](https://www.codeproject.com/Articles/814768/CRUD-Operations-Using-the-Generic-Repository-Patte)
sometimes with slight variantions like returning `IEnumerable<TEntity>` instead of
`IQueryable<TEntity>`. 
And in the later case often with an additional method for generating
queries like:
{% highlight csharp %}
IEnumerable<T> FindAll(Expression<Func<T, bool>> predicate);
{% endhighlight %}

So what is wrong with them you may ask? So far almost nothing,
not counting of course badly naming of the methods from Microsoft example(
they should be called `Find` and `FindAll` not `Get` and `GetAll`).

But "almost nothing" does not equal "nothing". One problem that I find with
these interfaces is that they violate Interface Segregation Principle.
They expose full set of CRUD operations even for entities for which 
e.g. deleting does not make sense (for example when you deactivate users
instead of deleting them from DB;
also see [Udi Dahan post about deleting data](http://udidahan.com/2009/09/01/dont-delete-just-dont/)).
But this problem can be easily solved by splitting this interface into three -
one for reading, one for updating and one for deleting entities.

The real problem that I have with these interfaces comes from their *improper*
usage. The original idea behind them is that they should be used as a base
interfaces for your custom repository interfaces, just like this:
{% highlight csharp %}
public interface IFooRepository : IGenericRepository<Foo> {
    Foo FindNewest();
    IEnumerable<Foo> FindAllOutdated();
}
{% endhighlight %}
And that your command handlers and services 
(in other words clients of your custom repositories) 
should decide what methods are
needed and should be put on your custom repository interfaces.

That is the theory. Unfortunately what I already saw a few times in my career 
instead is this:
{% highlight csharp %}
// notice: this is NOT an abstract class
public class GenericRepostiory<TEntity> : IGenericRepository<TEntity> {
    // implementation details skiped

    public IQueryable<TEntity> GetAll() { /* code */ }
    public TEntity GetById(object id) { /* code */ }

    public void Insert(TEntity entity) { /* code */ }
    public void Update(TEntity entityToUpdate) { /* code */ }

    public void Delete(object id) { /* code */ }
    public void Delete(TEntity entityToDelete) { /* code */ }
}
{% endhighlight %}
Someone has created a working implementation of `IGenericRepostory` interface.
What is worse this implementation is almost always registered in IoC container and
can be injected into your command handlers and
services like any other dependency:
{% highlight csharp %}
public class OrderService {
    private readonly IGenericRepository<Order> _orderRepository;

    // ctor and other stuff...

    public NewestOrderDto FindNewestOrderForCurrentUser() {
        var newestOrders = _orderRepository.GetAll()
            .Where(order => order.AssignedTo.Id == _currentUser.Id)
            .Where(order => order.State != OrderState.Closed)
            .OrderByDescending(order => order.CreationDate)
            .Take(10)
            .ToList();

        return _mapper.MapTo<NewestOrderDto>(newestOrders);
    }
}
{% endhighlight %}

This *looks* nice and clean but is not. I will tell you more about why
this is wrong later. Now I want to deal with one "solution" to the
`GenericRepository<T>` misinterpretation that 
I often hear from other developers. 
This solution sounds like this (dialog during code-review):

JIM SENIOR: Have you ever heard that
NHibernate `ISession` or Entity Framework `DbSet` *is a* repository?
Indeed what you just created is a tin wrapper over either 
`ISession` or `DbSet`.
Actually we can replace this `GenericRepository<T>` by e.g.
`DbSet` and get pretty must the same results.
The only service that `IGenericRepository<T>` provides is that it hides
most of the thirty methods that `DbSet` has. 
JONNY JUNIOR: Oh, indeed what you just said make sense.
I guess using generic repository
pattern here was a bit of overengineering. (Happily gets back to coding...)

For me using either `GenericRepository<T>` or raw `DbSet` is wrong most of the
time (one exception that I can accept is when you write 
the most CRUDest application ever, then don't bother
and use `DbSet` in your services). And why? Due to the following reasons:

- The only option to make sure that your LINQ queries will be properly translated
 to SQL is to test them against **the same** kind of database that you use 
 in production environment. But when your queries are scattered over methods 
 of your services it may be hard to create integration tests for them.
 For example look at the code:

{% highlight csharp %}
if (/* some complicated condition */) {
	if (/* some other complicated condition */) {
		 var result = _orderRepository.GetAll()
			  .Where(order => order.AssignedTo.Id == _currentUser.Id)
			  .Where(order => order.State != OrderState.Closed)
			  .OrderByDescending(order => order.CreationDate)
			  .Take(10)
			  .ToList(); 

		 return _mapper.MapTo<NewestOrderDto>(newestOrders);
	}
	// some code here
}
// more code here
{% endhighlight %}

To execute above query you must fulfill two if's conditions. This will make
an integration test for the above query less readable and more fragile. 
Instead imagine that this query is encapsulated by a repository method.
In integration test you would just call that repo method and check the 
results - simple isn't it?

- I am sure that you agree with me 
 that inline LINQ queries inside services 
 are not reusable and that they have a nasty tendency to
 duplicate themselves over the codebase. Even when a programmer decides to
 extract query to it's own method, it will usually be a private method on 
 a particular service. Moving queries to repository 
 methods makes them automatically reusable
 across entire application. 

- Inline LINQ queries are not named. Usually the only clue what a particular
 query does (without going deep it's logic) is the name of the variable that
 holds query result. Unfortunately for us inventing a good variable names is a skill
 that only comes with the experience and since we have a lot of junior devs in our 
 industry we are faced with names like `result`, `ordersToProcess` or just `orders`.
 Wrapping the query inside a repo method will automatically give it a name. 
 Even if this name is not perfect we can refactor it later and all places 
 that call this method will benefit from our refactoring automatically!

- Sometimes for performance reasons we are forced to use raw SQL to get our
 data from DB. Do you really want to litter your business logic with low
 level technical stuff like `DbConnection`s, query parameters and `SqlException`s?
 Let's hide this low level stuff inside a repository and let our business code 
 concentrate on business logic. Also see 
 [Single level of abstraction principle](http://principles-wiki.net/principles:single_level_of_abstraction).

So what is the solution you may ask? Get ready...

### What we need is the "specific" repository pattern

We should start repository design by specifying it's interface. 
The interface should contain only methods required by clients of 
the repository. In other words if nobody needs to delete entities of a given type
or it does not make sense from business point of view
we will not add `Delete` method to the interface.

If you are afraid that you will end up with different names for
basic CRUD operations like `Delete` on one repo and `Remove` on the other
you may create helper interfaces like `ICanDeleteEntity<TEntity>`,
`ICanUpdateEntity<TEntity>` etc. that will contain only methods for
specific usage like deleting, updating etc. 
Then the repository interface can inherit 
appropriate subset of them.

None of the methods on the repository interface should return `IQueryable<T>`
type.
Also make sure that the repository implementation does not 
return `IQueryable<T>` value hidden as `IEnumerable<T>` one. 
Always call `ToList()`
or `ToArray()` to materialize query results before returning them 
to the client.

When it comes to the repository implementation, the implementation is free
to inherit from *abstract* `GenericRepository<TEntity>` base class. 
Alternatively it may use `ISession` or `DbSet` directly if it is more convenient. 
No matter what approach you choose remember that "excessive" methods
like `Delete`
inherited from base class
may be hidden by the repository interface.

Please remember that your repository is NOT responsible for managing
database transactions. This concern is best managed using 
[Unit of Work pattern](https://martinfowler.com/eaaCatalog/unitOfWork.html).
This pattern is already implemented by both `ISession` and `DatabaseContext`
(think change tracking and dirty checking),
we only need a better interface over them:
{% highlight csharp %}
public interface IUnitOfWork {
    // or just Begin()
    void BeginTransaction();

    void Commit();
    void Rollback();
}
{% endhighlight %}

For the most web applications it is enough to start transaction using `IUnitOfWork`
at the beginning of the HTTP request and either `Commit` or `Rollback` at
the end of the request. This can be done by using either an action filter
or a decorator around command handlers and/or services. 

Example repository created using the above guidelines:
{% highlight csharp %}
public interface IOrderRepository {
	// We do not need FindById so we do not included it
	IEnumerable<Order> FindActiveOrdersAssignedToUser(UserId id); 
}

public class OrderRepository : GenericRepository<Order>, IOrderRepository {
    public IEnumerable<Order> FindActiveOrdersAssignedToUser(UserId id) {
        return base.FindAll()
                .Where(order => order.AssignedTo.Id == id.Value)
                .Where(order => order.State != OrderState.Closed)
                .ToList();
    }
}
{% endhighlight %}

This should be obvious by now, but let's not take chances.
Every method of our repositories should be covered by one or more
integration tests, which should use the same kind of DB that we use 
in production environment. Remember always use *integration* tests to
test your repositories.

### Turbocharging the repository pattern

There is no rose without thorns and presented above approach also has some
serious drawbacks. Some of them can be fixed by using a different
architecture than classic 3-layer arch.
Most common problems with "specific" repositories are as follows:

- Repositories can over long periods of time accumulate 
 dozens and dozens of `Find*` methods. Often these methods will be very similar
 to each other. There are two ways to combat this unwanted grow. One is to use 
 a query object pattern. Basically you group several of these `Find*` methods together
 into one more general `Find` method. That method should accept an object that will
 represent a query criteria. For example:

{% highlight csharp %}
var ordersToCancel = _orderRepository.FindAllMatching(
	// Alternatively you may use the builder pattern
	// to create a criteria object.
	new OrderCriteria {
		StatusIsIn = new[] { OrderStatus.New, OrderStatus.InProgres },
		OrderedItemsContainAll = new[] { searchedItem },
		CustomerIs = GetCurrentCustomer()
	});
{% endhighlight %}

To create a query from the criteria object we examine each search criteria and
build query step-by-step:
{% highlight csharp %}
IQueryable<Order> q = base.FindAll();

if (criteria.StatusIsIn != null) {
	q = q.Where(o => criteria.StatusIsIn.Contains(o.Status));
}

// A long list of other conditions here..

return q.ToList();
{% endhighlight %}

A closely related yet different aproach is to use the query object pattern (see 
[this](https://martinfowler.com/eaaCatalog/queryObject.html) and
[this](https://lostechies.com/jimmybogard/2012/10/08/favor-query-objects-over-repositories)).

The second solution to this problem is more robust and reliable.
Usually too big repositories are accompanied by huge services and 
overgrown entities. You can slim down both your repos and services 
by using something that I call CQRS-light. It differs from full-blown
CQRS by using exactly the same database tables for both reads and writes.
When doing CQRS-light we can use the same ORM framework for both reading and
writing data and slowly migrate to real CQRS only in these parts of our
application that really need it (do recall this 80+ columns searchable grid that
generates 20+ inner join query that halts your DB server? - real CQRS can help here).

The diagram below presents typical architecture of CQRS-light application:
![CQRS-light architecture](assets/images/2018-07-08/cqrs-light.svg)

The key principles of CQRS-light are:

- Split all user actions into two categories. In the first put all actions that
 can modify the state of the system like e.g. creating a new order in an e-commerce app.
 In the second  
 category put all actions that do not modify state of the system e.g. 
 viewing an order details. First category represents commands (writes), the second one
 queries (reads). Only commands can change state of the system.

- Query handlers do NOT use repositories to access data. They access DB 
 using whatever technology they want.
 Usual configurations include a single ORM on both read and write sides, 
 ORM for writes and micro-ORM like Dapper for reads or 
 using ORM for writes and raw SQL for reads.

- Command handlers can only use repositories to access and modify data. 
 Command handlers 
 should not call query handlers to fetch data from database. 
 If a command handler needs to execute 
 a complex query and this query can be answered by a query handler
 you should duplicate this query logic and put it
 in both query handler and in a repository method
 (read and write sides must be separated).

- Query handlers are tested only using integration tests.
 For command handlers you will have unit and optionally integration tests.
 Repositories will be tested using integration tests.

CQRS even in the "light" version is a huge topic and deserves a blog post of it's own.
[MediatR](https://github.com/jbogard/MediatR) library is a good starting point
if you want to find out more about CQRS-light approach.

Let us return to the subject of the "specific" repository pattern drawbacks. 
The second drawback that I want to mention is unwanted migration of the business
logic into query definitions. For example even this simple query:
{% highlight csharp %}
public IEnumerable<Order> FindActiveOrders() {
  return base.FindAll()
          .Where(order => order.State != OrderState.Closed 
                       && order.State != OrderState.Canceled)
          .ToList();
}
{% endhighlight %}
contains a piece of business logic that describes what 
it means for an order to be active.
Usually ORM's prevent us from encapsulating such pieces of logic
into a separate properties like `IsActive`.

What we need here is the specification pattern.
You can find pretty decent overview of the specification pattern
[here](https://enterprisecraftsmanship.com/2016/02/08/specification-pattern-c-implementation/).
Our query method when we use the specification pattern should look similar to:
{% highlight csharp %}
public IEnumerable<Order> FindActiveOrders() {
  return base.FindBySpec(new ActiveOrders())
          .ToList();
}
{% endhighlight %}



	  ]]></description>
	</item>

	<item>
	  <title>Devoxx Poland 2018</title>
	  <link>//devoxx-poland-2018</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2018-06-25T02:00:00+02:00</pubDate>
	  <guid>//devoxx-poland-2018</guid>
	  <description><![CDATA[
	     [Photo above shows Mr. Jakub Nabrdalik during his presentation about TDD 
in main conference room.]

### About conference

Thanks to my employer [CyberVadis](https://cybervadis.com/) I was able to
attend Devoxx Poland 2018 conference. The conference took place in
Cracow (Poland) and lasted three days (20 - 22 June).

Overall my experience with the conference was very good.
Things that I particularly liked were: good coffee, tasty muffins and
beautiful and very comfortable venue ([Cracow ICE](http://www.icekrakow.pl/)).

Things that organisers could have done better: on the first day of the 
conference it was difficult to find the right rooms (especially room no. 5). 
Rooms should be marked in a more outstanding way. Quality of
food served during lunches was
only mediocre, I expected something better. Conference offered a lot of
presentation still the number of presentation on advanced topics were limited.
I expected to see more advanced stuff there.

Conference keynote presentation was amazing. 
The speaker Mr. Brian Christian told us about application of
theoretical computer science stuff to everyday problems.
Presentation was based on Mr. Brian book 
[Algorithms to Live By](http://a.co/dYsQtCb).
I already ordered my own copy ;)


### My notes from presentations

Below you can find digitalized version of my notes that I took during
presentations. Remember that they are my **personal** notes mostly created for
my colleagues that couldn't attend the conference. Use them at your own risk.

#### State or events? Which shall I keep? by Jakub Pilimon

- You can find most of the topics addressed by Mr. Jakub in his blog
 post 
 [Event Storming and Spring with a Splash of DDD](https://spring.io/blog/2018/04/11/event-storming-and-spring-with-a-splash-of-ddd).
- ORM's can introduce 
 [accidental complexity](https://en.wikipedia.org/wiki/No_Silver_Bullet) into
 our applications. Example: loading a list of child
 objects when we only need
 to check number of objects (we are just calling `.size()` on the list)
 can cause performance bottlenecks when we are using ORM to persist
 our aggregates.
- Persisting aggregate state as a list of events is not only simpler
 but also much more aligned with DDD design.
- You should prefer returning domain events from aggregate instead of
 publishing them (no more `EventPublisher`s in aggregates). For example:

{% highlight java %}
public class MyAggregate {
    private final List<DomainEvent> pendingEvents = new ArrayList<>();
    public List<DomainEvent> getPendingEvents() {
        return pendingEvents;
    }
    public void flushEvents() {
        pendingEvents.clear();
    }
    public performOperation() {
        // do some stuff
        NameChangedEvent event = 
           new NameChangedEvent("old-name", "new-name");

        pendingEvents.add(event);
        applyEvent(event);
    }
    // ...
}

public class MyAggregateRepository {
    public MyAggregate load(UUID id) {
        List<DomainEvents> events = eventStore.loadEventsById(id);
        MyAggregate aggr = MyAggregate.recreateFrom(id, events);
        return aggr;
    }
    public void save(MyAggregate aggr) {
        eventStore.appendEvents(aggr.getId(), aggr.getPendingEvents());
        aggr.flushEvents();
    }
}

// later usage:
var aggr = repo.load(id);
aggr.performOperation();
repo.save(aggr);
{% endhighlight %}

This method of returning events from aggregate root is nothing new.
Variations of this approach appeared as early as in 2013, [for example here](https://blog.jayway.com/2013/06/20/dont-publish-domain-events-return-them/).

- (My question after talk) You should not confuse domain events used
 to store aggregate state from integration events. Generally it is a
 bad practice to publish to other systems events used to persist aggregate.
 Mostly because you may expose state that should be private to aggregate.

- (My question after talk) How to deal with GDPR when using immutable
 event store? You should try to keep sensitive data outside of domain events.
 Later I checked that this approach was described [here](https://twitter.com/mathiasverraes/status/927484596396199937?lang=en). 

As an alternative approach you may use encryption as described [here](https://www.michielrook.nl/2017/11/forget-me-please-event-sourcing-gdpr/).
But for some reason I find this solution ugly.

- (Someone else's question) It is fine to use SQL databases to store domain events (at least at the
 beginning). So if you want to start your adventure with event sourcing
 use your old tried SQL db!

Overall it was a good presentation but mostly directed at the
beginners. 

You can find Jakub Pilimon blog and twitter here:

- [Blog](https://pillopl.github.io/)
- [Twitter](https://twitter.com/JakubPilimon)

#### From availability and reliability to chaos engineering. Why breaking things should be practised by Adrian Hornsby 

- Jesse Robbins is one of the fathers of Chaos Engineering 
 (see [this](https://www.youtube.com/watch?v=zoz0ZjfrQ9s) video from 2011).
- Generally we break things in production to build confidence that
 we can quickly fix real problems.

Introducing Chaos Engineering into organisation:

- Start small. Only break things in production that you are sure are 
 able to survive your "experiments". 
- First make your application resilient then test that resiliency.
 Do NOT do Chaos Engineering experiments in production that you are sure
 will kill your app.
- Test not only infrastructure but also people. If say Bob
 solves 90% of problems on production, check what will happen if other
 team members must solve such problems without Bob.

My note: I cannot resist myself from calling this technique a "bus monkey".

- Remember: **Chaos doesn't cause problems it reveals them**
- Areas to test: people, applications, network and data, infrastructure

Increasing resiliency:

- Availability is measured in "nines", e.g. four nines is 99.99%, 
 six nines is 99.9999% of time on which application works.
- four-nines is an industry standard (as of 2018)
- Easiest way to increase availability is to create multiple copies of
 the least reliable resources. If for example you have a single 
 server that has 90% of 
 availability, having two such servers working in parallel 
 will create a system with availability of 99%.
- When you are hosting your apps in the cloud remember to use multiple 
 availability zones (AWS lingo).
- Use auto-scaling.
- Follow infrastructure as code approach to achieve testable infrastructure.
- Your infrastructure should be immutable. Never update servers always
 create new instances and remove old one.
- Practice rolling deployments. After a fresh deploy of an application
 do NOT kill old servers immediately. Allow them to say for a while as
 a standby - just in case when your new app version will not work they
 will allow you to quickly rollback your changes.
- Never put all your databases on the same server. Use sharding to spread
 data across many databases.
- Prefer messaging to HTTP requests, message queues are more resilient.
 Send commands instead of issuing HTTP requests.
- When using HTTP remember to use circuit breaker library.
 Use exponential backoff algorithm.
- Remember about DNS (DNS failover, smart load balancing).
- Transient state is a state that is constantly changing, like
 webpage view counters or ad clicks counters. Do not put transient 
 state into database, 
 instead use specialized solutions like Redis to keep it.
- Use async UI, do not wait for operation to finish, display notification
 to the user when operation succeeds or fails. See: 
 [Stop Getting In My Way! — Non-blocking UX](https://medium.com/@sophie_paxtonUX/stop-getting-in-my-way-non-blocking-ux-5cbbfe0f0158)

Chaos Engineering in Practice:

- Chaos Engineering is like a fire drills. You are doing it so that
 people will be prepared for a real fire and will not panic.
- Without exercises people will get scary when dealing with real issues
 on production.
- How to start? Start by defining *steady state* of your application.
 In other words define when you assume that your application is working.
 For example when you have an online shop, you may assume that your 
 application is working when people click "Buy" button a certain number of 
 times per hour. This will be a steady state of your application that
 you will monitor during chaos engineering experiments to make sure
 that application is still working.
- Generally you should use business metric to define steady state.
 Measure things that bring you money!
- Define experiments. What if our DB server stops working?
 What if we have a huge spike in traffic?
- Only try to break things that you are 100% sure should not break
 (otherwise make your application resilient first).
- During chaos experiments always have an emergency stop button so that
 you can stop your experiment at any time.
- Start small! (yeah again, looks like this is very important)
- Experiment with canary deployments e.g. run experiments on 1% of total
 traffic
- Quantify results. How much time elapsed from the failure to detection of 
 that failure? How much time did it take to fix it?
 Is our monitoring working properly? Does notification (pager duty) system
 works correctly?
- Never blame a single person, instead concentrate on things that 
 you can improve.

General tips:

- During post mortems use Rule of 5 Why. 
 Why it broke? Because of X. Why X happened? Because of Y.
 Why Y happened? ... (repeat 5 times)
- Be patient.
- Be aware of cultural blocks (especially among business people).
 Generally do not tell business people that you want to 
 break your application.
 Remember chaos reveals problems not causes them.

Overall this was a very good presentation with a bit of AWS advertisement.

You can find Adrian Hornsby twitter here:

- [Twitter](https://twitter.com/adhorn)

#### Through the valley of darkness, the road to microservices by Dominik Boszko

- Ask yourself if you get any of the benefits that
 microservice architecture promised you.
- Signs that you are working with distributed monolith:
  * Change in one microservice propagates to others
    e.g. I return additional field from some REST endpoint in service A,
     but may application will start working only when I recompile service B.
  * There is too much communication going on between teams.
  * Change in service A that is managed by my team requires approval from
    some other team
- When working with microservices Don't Repeat Yourself rule is considered
 harmfull. Microservices should be as independent from each other as possible.
- Avoid coupling between microservices. Do NOT create libraries with shared
 REST DTO's or events that will be used by many services.
 Instead introduce contracts (use tools like Swagger). 
 Each service should contain it's own copy of consumed DTO's and events.
 These DTO's should contain only the fields that the service needs.
- Be wary of `Core`s, `Platform`s, `Common`s etc. libraries that are used
 by every microservice. Microservices should be independent of each other.
 In the best case scenario you will only share security and logging related code.
- Shared libraries are bad because of transitive dependencies.
 For example team A adds a dependency on SuperXmlParser-v2.0 to the core library.
 This breaks service B maintained by team B that is using SuperXmlParser-v1.0 library.
- When using microservice architecture role of software architect changes.
 Architect no longer can enforce his decisions on teams. Instead teams are
 self organizing and cross functional and they ultimately decide on the design 
 and architecture of the services that they own.
- Software architect should concentrate on high level concerns like security,
 integration with other applications and best practices. Think BIG PICTURE!
- Software architects should strive to avoid micromanagement (especially when they
 have only experience with monolithic application development).
- Do not be afraid to use different technologies and architectural styles for
 different microservices (this is one of the selling points of the
 microservice architecture after all).
- Teams should be aligned with bounded context. Teams should have a deep
 knowledge of their domains. Therefore teams are best equipped to make
 architectural decisions. This is the best usage of the top talent that
 you have hired.
- Avoid nanoservices (service that does the job of a single method).
- Do not rush into microservices. Think if you really needs benefits that
 this approach can offer you. Keep in mind additional complexity that
 comes with this approach.

This was one of the best presentations that I have seen on Devoxx.
It was based on personal experiences of Mr. Dominik. Good Job!

#### How to impress your boss and your customer in a modern software development company by Wojciech Seliga

- Modern software house is decentralized. People communicate with each other.
 Programmers talk to the client. Client can decide whom you should give a rise!
- A few more attributes of modern software company: short feedback loops,
 constant improvement (thank to feedback), autonomous teams, decentralized
 decision making, individual impact (every one feels that his job is important
 and that this person contributes significantly to the success of company).
- In other words: Customer becomes the new boss.
- How to impress your new boss? Deliver great stuff!
- Check out [How Google Works](http://a.co/93Pp6BM) book.
 It uses term *Smart creatives* to define modern knowledge workers.
 Smart creatives are not only tech but also business savvy.
 They are open, passionate persons that strive to learn something new
 every day. (My note: this sounds like some old school hackers to me).
- Smart creatives like to work on interesting problems.
 They also like to work with interesting people. They often
 have interesting and colorful lives.
- Negativity destroys people. It also destroys people's brains - so please
 don't be negative.
- Check out [Pragmatic Thinking and Learning](https://pragprog.com/book/ahptl/pragmatic-thinking-and-learning) book
- (My note: more motivational $#@!, I have nothing against it but I think this is
 not based on any scientific studies. It is just pop-psychology stuff 
 so believe it or not). Success is 10% talent, 90% hard work.
 Hard work beats talent when talent fails to work hard.
- Anyone who stops learning is already OLD (my note: I should better learn something
 from this presentation).
- Growth mindset. Prise for effort not for results (my note: more pop-psychology).

Questions for job interview that can test if person has growth mindset
and is a good candidate to become smart creative:

- What have you learned in your current job?
- How do you decide what to learn?
- What did you learn last month?
- What do you do to stay up to date with tech?
- What trends in technology did you miss?
- What challenges do you expect at your new job?
- How do you measure yourself and your progress?

Who is a senior developer?

- Primary role of a senior developer is to teach and mentor others.
- Senior developer should be a great example to others.
- Seniors should strive to build better environment for developers
 (no blaming each other, better dev processes, better and more friendly
  code review etc.)
- Being a senior developer is not about doing the same things as mid but
 faster.

More job interview questions:

- What could you teach me in 5 minutes?
- What do you do now differently than in the last 5 years?
- How did you impact other people?

Back to main topic again:

- Be the weakest person in the room (so that you will learn quickly).
- Being the best person in the room is bad for your professional development.
 You may not learn as much as you can.
- 1 year in a fast-paced environment is often better than 5+ years of experience
 in an average company.

More job interview questions:

- What is your best professional achievement?
- What is your top strength?
- What is your weakest point as a professional software developer?
- What are you doing about it?
- Why did you choose software development as your career?
- What are you passionate about?

Back to main topic again:

- Developers should be ready to take responsibility for the product they build.
- Developers that are already responsible may take ownership of their product.
- Passion is very important for smart creatives. Passion gives you intrinsic 
 motivation. Curiosity will force you to learn new things. Desire to change
 the words will make it happen.
- Modern software house is sliced vertically. Every team owns parts of the product
 and can do support, maintenance and  development. 
 Also each team can talk directly with the client and make it's own
 decisions.

Overall it was an interesting and good presentation but I have a feeling
that I just missed the point.

Mr. Wojciech [Twitter](https://twitter.com/wseliga?lang=en).

#### Docs in the self-documenting world by Wojtek Erbetowski

(my note: I was late so I missed a lot of interesting stuff here)

- Apply UX techniques like [personas](https://en.wikipedia.org/wiki/Persona_(user_experience)) and [user journey mapping](https://boagworld.com/usability/customer-journey-mapping/) to the documentation.
- Do not put code snippets into documentation. Instead link to a real 
 test or program source code. Especially linking to tests source code is
 advised, this way documentation will always will be up to date.
- A lot of tools like [AsciiDoc](http://mrhaki.blogspot.com/2014/04/awesome-asciidoc-include-partial-parts.html) can already do this.
- Writing a documentation should be a pleasure for developers.
- Example: library of React components was created as a React application.
 For each component a short description, real working component, example source code
 usage and a list of available properties is displayed.
- This library is actually generated for the source code of the components. 
 So it doesn't need to be maintained by developers and stays always up to date.
- Always think for whom you are creating the documentation.

#### Improving your Test Driven Development in 45 minutes by Jakub Nabrdalik

- Interesting article [Does TDD really lead to good design?](https://codurance.com/2015/05/12/does-tdd-lead-to-good-design/)

Common problems with tests:

- Too low level tests:
  - We have test for every single class in our project.
  - Tests knows too much about code that they are testing.
    Even minor refactorings of class API result in broken tests.

- Too high level tests:
  - We only have integration tests.
  - Tests are slow. Generally speaking integration tests that use even in memory
    DB like H2 are too slow for TDD cycle (people are losing flow).

- To have effective TDD cycle we should been able 
 to run a single unit test in less than 1 second.

The solution:

- Group your code into modules. Module API changes more slowly than
 class API. Test only module public API.
- A single module contains all application layers e.g. REST controllers,
 services, command handlers, repositories, database access etc.
 In other words modules are vertical slices of functionality.
- Module should be like a microservice.
- Integration tests are slow. Use integration tests only to test
 crucial paths through your application. Tests things that bring you
 money.
- It is OK to have many assertions in a single integration test.
- Module should expose a `ModuleConfiguration` class that can create a
 ready to use module that uses fakes to interact with other modules and IO.
- Prefer fakes to mocks and stubs. Use in memory repositories. Avoid doing IO
 at all costs in unit tests.
- Test only behaviour of the module using its public API.
- Use mocks only for interaction with other modules.
- Checkout this repo [https://github.com/olivergierke/sos](https://github.com/olivergierke/sos)

Towards better tests:

- Use business names (ubiquitous language) in the tests (and tests names too).
- Hide unnecessary information from test code (you should only show information
 that are relevant for this particular test).
- For each module create utility classes that provide real-like test data.
- Create a DSL for your tests.
- Prefer code to frameworks like Cucumber (business people don't use it anyway).
- Spock is a very good testing framework for Java.
- You may use shared immutable (read only) DB with test data to test 
 e.g. repositories - this way you can speed up your integration tests.

Mr. Jakub Nabrdalik twitter and blog:

* [Twitter](https://twitter.com/jnabrdalik?lang=en)
* [Blog](http://blog.solidcraft.eu/)

If you want to learn more about Mr. Jakub way of doing modules
please see his [demo project](https://github.com/jakubnabrdalik/hentai) on GitHub.

#### Modules or Microservices? by Sander Mak

For this presentation I will not provide notes. Instead I am going to 
express my views on arguments used by Mr. Sander.

Mr. Sander believes that developing applications using microservice
architecture is much more difficult than developing a monolithic software.
Also Mr. Sander believes that microservice architecture moves so called
"wall of unmaintainability" further from us (we may add more features to
the application before it becomes unmaintainable in therms of cost).
I fully agree with these both statements.

Now the things that I disagree with. Mr. Sander proposes a modular architecture
(monolith split into modules) as a silver bullet that will allow us to reap
most of the benefits of microservices will still preserving simplicity of
development. Unfortunately in his presentation some disadvantages of this
approach were not mentioned, like:

- Slow build and testing. Slow deploy. (It is still a monolith just with a better
 code organization.)
- A minor error in a single unimportant module 
 can break entire application.
 For example large numbers of unclosed files,
 memory leaks or stackoverflow exceptions can break (depending
 on used tech stack) even entire application.
- Implicit shared state between modules like current working directory, PID etc.
- A modular application will usually use single database technology and
 a single database server (possibly with read replicas). 
 As writes will be server by a single server instance this may cause 
 severe performance problems in the future.
- Entire application must be written in the same technology (JVM, .NET, node.js).
- Usually in monolithic applications people have a kind of Core or Platform 
 (or Commons or whatever) library that contains utils and shared components.
 This kind of libraries have a tendency to grow uncontrollably 
 and over time they become difficult to change
 (because any change to them requires a lot of refactoring in several modules).
 Also quality of these libraries is often substandard (they are usually not actively
 maintained after they provide functionality needed by their authors - 
 if it works don't change it approach).

I must admit that nowadays it is much more difficult to develop microservices
vs monolith. But I believe this is caused mostly by lack of good 
frameworks and tools. For example I can imagine that in the future
we will have some standard API for logging and monitoring offered by
all relevant cloud providers. From my point of view Spring Boot framework
looks very promising. Also I believe that we have only just started doing 
cloud computing
(it still a very young and immature technology) and we should see a lot of
improvements in the area of distributed system development.

To sum up: using modules is always a good idea. Depending on your
requirements sometimes you will want to build a modular monolith, sometimes
a bunch of microservices. Context is always the king.

### Buzz

- GraphQL
- Chaos Engineering
- A/B Testing
- Canary releases
- Infrastructure as Code


	  ]]></description>
	</item>

	<item>
	  <title>Ray tracing a torus</title>
	  <link>//ray-tracing-torus</link>
	  <author>marcin-chwedczuk</author>
	  <pubDate>2018-05-06T02:00:00+02:00</pubDate>
	  <guid>//ray-tracing-torus</guid>
	  <description><![CDATA[
	     In this blog post I will show you how to ray trace a torus.
I will assume that you already know how to ray trace simple shapes
like spheres and cubes. I will also assume some basic familiarity
with shading and ray tracing in general.

### Obtaining torus equation

Before we start I must introduce some terminology.
I will use $$R$$ to denote torus major radius 
(the distance from the center of the tube to the center of the torus),
and $$r$$ to denote torus minor radius
(the radius of the tube). 
![Torus geometry](assets/images/2018-05-06/torusrR.png)

Let us consider torus $$T$$ centered at point 
$$(0,0,0)$$ with radiuses $$R$$ and $$r$$.
Torus $$T$$ can be defined as a set of points for which
certain function $$F$$ returns zero:

$$
	T = \{ p \in \mathbb{R}^3 \mid F(p) = 0 \}
$$

Our task will be to find a suitable definition of function $$F$$
that properly describes torus $$T$$.

We will start by looking at the intersection of torus $$T$$ with $$XY$$ plane:
![Torus-XY plane intersection](assets/images/2018-05-06/torus-def.svg)
Every point $$P=(x,y)$$ on the circumference of the 
right circle satisfies equation:

$$
(x - R)^2 + y^2 = r^2
$$

Now imagine that we are taking some point $$P$$ on the circumference
and we are rotating it around
$$Y$$ axis. 
![Rotating point around Y axis](assets/images/2018-05-06/torus-def2b.svg)
This way point $$P$$ becomes a set of points in 3D space:

$$
	P=(x,y,0) \Rightarrow \{(x',y,z') \in \mathbb{R}^3 | x'^2 + z'^2 = x^2 \}
$$

Torus can be obtained by rotating all points on the circumference
of the circle. In
other words points $$(x',y,z')$$ on the surface of a torus satisfy equations:

$$
\begin{cases}
(x - R)^2 + y^2 = r^2 \\
x'^2 + z'^2 = x^2 
\end{cases}
$$

This equations can be simplified by removal of $$x$$ variable into:

$$
(x'^2 + y^2 + z'^2)^2 - 2 (R^2 + r^2) (x'^2 + y^2 + z'^2) + 4 R^2 y^2 + (R^2 - r^2)^2 = 0
$$

And this is exactly what we were looking for, a suitable definition
for our function $$F$$. 
After a bit of renaming ($$x' \rightarrow x$$, $$z' \rightarrow z$$) 
we can write our final equation:

$$
F(x,y,z) = (x^2 + y^2 + z^2)^2 - 2 (R^2 + r^2) (x^2 + y^2 + z^2) + 4 R^2 y^2 + (R^2 - r^2)^2
$$

### Solving torus equation

Given ray definition:

$$
r(t) = o + \vec{d} * t
$$

$$
o = \begin{bmatrix}o_x\\o_y\\o_z\end{bmatrix}, \;
\vec{d} = \begin{bmatrix}d_x\\d_y\\d_z\end{bmatrix}
$$

where $$o$$ is the ray origin (starting point) 
and $$d$$ is a unit vector ($$ \left\lVert d \right\rVert = 1 $$) that
represents the ray direction,
we will try to find all positive ($$t > 0$$)
solutions to the equation:

$$
F(r(t)) = 0,\; t > 0
$$

Notice that for a particular ray this equation can have
0, 1, 2, 3 or 4 solutions:
![Visual illustration of number of the solutions](assets/images/2018-05-06/torus-sol4.svg)

We will start by substituting $$x, y, z$$ variables
by $$r(t)$$ point components 
in the formula of function $$F(x,y,z)$$:

$$
r(t) = \begin{bmatrix}r_x\\r_y\\r_z\end{bmatrix}
$$

$$
F(r_x,r_y,r_z) = (r_x^2 + r_y^2 + r_z^2)^2 - 2 (R^2 + r^2) (r_x^2 + r_y^2 + r_z^2) + 4 R^2 r_y^2 + (R^2 - r^2)^2
$$

And then we expand them to their full definition:

$$
r_x = o_x + d_x*t \\
r_y = o_y + d_y*t \\
r_z = o_z + d_z*t \\
$$

After long and tedious calculations and a lot of grouping and 
simplifications we finally get:

$$
F(r(t)) = c_4 t^4 + c_3 t^3 + c_2 t^2 + c_1 t + c_0 = 0
$$

where

$$
\begin{cases}
c_4 = (d_x^2 + d_y^2 + d_z^2)^2 \\
c_3 = 4 (d_x^2 + d_y^2 + d_z^2) (o_x d_x + o_y d_y + o_z d_z) \\
c_2 = 2 (d_x^2 + d_y^2 + d_z^2) (o_x^2 + o_y^2 + o_z^2 - (r^2 + R^2)) + 4 (o_x d_x + o_y d_y + o_z d_z)^2 + 4 R^2 d_y^2 \\
c_1 = 4 (o_x^2 + o_y^2 + o_z^2 - (r^2 + R^2)) (o_x d_x + o_y d_y + o_z d_z) + 8 R^2 o_y d_y \\
c_0 = (o_x^2 + o_y^2 + o_z^2 - (r^2 + R^2))^2 - 4 R^2 (r^2 - o_y^2)
\end{cases}
$$

Since our equation is just a polynomial of 4th degree, we may use 
one of the standard algorithms to solve it. 
In my demo application I used algorithm from 
[Graphic Gems](http://a.co/abkZKRO) book, freely available at
[GitHub](https://github.com/erich666/GraphicsGems/blob/master/gems/Roots3And4.c).
But you are free to use any other algorithm. In particular 
[Numerical Recipes in C](http://www.nrbook.com/a/bookcpdf.php) 
book is a good source of numerical algorithms.

TIP: Unfortunately `Roots3And4.c` file from Graphic Gems (called `solver.js` 
in my demo app) is sparsely 
documented. If you want to know how finding roots of 4th
degree polynomial actually works please
read section from Wikipedia about 
[Ferrari method](https://en.wikipedia.org/wiki/Quartic_function#Ferrari's_solution),
but use second definition of the _resolvent cubic_ described in [this Wikipedia article](https://en.wikipedia.org/wiki/Resolvent_cubic#Second_definition).
With a bit of effort you should be able to follow and understand source
code of the solver then.

### Practical considerations

1. Currently we can only render tori centered at point $$(0,0,0)$$ and laying
 on $$XZ$$ plane. To obtain tori located at arbitrary points and/or in arbitrary
 positions,
 we must apply matrix transformations to the _ray_
 just before computing intersections with the torus surface.
 For example from the viewer point of view
 the results of the following operations are the same:
 translating ray by vector $$(0,2,0)$$,
 translating torus by vector $$(0,-2,0)$$.
 In my demo app this transformation is done in `RayTracer.js#rotationEnd`
 method. For more details please see _Ray Tracing from the Ground Up_ book.

2. Due to limited accuracy of the floating point computations
 artifacts may be seen when we use huge numerical values for torus radiuses.
 For the best results we should keep $$R,r < 10$$.
 If you need huge tori in your scenes please use
 ray transformation technique described in point (1) to scale 
 small tori as needed.

3. From performance point of view rendering a torus by solving its equation
 is slow. Rendering may be speed up considerably if we manage to avoid
 solving the equation altogether e.g. by using 
 [triangle meshes](https://en.wikipedia.org/wiki/Triangle_mesh).

#### Source code

As a part of preparations to write this post I created a
simple demo app that ray traces a torus:
![Demo application](assets/images/2018-05-06/demo-app-thumbnail.png)

Source code can be downloaded from
[this GitHub repository](https://github.com/marcin-chwedczuk/ray_tracing_torus_js).

Application is written in JavaScript.
To run demo app execute:
{% highlight no-highlight %}
$ cd path/to/ray_tracing_torus_js/repo
$ npm install
$ bower install
$ gulp serve
{% endhighlight %}
`npm install` command may take a while to finish, so please be patient.
Also notice that you have to had both `bower` and `gulp` installed
on you local machine to make this work. 
You can install them by executing:
{% highlight no-highlight %}
$ sudo npm install --global gulp-cli
$ sudo npm install --global bower
{% endhighlight %}

#### References

* Ray Tracing from the Ground Up, Kevin Suffern, [Buy on Amazon](http://a.co/c5YAorf)
* Wikipedia, [Torus entry](https://en.wikipedia.org/wiki/Torus)
* [Roots3And4.c from Graphic Gems](https://github.com/erich666/GraphicsGems/blob/master/gems/Roots3And4.c)


	  ]]></description>
	</item>


</channel>
</rss>
